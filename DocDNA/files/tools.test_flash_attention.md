# tools.test_flash_attention

> Flash Attention 2 Testing

## Public API


### Functions
- **benchmark_attention_implementation** — Benchmark a specific attention implementation
- **load_model_with_attention** — Load model with specific attention implementation
- **test_flash_attention_vs_eager** — Test Flash Attention 2 vs eager attention

## Imports (local guesses)
- gc, json, modules.tts_engine, os, pathlib, sys, time, torch, traceback

## Entrypoint
- Contains `if __name__ == '__main__':` block