{
  "interface:<module>": [
    "ArgumentParser",
    "add_argument",
    "filterwarnings",
    "flush",
    "main",
    "parse_known_args",
    "print",
    "resume_book_from_chunk",
    "signal"
  ],
  "interface:signal_handler": [
    "print"
  ],
  "interface:prompt_book_selection": [
    "enumerate",
    "input",
    "int",
    "isdigit",
    "len",
    "print",
    "strip"
  ],
  "interface:prompt_voice_selection": [
    "enumerate",
    "input",
    "int",
    "isdigit",
    "len",
    "print",
    "strip"
  ],
  "interface:prompt_tts_params": [
    "get_choice_input",
    "get_float_input",
    "get_system_profile",
    "get_yes_no_input",
    "len",
    "list",
    "print",
    "print_system_summary",
    "range",
    "recommend_asr_models",
    "upper"
  ],
  "interface:prompt_tts_params.get_float_input": [
    "float",
    "input",
    "print",
    "str",
    "strip"
  ],
  "interface:prompt_tts_params.get_yes_no_input": [
    "input",
    "lower",
    "print",
    "strip"
  ],
  "interface:prompt_tts_params.get_choice_input": [
    "input",
    "int",
    "len",
    "print",
    "strip"
  ],
  "interface:pipeline_book_processing": [
    "append",
    "enumerate",
    "exists",
    "get",
    "get_best_available_device",
    "len",
    "print",
    "print_exc",
    "process_book_folder"
  ],
  "interface:main": [
    "Path",
    "append",
    "ensure_voice_sample_compatibility",
    "enumerate",
    "input",
    "is_dir",
    "isinstance",
    "iterdir",
    "len",
    "list_voice_samples",
    "log_console",
    "lower",
    "pipeline_book_processing",
    "print",
    "prompt_book_selection",
    "prompt_tts_params",
    "prompt_voice_selection"
  ],
  "interface:main_with_resume": [
    "input",
    "int",
    "main",
    "print",
    "resume_book_from_chunk",
    "run_combine_only_mode",
    "strip"
  ],
  "main_launcher:prompt_menu": [
    "enumerate",
    "input",
    "int",
    "isdigit",
    "len",
    "print",
    "strip"
  ],
  "main_launcher:prepare_chunk_file": [
    "Path",
    "enumerate",
    "exists",
    "generate_enriched_chunks",
    "get_float_input",
    "get_yes_no_input",
    "glob",
    "input",
    "int",
    "is_dir",
    "iterdir",
    "len",
    "list",
    "mkdir",
    "print",
    "strip"
  ],
  "main_launcher:prepare_chunk_file.get_float_input": [
    "float",
    "input",
    "print",
    "strip"
  ],
  "main_launcher:prepare_chunk_file.get_yes_no_input": [
    "input",
    "lower",
    "print",
    "strip"
  ],
  "main_launcher:main_with_resume": [
    "input",
    "int",
    "main",
    "print",
    "resume_book_from_chunk",
    "run_combine_only_mode",
    "strip"
  ],
  "main_launcher:wrapper_main": [
    "generate_from_json_main",
    "input",
    "int",
    "main",
    "prepare_chunk_file",
    "print",
    "prompt_menu",
    "resume_book_from_chunk",
    "run_chunk_repair_tool",
    "run_combine_only_mode",
    "strip",
    "test_chunking"
  ],
  "main_launcher:<module>": [
    "wrapper_main"
  ],
  "launch:main": [
    "Path",
    "absolute",
    "chdir",
    "exists",
    "print",
    "run",
    "str"
  ],
  "launch:<module>": [
    "exit",
    "main"
  ],
  "gradio_launcher:GradioLauncher.print_header": [
    "print"
  ],
  "gradio_launcher:GradioLauncher.check_python_version": [
    "exit",
    "print"
  ],
  "gradio_launcher:GradioLauncher.check_working_directory": [
    "Path",
    "append",
    "exists",
    "join",
    "print"
  ],
  "gradio_launcher:GradioLauncher.create_directories": [
    "Path",
    "append",
    "exists",
    "join",
    "mkdir",
    "print"
  ],
  "gradio_launcher:GradioLauncher.check_package_installed": [
    "Path",
    "exists",
    "get_distribution",
    "getattr",
    "hasattr",
    "import_module",
    "run",
    "split",
    "startswith",
    "strip"
  ],
  "gradio_launcher:GradioLauncher.compare_versions": [
    "extend",
    "int",
    "len",
    "max",
    "split"
  ],
  "gradio_launcher:GradioLauncher.setup_virtual_environment": [
    "Path",
    "exists",
    "print",
    "run",
    "str",
    "strip"
  ],
  "gradio_launcher:GradioLauncher.install_package": [
    "Path",
    "exists",
    "getattr",
    "hasattr",
    "install_package",
    "print",
    "run",
    "setup_virtual_environment",
    "str"
  ],
  "gradio_launcher:GradioLauncher.check_and_install_requirements": [
    "append",
    "check_package_installed",
    "compare_versions",
    "get",
    "install_package",
    "items",
    "len",
    "print"
  ],
  "gradio_launcher:GradioLauncher.check_gpu_availability": [
    "device_count",
    "get_device_name",
    "hasattr",
    "is_available",
    "print",
    "str"
  ],
  "gradio_launcher:GradioLauncher.verify_installation": [
    "append",
    "import_module",
    "join",
    "print",
    "str"
  ],
  "gradio_launcher:GradioLauncher.launch_interface": [
    "Path",
    "_launch_direct",
    "exists",
    "exit",
    "getenv",
    "hasattr",
    "print",
    "run",
    "str"
  ],
  "gradio_launcher:GradioLauncher._launch_direct": [
    "exit",
    "getenv",
    "hasattr",
    "launch_interface",
    "print",
    "sleep",
    "str"
  ],
  "gradio_launcher:GradioLauncher.run": [
    "check_and_install_requirements",
    "check_gpu_availability",
    "check_python_version",
    "check_working_directory",
    "create_directories",
    "exit",
    "launch_interface",
    "print",
    "print_header",
    "verify_installation"
  ],
  "gradio_launcher:main": [
    "GradioLauncher",
    "run"
  ],
  "gradio_launcher:<module>": [
    "main"
  ],
  "gradio_app:<module>": [
    "SentimentIntensityAnalyzer",
    "basicConfig",
    "create_interface",
    "error",
    "getLogger",
    "info",
    "initialize_tts",
    "launch"
  ],
  "gradio_app:initialize_tts": [
    "ChatterboxTTS",
    "error",
    "info",
    "is_available",
    "set_per_process_memory_fraction"
  ],
  "gradio_app:process_text_to_chunks": [
    "append",
    "enumerate",
    "error",
    "max",
    "min",
    "polarity_scores",
    "round",
    "sentence_chunk_text",
    "smart_punctuate"
  ],
  "gradio_app:generate_chunk_audio": [
    "add_contextual_silence",
    "error",
    "generate_speech",
    "get",
    "initialize_tts",
    "progress_callback"
  ],
  "gradio_app:generate_audiobook": [
    "NamedTemporaryFile",
    "Progress",
    "append",
    "cat",
    "enumerate",
    "error",
    "format_exc",
    "generate_chunk_audio",
    "info",
    "join",
    "len",
    "open",
    "process_text_to_chunks",
    "progress",
    "read",
    "save",
    "str",
    "strip"
  ],
  "gradio_app:create_interface": [
    "Accordion",
    "Audio",
    "Blocks",
    "Button",
    "Column",
    "File",
    "Markdown",
    "Row",
    "Slider",
    "Soft",
    "Textbox",
    "click"
  ],
  "gradio_main_interface:<module>": [
    "Path",
    "append",
    "launch_interface",
    "print",
    "str"
  ],
  "gradio_main_interface:detect_device_status": [
    "get_device_name",
    "get_device_properties",
    "is_available"
  ],
  "gradio_main_interface:create_placeholder_tab": [
    "Button",
    "Column",
    "Markdown"
  ],
  "gradio_main_interface:create_main_interface": [
    "Blocks",
    "Markdown",
    "Soft",
    "Tab",
    "Tabs",
    "create_chunk_tools_tab",
    "create_combine_audio_tab",
    "create_configuration_tab",
    "create_convert_book_tab",
    "create_json_generate_tab",
    "create_placeholder_tab",
    "create_prepare_text_tab",
    "create_settings_tab_interface",
    "detect_device_status"
  ],
  "gradio_main_interface:launch_interface": [
    "create_main_interface",
    "getenv",
    "launch",
    "print"
  ],
  "chatterbox_gui:<module>": [
    "globals",
    "isinstance",
    "main",
    "print"
  ],
  "chatterbox_gui:NoScrollSpinBox.wheelEvent": [
    "ignore"
  ],
  "chatterbox_gui:NoScrollDoubleSpinBox.wheelEvent": [
    "ignore"
  ],
  "chatterbox_gui:StructuredStatusPanel.__init__": [
    "__init__",
    "setup_ui",
    "super"
  ],
  "chatterbox_gui:StructuredStatusPanel.setup_ui": [
    "QFormLayout",
    "QLabel",
    "QProgressBar",
    "addRow",
    "setFormat",
    "setStyleSheet",
    "setTextVisible",
    "setVisible"
  ],
  "chatterbox_gui:StructuredStatusPanel.update_status": [
    "endswith",
    "isinstance",
    "setMaximum",
    "setText",
    "setValue",
    "setVisible",
    "str"
  ],
  "chatterbox_gui:StructuredStatusPanel.reset": [
    "setText",
    "setVisible"
  ],
  "chatterbox_gui:ChunkingTestWindow.__init__": [
    "QHBoxLayout",
    "QLabel",
    "QPushButton",
    "QTextEdit",
    "QVBoxLayout",
    "__init__",
    "addLayout",
    "addStretch",
    "addWidget",
    "connect",
    "setGeometry",
    "setModal",
    "setReadOnly",
    "setStyleSheet",
    "setWindowTitle",
    "super"
  ],
  "chatterbox_gui:ChunkingTestWindow.set_chunking_results": [
    "movePosition",
    "setPlainText",
    "setTextCursor",
    "textCursor"
  ],
  "chatterbox_gui:ChunkingTestWindow.copy_to_clipboard": [
    "clipboard",
    "information",
    "setText",
    "toPlainText"
  ],
  "chatterbox_gui:ProcessThread": [
    "pyqtSignal"
  ],
  "chatterbox_gui:ProcessThread.__init__": [
    "__init__",
    "super"
  ],
  "chatterbox_gui:ProcessThread.parse_and_emit_status": [
    "emit",
    "group",
    "int",
    "search"
  ],
  "chatterbox_gui:ProcessThread.parse_chunk_progress": [
    "emit",
    "group",
    "int",
    "search"
  ],
  "chatterbox_gui:ProcessThread.run.GUIOutput.write": [
    "emit",
    "parse_chunk_progress",
    "strip",
    "write"
  ],
  "chatterbox_gui:ProcessThread.run.GUIOutput.flush": [
    "flush"
  ],
  "chatterbox_gui:ProcessThread.run": [
    "GUIOutput",
    "emit",
    "hasattr",
    "str",
    "target_function"
  ],
  "chatterbox_gui:ChatterboxMainWindow.__init__": [
    "QScrollArea",
    "QSettings",
    "QSplitter",
    "QTabWidget",
    "QVBoxLayout",
    "QWidget",
    "__init__",
    "addWidget",
    "connect",
    "create_audio_output_analyzer_tab",
    "create_combine_tab",
    "create_config_tab",
    "create_convert_book_tab",
    "create_json_generate_tab",
    "create_output_area_widget",
    "create_prepare_text_tab",
    "create_repair_tool_tab",
    "create_resume_tab",
    "create_test_chunking_tab",
    "create_voice_analyzer_tab",
    "init_token_logging",
    "setCentralWidget",
    "setCollapsible",
    "setContentsMargins",
    "setGeometry",
    "setHorizontalScrollBarPolicy",
    "setSizes",
    "setVerticalScrollBarPolicy",
    "setWidget",
    "setWidgetResizable",
    "setWindowTitle",
    "showMessage",
    "statusBar",
    "super",
    "test_audio_system_startup"
  ],
  "chatterbox_gui:ChatterboxMainWindow.init_token_logging": [
    "init_token_log",
    "log_output"
  ],
  "chatterbox_gui:ChatterboxMainWindow.closeEvent": [
    "accept",
    "hasattr",
    "stop_voice_sample"
  ],
  "chatterbox_gui:ChatterboxMainWindow.test_audio_system_startup": [
    "init",
    "quit",
    "showMessage",
    "statusBar",
    "system"
  ],
  "chatterbox_gui:ChatterboxMainWindow.create_convert_book_tab": [
    "NoScrollDoubleSpinBox",
    "NoScrollSpinBox",
    "QButtonGroup",
    "QCheckBox",
    "QComboBox",
    "QFormLayout",
    "QGroupBox",
    "QHBoxLayout",
    "QLabel",
    "QLineEdit",
    "QPushButton",
    "QRadioButton",
    "QScrollArea",
    "QTextEdit",
    "QVBoxLayout",
    "QWidget",
    "StructuredStatusPanel",
    "_attach_spin_reset",
    "addButton",
    "addItems",
    "addLayout",
    "addRow",
    "addSpacing",
    "addStretch",
    "addTab",
    "addWidget",
    "connect",
    "detect_and_update_device_status",
    "keys",
    "list",
    "setChecked",
    "setCurrentText",
    "setDecimals",
    "setEnabled",
    "setHorizontalScrollBarPolicy",
    "setLayout",
    "setMaximumHeight",
    "setMaximumWidth",
    "setPlaceholderText",
    "setPlainText",
    "setRange",
    "setReadOnly",
    "setSingleStep",
    "setSizePolicy",
    "setStyleSheet",
    "setToolTip",
    "setValue",
    "setVerticalScrollBarPolicy",
    "setVisible",
    "setWidget",
    "setWidgetResizable",
    "str"
  ],
  "chatterbox_gui:ChatterboxMainWindow.handle_micro_batching_toggle": [
    "bool",
    "info"
  ],
  "chatterbox_gui:ChatterboxMainWindow.handle_vader_toggle": [
    "bool",
    "hasattr",
    "isChecked",
    "setChecked"
  ],
  "chatterbox_gui:ChatterboxMainWindow._attach_spin_reset": [
    "_show_spin_context_menu",
    "connect",
    "setContextMenuPolicy",
    "setProperty"
  ],
  "chatterbox_gui:ChatterboxMainWindow._attach_config_key": [
    "setProperty"
  ],
  "chatterbox_gui:ChatterboxMainWindow._read_widget_value": [
    "bool",
    "currentText",
    "float",
    "int",
    "isChecked",
    "isdigit",
    "isinstance",
    "strip",
    "value"
  ],
  "chatterbox_gui:ChatterboxMainWindow._build_effective_settings": [
    "_read_widget_value",
    "findChildren",
    "get",
    "hasattr",
    "property"
  ],
  "chatterbox_gui:ChatterboxMainWindow._show_spin_context_menu": [
    "QMenu",
    "_reset_spin_from_saved",
    "addAction",
    "connect",
    "exec_",
    "mapToGlobal"
  ],
  "chatterbox_gui:ChatterboxMainWindow._reset_spin_from_saved": [
    "blockSignals",
    "float",
    "getattr",
    "hasattr",
    "int",
    "isinstance",
    "max",
    "maximum",
    "min",
    "minimum",
    "property",
    "reload",
    "setValue",
    "showMessage",
    "statusBar"
  ],
  "chatterbox_gui:ChatterboxMainWindow.reload_tab1_from_config": [
    "blockSignals",
    "float",
    "getattr",
    "hasattr",
    "int",
    "isinstance",
    "max",
    "maximum",
    "min",
    "minimum",
    "reload",
    "setValue",
    "showMessage",
    "statusBar"
  ],
  "chatterbox_gui:ChatterboxMainWindow.create_config_tab": [
    "NoScrollDoubleSpinBox",
    "NoScrollSpinBox",
    "QCheckBox",
    "QComboBox",
    "QFormLayout",
    "QGroupBox",
    "QHBoxLayout",
    "QLabel",
    "QPushButton",
    "QScrollArea",
    "QVBoxLayout",
    "QWidget",
    "_attach_config_key",
    "_attach_spin_reset",
    "addItems",
    "addLayout",
    "addRow",
    "addSpacing",
    "addStretch",
    "addTab",
    "addWidget",
    "bool",
    "connect",
    "getattr",
    "globals",
    "save_original_config_values",
    "setChecked",
    "setCurrentText",
    "setDecimals",
    "setMaximumWidth",
    "setRange",
    "setSingleStep",
    "setStyleSheet",
    "setToolTip",
    "setValue",
    "setVerticalScrollBarPolicy",
    "setVisible",
    "setWidget",
    "setWidgetResizable",
    "setWordWrap",
    "setup_config_change_tracking",
    "str"
  ],
  "chatterbox_gui:ChatterboxMainWindow.create_resume_tab": [
    "QGroupBox",
    "QLabel",
    "QListWidget",
    "QProgressBar",
    "QPushButton",
    "QVBoxLayout",
    "QWidget",
    "addStretch",
    "addTab",
    "addWidget",
    "connect",
    "setStyleSheet",
    "setVisible"
  ],
  "chatterbox_gui:ChatterboxMainWindow.create_combine_tab": [
    "QFormLayout",
    "QGroupBox",
    "QHBoxLayout",
    "QLabel",
    "QLineEdit",
    "QProgressBar",
    "QPushButton",
    "QVBoxLayout",
    "QWidget",
    "addLayout",
    "addRow",
    "addStretch",
    "addTab",
    "addWidget",
    "connect",
    "setPlaceholderText",
    "setStyleSheet",
    "setVisible",
    "setWordWrap"
  ],
  "chatterbox_gui:ChatterboxMainWindow.create_prepare_text_tab": [
    "QFormLayout",
    "QGroupBox",
    "QHBoxLayout",
    "QLabel",
    "QLineEdit",
    "QProgressBar",
    "QPushButton",
    "QVBoxLayout",
    "QWidget",
    "addRow",
    "addStretch",
    "addTab",
    "addWidget",
    "connect",
    "setPlaceholderText",
    "setStyleSheet",
    "setVisible",
    "setWordWrap"
  ],
  "chatterbox_gui:ChatterboxMainWindow.create_test_chunking_tab": [
    "NoScrollDoubleSpinBox",
    "NoScrollSpinBox",
    "QCheckBox",
    "QFormLayout",
    "QGroupBox",
    "QLabel",
    "QPushButton",
    "QTextEdit",
    "QVBoxLayout",
    "QWidget",
    "addRow",
    "addStretch",
    "addTab",
    "addWidget",
    "connect",
    "setChecked",
    "setDecimals",
    "setEnabled",
    "setMaximumHeight",
    "setPlaceholderText",
    "setRange",
    "setSingleStep",
    "setStyleSheet",
    "setToolTip",
    "setValue"
  ],
  "chatterbox_gui:ChatterboxMainWindow.create_repair_tool_tab": [
    "NoScrollDoubleSpinBox",
    "QComboBox",
    "QGroupBox",
    "QHBoxLayout",
    "QLabel",
    "QLineEdit",
    "QListWidget",
    "QPushButton",
    "QTextEdit",
    "QVBoxLayout",
    "QWidget",
    "addItem",
    "addItems",
    "addLayout",
    "addStretch",
    "addTab",
    "addWidget",
    "connect",
    "refresh_repair_books",
    "setDecimals",
    "setMaximumHeight",
    "setMaximumWidth",
    "setPlaceholderText",
    "setRange",
    "setSingleStep",
    "setSpacing",
    "setStyleSheet"
  ],
  "chatterbox_gui:ChatterboxMainWindow.create_json_generate_tab": [
    "QComboBox",
    "QFormLayout",
    "QGroupBox",
    "QHBoxLayout",
    "QLabel",
    "QLineEdit",
    "QProgressBar",
    "QPushButton",
    "QSlider",
    "QVBoxLayout",
    "QWidget",
    "StructuredStatusPanel",
    "addLayout",
    "addRow",
    "addStretch",
    "addTab",
    "addWidget",
    "connect",
    "refresh_json_voices",
    "setAlignment",
    "setEnabled",
    "setPlaceholderText",
    "setStyleSheet",
    "setVisible"
  ],
  "chatterbox_gui:ChatterboxMainWindow.create_output_area_widget": [
    "QGroupBox",
    "QPushButton",
    "QTextEdit",
    "QVBoxLayout",
    "addWidget",
    "connect",
    "setContentsMargins",
    "setMinimumHeight",
    "setStyleSheet"
  ],
  "chatterbox_gui:ChatterboxMainWindow.create_output_area": [
    "QWidget",
    "create_output_area_widget"
  ],
  "chatterbox_gui:ChatterboxMainWindow.browse_book_folder": [
    "getExistingDirectory",
    "populate_text_files",
    "setText",
    "setValue",
    "value"
  ],
  "chatterbox_gui:ChatterboxMainWindow.populate_text_files": [
    "Path",
    "addItem",
    "clear",
    "glob",
    "list",
    "str"
  ],
  "chatterbox_gui:ChatterboxMainWindow.browse_voice_file": [
    "Path",
    "getOpenFileName",
    "hasattr",
    "setEnabled",
    "setText",
    "setValue",
    "str",
    "value"
  ],
  "chatterbox_gui:ChatterboxMainWindow.play_voice_sample": [
    "Path",
    "PlaySound",
    "Popen",
    "QMessageBox",
    "QTimer",
    "connect",
    "exec_",
    "exists",
    "get_init",
    "hasattr",
    "init",
    "load",
    "play",
    "setEnabled",
    "setIcon",
    "setInformativeText",
    "setText",
    "setWindowTitle",
    "singleShot",
    "start",
    "stop_voice_sample",
    "str",
    "system",
    "text",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.stop_voice_sample": [
    "PlaySound",
    "_reset_voice_buttons",
    "get_init",
    "print",
    "stop",
    "system"
  ],
  "chatterbox_gui:ChatterboxMainWindow._reset_voice_buttons": [
    "hasattr",
    "setEnabled",
    "stop"
  ],
  "chatterbox_gui:ChatterboxMainWindow._check_voice_playback": [
    "_reset_voice_buttons",
    "get_busy",
    "hasattr",
    "print"
  ],
  "chatterbox_gui:ChatterboxMainWindow.handle_asr_toggle": [
    "setVisible"
  ],
  "chatterbox_gui:ChatterboxMainWindow.analyze_system": [
    "categorize_system",
    "get_system_profile",
    "setPlainText",
    "str",
    "update_asr_models"
  ],
  "chatterbox_gui:ChatterboxMainWindow.update_asr_models": [
    "checkedId",
    "get_system_profile",
    "recommend_asr_models",
    "setPlainText",
    "str",
    "upper"
  ],
  "chatterbox_gui:ChatterboxMainWindow.apply_preset": [
    "currentText",
    "format_exc",
    "get",
    "isChecked",
    "keys",
    "list",
    "log_output",
    "setChecked",
    "setCurrentText",
    "setValue",
    "str",
    "value"
  ],
  "chatterbox_gui:ChatterboxMainWindow.browse_combine_book": [
    "getExistingDirectory",
    "setText"
  ],
  "chatterbox_gui:ChatterboxMainWindow.browse_prepare_text": [
    "getOpenFileName",
    "setText"
  ],
  "chatterbox_gui:ChatterboxMainWindow.browse_json_file": [
    "basename",
    "dirname",
    "getOpenFileName",
    "log_output",
    "setText",
    "setValue",
    "value"
  ],
  "chatterbox_gui:ChatterboxMainWindow.start_conversion": [
    "Path",
    "ProcessThread",
    "_build_effective_settings",
    "checkedId",
    "clear_token_overruns",
    "connect",
    "currentData",
    "currentText",
    "get",
    "get_system_profile",
    "hasattr",
    "isChecked",
    "log_output",
    "print",
    "recommend_asr_models",
    "reset",
    "setEnabled",
    "setText",
    "singleShot",
    "start",
    "text",
    "update_status",
    "update_status_display",
    "upper",
    "value",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.start_conversion.debug_scroll": [
    "maximum",
    "print",
    "setValue",
    "verticalScrollBar"
  ],
  "chatterbox_gui:ChatterboxMainWindow.run_book_conversion": [
    "get",
    "get_best_available_device",
    "print",
    "print_exc",
    "process_book_folder",
    "upper"
  ],
  "chatterbox_gui:ChatterboxMainWindow.refresh_incomplete_books": [
    "addItem",
    "clear",
    "find_incomplete_books",
    "len",
    "log_output",
    "str"
  ],
  "chatterbox_gui:ChatterboxMainWindow.resume_processing": [
    "ProcessThread",
    "connect",
    "currentItem",
    "log_output",
    "start",
    "text",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.combine_audio": [
    "Path",
    "ProcessThread",
    "connect",
    "log_output",
    "on_combine_finished",
    "start",
    "text",
    "update_status_display",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.combine_audio_wav_only": [
    "Path",
    "ProcessThread",
    "connect",
    "log_output",
    "on_combine_wav_finished",
    "start",
    "text",
    "update_status_display",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.on_combine_finished": [
    "critical",
    "information",
    "log_output",
    "update_status_display"
  ],
  "chatterbox_gui:ChatterboxMainWindow.on_combine_wav_finished": [
    "critical",
    "information",
    "log_output",
    "update_status_display"
  ],
  "chatterbox_gui:ChatterboxMainWindow.prepare_text": [
    "Path",
    "ProcessThread",
    "connect",
    "log_output",
    "on_text_prep_finished",
    "start",
    "text",
    "update_status_display",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow._process_text_file": [
    "_build_effective_settings",
    "currentText",
    "generate_enriched_chunks",
    "isChecked",
    "len",
    "mkdir",
    "print",
    "value"
  ],
  "chatterbox_gui:ChatterboxMainWindow.on_text_prep_finished": [
    "critical",
    "information",
    "log_output",
    "update_status_display"
  ],
  "chatterbox_gui:ChatterboxMainWindow.test_chunking": [
    "ChunkingTestWindow",
    "StringIO",
    "critical",
    "getvalue",
    "log_output",
    "redirect_stdout",
    "set_chunking_results",
    "show",
    "strip",
    "test_chunking",
    "toPlainText",
    "value"
  ],
  "chatterbox_gui:ChatterboxMainWindow.refresh_repair_books": [
    "Path",
    "addItem",
    "any",
    "append",
    "clear",
    "exists",
    "glob",
    "is_dir",
    "iterdir",
    "len",
    "log_output",
    "replace"
  ],
  "chatterbox_gui:ChatterboxMainWindow.load_chunks_for_repair": [
    "Path",
    "clear",
    "currentData",
    "detect_and_update_voice_info",
    "enumerate",
    "len",
    "load_chunks",
    "log_output",
    "str",
    "update_repair_chunk_display"
  ],
  "chatterbox_gui:ChatterboxMainWindow.detect_and_update_voice_info": [
    "addItem",
    "clear",
    "currentData",
    "get_likely_voices_for_book",
    "len",
    "log_output",
    "setStyleSheet",
    "setText"
  ],
  "chatterbox_gui:ChatterboxMainWindow.refresh_available_voices": [
    "detect_and_update_voice_info",
    "log_output"
  ],
  "chatterbox_gui:ChatterboxMainWindow.search_chunks_for_repair": [
    "QListWidgetItem",
    "addItem",
    "clear",
    "len",
    "log_output",
    "search_chunks",
    "setData",
    "strip",
    "text",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.search_chunks_by_number": [
    "QListWidgetItem",
    "addItem",
    "append",
    "clear",
    "get",
    "int",
    "isdigit",
    "len",
    "log_output",
    "setData",
    "split",
    "strip",
    "text",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.select_chunk_for_repair": [
    "data",
    "log_output",
    "update_repair_chunk_display"
  ],
  "chatterbox_gui:ChatterboxMainWindow.update_repair_chunk_display": [
    "clear",
    "get",
    "setCurrentText",
    "setPlainText",
    "setText",
    "setValue"
  ],
  "chatterbox_gui:ChatterboxMainWindow.save_chunk_changes": [
    "OrderedDict",
    "critical",
    "currentText",
    "deepcopy",
    "exists",
    "fromtimestamp",
    "get",
    "getmtime",
    "information",
    "keys",
    "len",
    "list",
    "load_chunks",
    "log_output",
    "round",
    "save_chunks",
    "split",
    "str",
    "strftime",
    "toPlainText",
    "value",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.play_original_chunk": [
    "exists",
    "log_output",
    "play_chunk_audio",
    "str",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.resynthesize_chunk": [
    "copy",
    "critical",
    "currentData",
    "currentText",
    "information",
    "len",
    "log_output",
    "split",
    "synthesize_chunk",
    "toPlainText",
    "value",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.play_revised_chunk": [
    "exists",
    "log_output",
    "play_chunk_audio",
    "str",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.accept_chunk_revision": [
    "accept_revision",
    "critical",
    "exists",
    "hasattr",
    "information",
    "log_output",
    "update_repair_chunk_display",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.generate_from_json": [
    "Path",
    "ProcessThread",
    "analyze_and_optimize_tokens",
    "basename",
    "connect",
    "critical",
    "currentText",
    "exists",
    "format_analysis_summary",
    "hasattr",
    "information",
    "log_output",
    "reset",
    "setEnabled",
    "setValue",
    "setVisible",
    "start",
    "strip",
    "text",
    "update_status",
    "value",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.browse_m4b_file": [
    "Path",
    "cwd",
    "exists",
    "getOpenFileName",
    "log_output",
    "lower",
    "resolve",
    "setEnabled",
    "setToolTip",
    "str",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.regenerate_m4b": [
    "QMessageBox",
    "append",
    "convert_to_m4b",
    "critical",
    "currentText",
    "exec_",
    "exists",
    "glob",
    "hasattr",
    "information",
    "int",
    "log_output",
    "max",
    "rename",
    "setEnabled",
    "setIcon",
    "setInformativeText",
    "setText",
    "setToolTip",
    "setWindowTitle",
    "split",
    "stat",
    "str",
    "strip",
    "unlink",
    "value",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow._handle_token_overruns": [
    "QMessageBox",
    "QPushButton",
    "addButton",
    "clickedButton",
    "exec_",
    "join",
    "len",
    "log_output",
    "setCurrentIndex",
    "setIcon",
    "setText",
    "setWindowTitle"
  ],
  "chatterbox_gui:ChatterboxMainWindow.on_conversion_finished": [
    "Path",
    "_handle_token_overruns",
    "critical",
    "exists",
    "get_token_overruns",
    "information",
    "log_output",
    "setEnabled",
    "setText",
    "text",
    "update_status_display"
  ],
  "chatterbox_gui:ChatterboxMainWindow.reset_config_defaults": [
    "critical",
    "currentText",
    "getattr",
    "hasattr",
    "int",
    "isChecked",
    "log_output",
    "reload",
    "setChecked",
    "setCurrentText",
    "setValue",
    "showMessage",
    "statusBar",
    "str",
    "value"
  ],
  "chatterbox_gui:ChatterboxMainWindow.save_original_config_values": [
    "isChecked",
    "value"
  ],
  "chatterbox_gui:ChatterboxMainWindow.setup_config_change_tracking": [
    "connect"
  ],
  "chatterbox_gui:ChatterboxMainWindow.check_unsaved_config_changes": [
    "question",
    "save_config_to_file"
  ],
  "chatterbox_gui:ChatterboxMainWindow.on_tab_changed": [
    "check_unsaved_config_changes",
    "getattr",
    "setCurrentIndex"
  ],
  "chatterbox_gui:ChatterboxMainWindow.save_config_to_file": [
    "_release_global_tts_model",
    "blockSignals",
    "collect",
    "critical",
    "currentText",
    "empty_cache",
    "getattr",
    "hasattr",
    "int",
    "ipc_collect",
    "isChecked",
    "is_available",
    "items",
    "log_output",
    "open",
    "read",
    "reload",
    "setCurrentText",
    "setValue",
    "showMessage",
    "statusBar",
    "str",
    "sub",
    "synchronize",
    "value",
    "write"
  ],
  "chatterbox_gui:ChatterboxMainWindow.play_m4b_file": [
    "Popen",
    "critical",
    "exists",
    "hasattr",
    "information",
    "log_output",
    "str"
  ],
  "chatterbox_gui:ChatterboxMainWindow.detect_and_update_device_status": [
    "device_count",
    "float",
    "get_device_name",
    "get_device_properties",
    "group",
    "hasattr",
    "int",
    "is_available",
    "len",
    "log_output",
    "run",
    "search",
    "setStyleSheet",
    "setText",
    "split",
    "startswith",
    "str"
  ],
  "chatterbox_gui:ChatterboxMainWindow.log_output": [
    "append",
    "hasattr",
    "maximum",
    "now",
    "print",
    "setValue",
    "strftime",
    "sub",
    "verticalScrollBar"
  ],
  "chatterbox_gui:ChatterboxMainWindow.update_tab1_status_panel": [
    "get",
    "hasattr",
    "update_status"
  ],
  "chatterbox_gui:ChatterboxMainWindow.update_tab8_status_panel": [
    "get",
    "hasattr",
    "update_status"
  ],
  "chatterbox_gui:ChatterboxMainWindow.refresh_json_voices": [
    "addItem",
    "clear",
    "len",
    "list_voice_samples",
    "log_output",
    "str"
  ],
  "chatterbox_gui:ChatterboxMainWindow._generate_audiobook_from_json": [
    "generate_audiobook_from_json",
    "print"
  ],
  "chatterbox_gui:ChatterboxMainWindow.json_generation_finished": [
    "basename",
    "critical",
    "information",
    "log_output",
    "setEnabled",
    "setStyleSheet",
    "setText",
    "setVisible"
  ],
  "chatterbox_gui:ChatterboxMainWindow.play_json_audio": [
    "Popen",
    "basename",
    "critical",
    "exists",
    "log_output",
    "setEnabled",
    "system",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.pause_json_audio": [
    "log_output",
    "setText",
    "text"
  ],
  "chatterbox_gui:ChatterboxMainWindow.stop_json_audio": [
    "log_output",
    "setEnabled",
    "setText",
    "terminate"
  ],
  "chatterbox_gui:ChatterboxMainWindow.rewind_json_audio": [
    "log_output"
  ],
  "chatterbox_gui:ChatterboxMainWindow.ff_json_audio": [
    "log_output"
  ],
  "chatterbox_gui:ChatterboxMainWindow.create_voice_analyzer_tab": [
    "QLabel",
    "QPushButton",
    "QVBoxLayout",
    "QWidget",
    "addLayout",
    "addStretch",
    "addTab",
    "addWidget",
    "build_voice_analyzer_gui",
    "connect",
    "setStyleSheet",
    "setWordWrap",
    "str"
  ],
  "chatterbox_gui:ChatterboxMainWindow.try_install_voice_analyzer_deps": [
    "critical",
    "information",
    "log_output",
    "question",
    "run",
    "str"
  ],
  "chatterbox_gui:ChatterboxMainWindow.build_voice_analyzer_gui": [
    "QCheckBox",
    "QGroupBox",
    "QHBoxLayout",
    "QLabel",
    "QListWidget",
    "QProgressBar",
    "QPushButton",
    "QSplitter",
    "QTabWidget",
    "QVBoxLayout",
    "QWidget",
    "addLayout",
    "addStretch",
    "addWidget",
    "connect",
    "setChecked",
    "setEnabled",
    "setMaximumWidth",
    "setSizes",
    "setStyleSheet",
    "setToolTip",
    "setVisible",
    "setup_analyzer_autofix_tab",
    "setup_analyzer_comparison_tab",
    "setup_analyzer_plots_tab",
    "setup_analyzer_recommendations_tab",
    "setup_analyzer_scores_tab",
    "update_analyzer_ui_state"
  ],
  "chatterbox_gui:ChatterboxMainWindow.setup_analyzer_scores_tab": [
    "QFont",
    "QGridLayout",
    "QLabel",
    "QScrollArea",
    "QVBoxLayout",
    "QWidget",
    "addTab",
    "addWidget",
    "setAlignment",
    "setFont",
    "setStyleSheet",
    "setWidget",
    "setWidgetResizable"
  ],
  "chatterbox_gui:ChatterboxMainWindow.setup_analyzer_plots_tab": [
    "Figure",
    "FigureCanvas",
    "QLabel",
    "QVBoxLayout",
    "QWidget",
    "addTab",
    "addWidget",
    "add_subplot",
    "draw",
    "setAlignment",
    "setStyleSheet",
    "set_title",
    "text"
  ],
  "chatterbox_gui:ChatterboxMainWindow.setup_analyzer_recommendations_tab": [
    "QFont",
    "QTextEdit",
    "QVBoxLayout",
    "QWidget",
    "addTab",
    "addWidget",
    "setFont",
    "setReadOnly",
    "setText"
  ],
  "chatterbox_gui:ChatterboxMainWindow.setup_analyzer_comparison_tab": [
    "Figure",
    "FigureCanvas",
    "QLabel",
    "QVBoxLayout",
    "QWidget",
    "addTab",
    "addWidget",
    "add_subplot",
    "draw",
    "setAlignment",
    "setStyleSheet",
    "set_title",
    "text"
  ],
  "chatterbox_gui:ChatterboxMainWindow.setup_analyzer_autofix_tab": [
    "NoScrollSpinBox",
    "QCheckBox",
    "QFont",
    "QGroupBox",
    "QHBoxLayout",
    "QLabel",
    "QProgressBar",
    "QPushButton",
    "QScrollArea",
    "QVBoxLayout",
    "QWidget",
    "addLayout",
    "addStretch",
    "addTab",
    "addWidget",
    "connect",
    "setAlignment",
    "setChecked",
    "setEnabled",
    "setFont",
    "setLayout",
    "setRange",
    "setStyleSheet",
    "setToolTip",
    "setValue",
    "setVisible",
    "setWidget",
    "setWidgetResizable",
    "setWordWrap"
  ],
  "chatterbox_gui:ChatterboxMainWindow.add_analyzer_files": [
    "Path",
    "QListWidgetItem",
    "addItem",
    "getOpenFileNames",
    "len",
    "log_output",
    "setData",
    "setToolTip",
    "update_analyzer_ui_state"
  ],
  "chatterbox_gui:ChatterboxMainWindow.remove_analyzer_file": [
    "Path",
    "clear_analyzer_displays",
    "currentItem",
    "currentRow",
    "data",
    "takeItem",
    "update_analyzer_ui_state"
  ],
  "chatterbox_gui:ChatterboxMainWindow.clear_analyzer_files": [
    "clear",
    "clear_analyzer_displays",
    "update_analyzer_ui_state"
  ],
  "chatterbox_gui:ChatterboxMainWindow.on_analyzer_file_selected": [
    "Path",
    "data",
    "update_analyzer_result_display",
    "update_analyzer_ui_state"
  ],
  "chatterbox_gui:ChatterboxMainWindow.analyze_selected_voice": [
    "currentItem",
    "data",
    "start_voice_analysis",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.analyze_all_voices": [
    "append",
    "count",
    "data",
    "item",
    "range",
    "start_voice_analysis",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.start_voice_analysis": [
    "Path",
    "analyze_voice_sample",
    "append",
    "currentItem",
    "data",
    "enumerate",
    "isChecked",
    "len",
    "log_output",
    "setEnabled",
    "setRange",
    "setText",
    "setValue",
    "setVisible",
    "str",
    "update_analyzer_result_display",
    "update_analyzer_ui_state"
  ],
  "chatterbox_gui:ChatterboxMainWindow.update_analyzer_result_display": [
    "addWidget",
    "clear_analyzer_scores_grid",
    "create_score_widget",
    "enumerate",
    "len",
    "setStyleSheet",
    "setText",
    "update_analyzer_comparison_plot",
    "update_analyzer_visualization"
  ],
  "chatterbox_gui:ChatterboxMainWindow.create_score_widget": [
    "QFont",
    "QLabel",
    "QVBoxLayout",
    "QWidget",
    "addWidget",
    "setAlignment",
    "setFont",
    "setStyleSheet",
    "setWordWrap"
  ],
  "chatterbox_gui:ChatterboxMainWindow.clear_analyzer_scores_grid": [
    "count",
    "deleteLater",
    "takeAt",
    "widget"
  ],
  "chatterbox_gui:ChatterboxMainWindow.clear_analyzer_displays": [
    "clear_analyzer_scores_grid",
    "setStyleSheet",
    "setText"
  ],
  "chatterbox_gui:ChatterboxMainWindow.update_analyzer_ui_state": [
    "count",
    "currentItem",
    "len",
    "setEnabled"
  ],
  "chatterbox_gui:ChatterboxMainWindow.select_all_analyzer_fixes": [
    "setChecked"
  ],
  "chatterbox_gui:ChatterboxMainWindow.select_recommended_analyzer_fixes": [
    "clear_all_analyzer_fixes",
    "information",
    "log_output",
    "setChecked"
  ],
  "chatterbox_gui:ChatterboxMainWindow.clear_all_analyzer_fixes": [
    "setChecked"
  ],
  "chatterbox_gui:ChatterboxMainWindow.update_analyzer_fix_ui_state": [
    "any",
    "currentItem",
    "isChecked",
    "setEnabled",
    "setText",
    "sum"
  ],
  "chatterbox_gui:ChatterboxMainWindow.apply_analyzer_fixes": [
    "Path",
    "QListWidgetItem",
    "abs",
    "addItem",
    "analyze_selected_voice",
    "append",
    "critical",
    "currentItem",
    "data",
    "get",
    "getSaveFileName",
    "information",
    "isChecked",
    "isinstance",
    "items",
    "len",
    "log_output",
    "process_voice_sample",
    "question",
    "setCurrentItem",
    "setData",
    "setRange",
    "setText",
    "setToolTip",
    "setVisible",
    "str",
    "value",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.apply_analyzer_fixes.progress_callback": [
    "setText"
  ],
  "chatterbox_gui:ChatterboxMainWindow.export_analyzer_plot": [
    "Path",
    "critical",
    "getSaveFileName",
    "hasattr",
    "information",
    "log_output",
    "savefig",
    "str",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.export_analyzer_report": [
    "Path",
    "create_summary_report",
    "critical",
    "getSaveFileName",
    "information",
    "log_output",
    "open",
    "str",
    "warning",
    "write"
  ],
  "chatterbox_gui:ChatterboxMainWindow.update_analyzer_visualization": [
    "add_subplot",
    "axhline",
    "bar",
    "clear",
    "draw",
    "get_height",
    "get_width",
    "get_x",
    "get_xticklabels",
    "grid",
    "hasattr",
    "legend",
    "set_title",
    "set_ylabel",
    "set_ylim",
    "setp",
    "str",
    "text",
    "tight_layout",
    "zip"
  ],
  "chatterbox_gui:ChatterboxMainWindow.update_analyzer_comparison_plot": [
    "add_subplot",
    "arange",
    "axhline",
    "bar",
    "clear",
    "draw",
    "enumerate",
    "get_height",
    "get_width",
    "get_x",
    "grid",
    "hasattr",
    "legend",
    "len",
    "range",
    "set_title",
    "set_xticklabels",
    "set_xticks",
    "set_ylabel",
    "set_ylim",
    "str",
    "text",
    "tight_layout",
    "zip"
  ],
  "chatterbox_gui:ChatterboxMainWindow.create_audio_output_analyzer_tab": [
    "QCheckBox",
    "QFont",
    "QGridLayout",
    "QGroupBox",
    "QHBoxLayout",
    "QLabel",
    "QListWidget",
    "QProgressBar",
    "QPushButton",
    "QSplitter",
    "QTabWidget",
    "QVBoxLayout",
    "QWidget",
    "addLayout",
    "addStretch",
    "addTab",
    "addWidget",
    "connect",
    "setAlignment",
    "setChecked",
    "setEnabled",
    "setFont",
    "setMaximumWidth",
    "setSizes",
    "setStyleSheet",
    "setToolTip",
    "setVisible",
    "setWordWrap",
    "setup_output_chapter_tab",
    "setup_output_comparison_tab",
    "setup_output_quality_tab",
    "setup_output_standards_tab",
    "setup_output_technical_tab",
    "update_output_analyzer_ui_state"
  ],
  "chatterbox_gui:ChatterboxMainWindow.setup_output_quality_tab": [
    "QFont",
    "QGridLayout",
    "QLabel",
    "QScrollArea",
    "QVBoxLayout",
    "QWidget",
    "addTab",
    "addWidget",
    "setAlignment",
    "setFont",
    "setStyleSheet",
    "setWidget",
    "setWidgetResizable"
  ],
  "chatterbox_gui:ChatterboxMainWindow.setup_output_technical_tab": [
    "QFont",
    "QTextEdit",
    "QVBoxLayout",
    "QWidget",
    "addTab",
    "addWidget",
    "setFont",
    "setReadOnly",
    "setText"
  ],
  "chatterbox_gui:ChatterboxMainWindow.setup_output_standards_tab": [
    "QFont",
    "QTextEdit",
    "QVBoxLayout",
    "QWidget",
    "addTab",
    "addWidget",
    "setFont",
    "setReadOnly",
    "setText"
  ],
  "chatterbox_gui:ChatterboxMainWindow.setup_output_chapter_tab": [
    "QFont",
    "QTextEdit",
    "QVBoxLayout",
    "QWidget",
    "addTab",
    "addWidget",
    "setFont",
    "setReadOnly",
    "setText"
  ],
  "chatterbox_gui:ChatterboxMainWindow.setup_output_comparison_tab": [
    "Figure",
    "FigureCanvas",
    "QLabel",
    "QVBoxLayout",
    "QWidget",
    "addTab",
    "addWidget",
    "add_subplot",
    "draw",
    "setAlignment",
    "setStyleSheet",
    "set_title",
    "text"
  ],
  "chatterbox_gui:ChatterboxMainWindow.add_output_files": [
    "Path",
    "QListWidgetItem",
    "addItem",
    "getOpenFileNames",
    "len",
    "log_output",
    "setData",
    "setToolTip",
    "update_output_analyzer_ui_state"
  ],
  "chatterbox_gui:ChatterboxMainWindow.remove_output_file": [
    "Path",
    "clear_output_displays",
    "currentItem",
    "currentRow",
    "data",
    "takeItem",
    "update_output_analyzer_ui_state"
  ],
  "chatterbox_gui:ChatterboxMainWindow.clear_output_files": [
    "clear",
    "clear_output_displays",
    "update_output_analyzer_ui_state"
  ],
  "chatterbox_gui:ChatterboxMainWindow.on_output_file_selected": [
    "Path",
    "data",
    "update_output_analyzer_ui_state",
    "update_output_result_display"
  ],
  "chatterbox_gui:ChatterboxMainWindow.analyze_selected_output": [
    "currentItem",
    "data",
    "start_output_analysis",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.analyze_all_outputs": [
    "append",
    "count",
    "data",
    "item",
    "range",
    "start_output_analysis",
    "warning"
  ],
  "chatterbox_gui:ChatterboxMainWindow.start_output_analysis": [
    "Path",
    "analyze_audiobook_file",
    "append",
    "currentItem",
    "data",
    "enumerate",
    "hasattr",
    "len",
    "log_output",
    "setEnabled",
    "setRange",
    "setText",
    "setValue",
    "setVisible",
    "str",
    "update_output_analyzer_ui_state",
    "update_output_comparison_plot",
    "update_output_result_display"
  ],
  "chatterbox_gui:ChatterboxMainWindow.analyze_audiobook_file": [
    "Path",
    "abs",
    "append",
    "estimate_bitrate",
    "fft",
    "fftfreq",
    "getsize",
    "int",
    "len",
    "load",
    "log10",
    "lower",
    "max",
    "mean",
    "range",
    "sort",
    "sqrt",
    "std",
    "str",
    "sum"
  ],
  "chatterbox_gui:ChatterboxMainWindow.estimate_bitrate": [
    "getsize",
    "int"
  ],
  "chatterbox_gui:ChatterboxMainWindow.update_output_result_display": [
    "addWidget",
    "append",
    "clear_output_quality_grid",
    "create_output_score_widget",
    "enumerate",
    "int",
    "setStyleSheet",
    "setText",
    "upper"
  ],
  "chatterbox_gui:ChatterboxMainWindow.create_output_score_widget": [
    "QFont",
    "QLabel",
    "QVBoxLayout",
    "QWidget",
    "addWidget",
    "setAlignment",
    "setFont",
    "setStyleSheet",
    "setWordWrap"
  ],
  "chatterbox_gui:ChatterboxMainWindow.clear_output_quality_grid": [
    "count",
    "deleteLater",
    "takeAt",
    "widget"
  ],
  "chatterbox_gui:ChatterboxMainWindow.clear_output_displays": [
    "clear_output_quality_grid",
    "setStyleSheet",
    "setText"
  ],
  "chatterbox_gui:ChatterboxMainWindow.update_output_comparison_plot": [
    "add_subplot",
    "arange",
    "axhline",
    "bar",
    "clear",
    "draw",
    "enumerate",
    "get_height",
    "get_width",
    "get_x",
    "grid",
    "hasattr",
    "legend",
    "len",
    "range",
    "set_title",
    "set_xticklabels",
    "set_xticks",
    "set_ylabel",
    "set_ylim",
    "str",
    "text",
    "tight_layout",
    "zip"
  ],
  "chatterbox_gui:ChatterboxMainWindow.update_output_analyzer_ui_state": [
    "count",
    "currentItem",
    "len",
    "setEnabled"
  ],
  "chatterbox_gui:ChatterboxMainWindow.export_output_report": [
    "Path",
    "critical",
    "getSaveFileName",
    "information",
    "int",
    "isinstance",
    "items",
    "log_output",
    "open",
    "replace",
    "str",
    "title",
    "upper",
    "warning",
    "write"
  ],
  "chatterbox_gui:ChatterboxMainWindow.export_output_plot": [
    "Path",
    "critical",
    "getSaveFileName",
    "hasattr",
    "information",
    "log_output",
    "savefig",
    "str",
    "warning"
  ],
  "chatterbox_gui:main": [
    "ChatterboxMainWindow",
    "QApplication",
    "exec_",
    "exit",
    "setStyle",
    "show"
  ],
  "start:prompt_menu": [
    "enumerate",
    "input",
    "int",
    "isdigit",
    "len",
    "print",
    "strip"
  ],
  "start:wrapper_main": [
    "main",
    "main_with_resume",
    "prompt_menu",
    "run_chunk_repair_tool",
    "run_combine_only_mode",
    "test_chunking"
  ],
  "start:<module>": [
    "wrapper_main"
  ],
  "utils.generate_from_json:<module>": [
    "Path",
    "append",
    "main",
    "str"
  ],
  "utils.generate_from_json:main": [
    "Path",
    "ThreadPoolExecutor",
    "append",
    "as_completed",
    "ensure_voice_sample_compatibility",
    "enumerate",
    "exists",
    "get",
    "glob",
    "input",
    "int",
    "is_available",
    "len",
    "list_voice_samples",
    "load_chunks",
    "load_optimized_model",
    "log_chunk_progress",
    "prepare_conditionals",
    "print",
    "result",
    "setup_book_directories",
    "str",
    "strip",
    "submit",
    "time",
    "timedelta",
    "unlink"
  ],
  "gradio_tabs.tab6_settings:<module>": [
    "print"
  ],
  "gradio_tabs.tab6_settings:ConfigManager.__init__": [
    "Path",
    "load_current_config"
  ],
  "gradio_tabs.tab6_settings:ConfigManager.load_current_config": [
    "dir",
    "getattr",
    "isinstance",
    "startswith"
  ],
  "gradio_tabs.tab6_settings:ConfigManager.reload_config": [
    "load_current_config",
    "reload",
    "str"
  ],
  "gradio_tabs.tab6_settings:ConfigManager.save_config_value": [
    "hasattr",
    "setattr",
    "str"
  ],
  "gradio_tabs.tab6_settings:ConfigManager.get_config_categories": [
    "any",
    "append",
    "items",
    "keys",
    "lower"
  ],
  "gradio_tabs.tab6_settings:create_config_editor": [
    "Accordion",
    "Button",
    "Checkbox",
    "Column",
    "Markdown",
    "Number",
    "Textbox",
    "click",
    "get",
    "get_config_categories",
    "isinstance",
    "items",
    "list",
    "str",
    "values"
  ],
  "gradio_tabs.tab6_settings:create_config_editor.reload_config": [
    "get",
    "items",
    "reload_config",
    "update",
    "values"
  ],
  "gradio_tabs.tab6_settings:create_config_editor.save_all_changes": [
    "append",
    "enumerate",
    "items",
    "join",
    "save_config_value"
  ],
  "gradio_tabs.tab6_settings:create_config_backup": [
    "Button",
    "Column",
    "File",
    "Markdown",
    "Row",
    "Textbox",
    "click"
  ],
  "gradio_tabs.tab6_settings:create_config_backup.create_backup": [
    "Path",
    "dir",
    "dump",
    "getattr",
    "isinstance",
    "open",
    "startswith",
    "str"
  ],
  "gradio_tabs.tab6_settings:create_config_backup.restore_backup": [
    "hasattr",
    "items",
    "load",
    "open",
    "setattr",
    "str"
  ],
  "gradio_tabs.tab6_settings:create_chunking_test": [
    "Button",
    "Column",
    "Markdown",
    "Row",
    "Slider",
    "Textbox",
    "click"
  ],
  "gradio_tabs.tab6_settings:create_chunking_test.run_chunking_test": [
    "StringIO",
    "getvalue",
    "redirect_stdout",
    "str",
    "strip",
    "test_chunking"
  ],
  "gradio_tabs.tab6_settings:create_system_info": [
    "Button",
    "Column",
    "Markdown",
    "click",
    "get_system_info"
  ],
  "gradio_tabs.tab6_settings:create_system_info.get_system_info": [
    "Path",
    "append",
    "dir",
    "exists",
    "getcwd",
    "join",
    "len",
    "split",
    "startswith"
  ],
  "gradio_tabs.tab6_settings:create_settings_tab": [
    "Column",
    "ConfigManager",
    "Markdown",
    "Tab",
    "Tabs",
    "create_chunking_test",
    "create_config_backup",
    "create_config_editor",
    "create_system_info"
  ],
  "gradio_tabs.tab6_settings:create_settings_tab_interface": [
    "create_settings_tab"
  ],
  "gradio_tabs.tab8_json_generate:<module>": [
    "Blocks",
    "create_json_generate_tab",
    "launch",
    "print"
  ],
  "gradio_tabs.tab8_json_generate:generate_audiobook_from_json": [
    "ImportError"
  ],
  "gradio_tabs.tab8_json_generate:list_voice_samples": [
    "ImportError"
  ],
  "gradio_tabs.tab8_json_generate:get_available_json_files": [
    "Path",
    "any",
    "append",
    "exists",
    "glob",
    "is_dir",
    "iterdir",
    "len",
    "load",
    "open",
    "replace",
    "sorted",
    "str"
  ],
  "gradio_tabs.tab8_json_generate:get_available_voices": [
    "append",
    "list_voice_samples",
    "print",
    "sorted",
    "str"
  ],
  "gradio_tabs.tab8_json_generate:load_json_file_info": [
    "Path",
    "exists",
    "get",
    "get_available_json_files",
    "glob",
    "int",
    "len",
    "list",
    "load",
    "open",
    "split",
    "str",
    "sum"
  ],
  "gradio_tabs.tab8_json_generate:start_json_generation": [
    "Thread",
    "get_available_json_files",
    "get_available_voices",
    "start",
    "str"
  ],
  "gradio_tabs.tab8_json_generate:start_json_generation.generation_worker": [
    "generate_audiobook_from_json",
    "str"
  ],
  "gradio_tabs.tab8_json_generate:get_generation_status": [
    "get"
  ],
  "gradio_tabs.tab8_json_generate:stop_json_generation": [
    "get"
  ],
  "gradio_tabs.tab8_json_generate:play_audio": [
    "Path",
    "exists",
    "get",
    "isinstance",
    "str"
  ],
  "gradio_tabs.tab8_json_generate:create_json_generate_tab": [
    "Button",
    "Column",
    "Dropdown",
    "Markdown",
    "Row",
    "Slider",
    "Textbox",
    "change",
    "click",
    "get_available_json_files",
    "get_available_voices"
  ],
  "gradio_tabs.tab8_json_generate:create_json_generate_tab.refresh_json_files": [
    "get_available_json_files",
    "update"
  ],
  "gradio_tabs.tab8_json_generate:create_json_generate_tab.refresh_voice_list": [
    "get_available_voices",
    "update"
  ],
  "gradio_tabs.tab2_configuration:<module>": [
    "Blocks",
    "Path",
    "create_configuration_tab",
    "launch"
  ],
  "gradio_tabs.tab2_configuration:_get_literal": [
    "escape",
    "group",
    "literal_eval",
    "search",
    "strip"
  ],
  "gradio_tabs.tab2_configuration:_load_config_from_file": [
    "_get_literal",
    "read_text",
    "tuple",
    "v"
  ],
  "gradio_tabs.tab2_configuration:_atomic_write_with_backup": [
    "NamedTemporaryFile",
    "copy2",
    "now",
    "replace",
    "str",
    "strftime",
    "with_suffix",
    "write"
  ],
  "gradio_tabs.tab2_configuration:_patch_config": [
    "compile",
    "enumerate",
    "escape",
    "groups",
    "isinstance",
    "items",
    "join",
    "lstrip",
    "match",
    "read_text",
    "repr",
    "splitlines",
    "startswith",
    "str"
  ],
  "gradio_tabs.tab2_configuration:create_configuration_tab": [
    "Button",
    "Checkbox",
    "Column",
    "Markdown",
    "Row",
    "Slider",
    "Textbox",
    "click",
    "field_value_from_file"
  ],
  "gradio_tabs.tab2_configuration:create_configuration_tab.save_configuration": [
    "_atomic_write_with_backup",
    "_patch_config",
    "bool",
    "exists",
    "float",
    "format_exc",
    "int",
    "reload"
  ],
  "gradio_tabs.tab2_configuration:create_configuration_tab.reload_configuration": [
    "_load_config_from_file"
  ],
  "gradio_tabs.tab2_configuration:create_configuration_tab.reset_configuration": [
    "_load_config_from_file"
  ],
  "gradio_tabs.tab2_configuration:create_configuration_tab.field_value_from_file": [
    "_load_config_from_file"
  ],
  "gradio_tabs.tab4_combine_audio:<module>": [
    "Blocks",
    "create_combine_audio_tab",
    "launch",
    "print"
  ],
  "gradio_tabs.tab4_combine_audio:combine_audio_for_book": [
    "ImportError"
  ],
  "gradio_tabs.tab4_combine_audio:get_audio_files_in_directory": [
    "ImportError"
  ],
  "gradio_tabs.tab4_combine_audio:get_wav_duration": [
    "ImportError"
  ],
  "gradio_tabs.tab4_combine_audio:get_available_books": [
    "Path",
    "append",
    "exists",
    "get_wav_duration",
    "glob",
    "int",
    "is_dir",
    "iterdir",
    "len",
    "list",
    "sorted",
    "str",
    "sum"
  ],
  "gradio_tabs.tab4_combine_audio:get_book_info": [
    "Path",
    "append",
    "exists",
    "get_audio_files_in_directory",
    "get_wav_duration",
    "int",
    "join",
    "len",
    "stat",
    "str",
    "sum"
  ],
  "gradio_tabs.tab4_combine_audio:run_combine_operation": [
    "Path",
    "combine_audio_for_book",
    "print",
    "str"
  ],
  "gradio_tabs.tab4_combine_audio:create_combine_audio_tab": [
    "Button",
    "Column",
    "Dropdown",
    "Markdown",
    "Number",
    "Row",
    "Textbox",
    "change",
    "click",
    "get_available_books"
  ],
  "gradio_tabs.tab4_combine_audio:create_combine_audio_tab.update_book_info": [
    "get_book_info"
  ],
  "gradio_tabs.tab4_combine_audio:create_combine_audio_tab.refresh_book_list": [
    "get_available_books",
    "update"
  ],
  "gradio_tabs.tab4_combine_audio:create_combine_audio_tab.get_selected_book_path": [
    "strip"
  ],
  "gradio_tabs.tab4_combine_audio:create_combine_audio_tab.start_combine_operation": [
    "Path",
    "Thread",
    "get",
    "get_selected_book_path",
    "start",
    "str",
    "update"
  ],
  "gradio_tabs.tab4_combine_audio:create_combine_audio_tab.start_combine_operation.run_combine_thread": [
    "Path",
    "append",
    "exists",
    "get",
    "join",
    "run_combine_operation",
    "stat",
    "str",
    "strip",
    "time"
  ],
  "gradio_tabs.tab4_combine_audio:create_combine_audio_tab.stop_combine_operation": [
    "get",
    "update"
  ],
  "gradio_tabs.tab4_combine_audio:create_combine_audio_tab.get_current_status": [
    "get",
    "int",
    "time",
    "update"
  ],
  "gradio_tabs.tab7_chunk_tools:<module>": [
    "Blocks",
    "create_chunk_tools_tab",
    "launch",
    "print"
  ],
  "gradio_tabs.tab7_chunk_tools:load_chunks": [
    "ImportError"
  ],
  "gradio_tabs.tab7_chunk_tools:save_chunks": [
    "ImportError"
  ],
  "gradio_tabs.tab7_chunk_tools:search_chunks": [
    "ImportError"
  ],
  "gradio_tabs.tab7_chunk_tools:update_chunk": [
    "ImportError"
  ],
  "gradio_tabs.tab7_chunk_tools:play_chunk_audio": [
    "ImportError"
  ],
  "gradio_tabs.tab7_chunk_tools:synthesize_chunk": [
    "ImportError"
  ],
  "gradio_tabs.tab7_chunk_tools:accept_revision": [
    "ImportError"
  ],
  "gradio_tabs.tab7_chunk_tools:get_likely_voices_for_book": [
    "ImportError"
  ],
  "gradio_tabs.tab7_chunk_tools:get_available_repair_books": [
    "Path",
    "any",
    "append",
    "exists",
    "glob",
    "is_dir",
    "iterdir",
    "len",
    "load",
    "open",
    "replace",
    "sorted",
    "str"
  ],
  "gradio_tabs.tab7_chunk_tools:load_book_chunks": [
    "Path",
    "append",
    "enumerate",
    "get_available_repair_books",
    "get_likely_voices_for_book",
    "len",
    "load_chunks",
    "str"
  ],
  "gradio_tabs.tab7_chunk_tools:search_for_chunks": [
    "append",
    "len",
    "search_chunks",
    "str",
    "strip",
    "update"
  ],
  "gradio_tabs.tab7_chunk_tools:select_chunk_for_editing": [
    "get",
    "int",
    "split",
    "str"
  ],
  "gradio_tabs.tab7_chunk_tools:save_chunk_changes": [
    "len",
    "save_chunks",
    "split",
    "str",
    "strip"
  ],
  "gradio_tabs.tab7_chunk_tools:play_original_audio": [
    "Thread",
    "exists",
    "start",
    "str"
  ],
  "gradio_tabs.tab7_chunk_tools:play_original_audio.play_audio": [
    "play_chunk_audio",
    "print",
    "str"
  ],
  "gradio_tabs.tab7_chunk_tools:resynthesize_chunk_audio": [
    "Thread",
    "start",
    "str",
    "strip"
  ],
  "gradio_tabs.tab7_chunk_tools:resynthesize_chunk_audio.resynth_worker": [
    "print",
    "str",
    "synthesize_chunk"
  ],
  "gradio_tabs.tab7_chunk_tools:play_revised_audio": [
    "Thread",
    "exists",
    "start",
    "str"
  ],
  "gradio_tabs.tab7_chunk_tools:play_revised_audio.play_audio": [
    "play_chunk_audio",
    "print",
    "str"
  ],
  "gradio_tabs.tab7_chunk_tools:accept_chunk_revision": [
    "accept_revision",
    "str"
  ],
  "gradio_tabs.tab7_chunk_tools:create_chunk_tools_tab": [
    "Button",
    "Column",
    "Dropdown",
    "Markdown",
    "Row",
    "Slider",
    "Textbox",
    "change",
    "click",
    "get_available_repair_books",
    "submit"
  ],
  "gradio_tabs.tab7_chunk_tools:create_chunk_tools_tab.refresh_book_list": [
    "get_available_repair_books",
    "update"
  ],
  "gradio_tabs.tab7_chunk_tools:create_chunk_tools_tab.refresh_voice_candidates": [
    "append",
    "get_likely_voices_for_book",
    "len",
    "str",
    "update"
  ],
  "gradio_tabs.tab1_convert_book:<module>": [
    "Blocks",
    "create_convert_book_tab",
    "filterwarnings",
    "launch",
    "module_from_spec",
    "print",
    "spec_from_file_location"
  ],
  "gradio_tabs.tab1_convert_book:parse_progress_stats": [
    "group",
    "int",
    "print",
    "search"
  ],
  "gradio_tabs.tab1_convert_book:get_book_folders": [
    "Path",
    "append",
    "exists",
    "is_dir",
    "iterdir",
    "sorted"
  ],
  "gradio_tabs.tab1_convert_book:get_text_files_in_folder": [
    "Path",
    "append",
    "exists",
    "glob",
    "sorted"
  ],
  "gradio_tabs.tab1_convert_book:get_voice_samples": [
    "Path",
    "append",
    "exists",
    "glob",
    "sorted"
  ],
  "gradio_tabs.tab1_convert_book:find_generated_audiobook": [
    "Path",
    "exists",
    "glob",
    "print",
    "str",
    "upper"
  ],
  "gradio_tabs.tab1_convert_book:run_book_conversion": [
    "Path",
    "get",
    "get_best_available_device",
    "print",
    "print_exc",
    "process_book_folder",
    "str",
    "upper"
  ],
  "gradio_tabs.tab1_convert_book:run_book_conversion.progress_callback": [
    "int",
    "print"
  ],
  "gradio_tabs.tab1_convert_book:regenerate_m4b_file": [
    "Path",
    "add_metadata_to_m4b",
    "convert_to_m4b",
    "exists",
    "glob",
    "is_dir",
    "iterdir",
    "print",
    "replace",
    "str",
    "unlink"
  ],
  "gradio_tabs.tab1_convert_book:list_text_files": [
    "Path",
    "glob",
    "is_dir",
    "update"
  ],
  "gradio_tabs.tab1_convert_book:play_voice_sample": [
    "Path",
    "exists",
    "get_busy",
    "init",
    "load",
    "play",
    "print",
    "sleep"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab": [
    "Audio",
    "Button",
    "Checkbox",
    "Column",
    "Dropdown",
    "File",
    "Markdown",
    "Number",
    "Radio",
    "Row",
    "Slider",
    "Textbox",
    "WaveformOptions",
    "change",
    "click",
    "keys",
    "list"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab.handle_voice_upload": [
    "update"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab.get_session_audiobooks": [
    "Path",
    "append",
    "exists",
    "glob",
    "is_dir",
    "iterdir",
    "sort",
    "stat",
    "str"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab.update_audiobook_dropdowns": [
    "get_session_audiobooks",
    "update"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab.update_audiobook_dropdowns_after_conversion": [
    "update_audiobook_dropdowns"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab.update_playback_only": [
    "get_session_audiobooks",
    "update"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab.load_selected_audiobook": [
    "get_session_audiobooks"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab.handle_asr_toggle": [
    "update"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab.analyze_system": [
    "categorize_system",
    "get_system_profile",
    "str"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab.update_asr_models": [
    "get_system_profile",
    "recommend_asr_models",
    "str",
    "upper"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab.start_conversion": [
    "Path",
    "Thread",
    "copy2",
    "format_path_warning_text",
    "get",
    "get_system_profile",
    "mkdir",
    "now",
    "print",
    "recommend_asr_models",
    "replace",
    "start",
    "str",
    "strftime",
    "update",
    "validate_book_path"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab.start_conversion.run_conversion_thread": [
    "get",
    "run_book_conversion",
    "str"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab.handle_m4b_regeneration": [
    "Path",
    "load_selected_audiobook",
    "regenerate_m4b_file",
    "update",
    "update_playback_only"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab.apply_preset": [
    "get",
    "update"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab.get_current_stats": [
    "Path",
    "exists",
    "get",
    "glob",
    "int",
    "len",
    "list",
    "load",
    "open",
    "print"
  ],
  "gradio_tabs.tab1_convert_book:create_convert_book_tab.get_status_and_results": [
    "load_selected_audiobook",
    "update",
    "update_audiobook_dropdowns_after_conversion"
  ],
  "gradio_tabs.tab5_prepare_text:<module>": [
    "Blocks",
    "create_prepare_text_tab",
    "launch",
    "print"
  ],
  "gradio_tabs.tab5_prepare_text:generate_enriched_chunks": [
    "ImportError"
  ],
  "gradio_tabs.tab5_prepare_text:get_available_text_files": [
    "Path",
    "append",
    "exists",
    "glob",
    "globals",
    "is_dir",
    "iterdir",
    "sorted",
    "stat",
    "str"
  ],
  "gradio_tabs.tab5_prepare_text:load_text_file_info": [
    "Path",
    "exists",
    "get_available_text_files",
    "len",
    "load",
    "max",
    "open",
    "read",
    "split",
    "splitlines",
    "str",
    "strip"
  ],
  "gradio_tabs.tab5_prepare_text:start_text_preparation": [
    "Thread",
    "get_available_text_files",
    "start",
    "str"
  ],
  "gradio_tabs.tab5_prepare_text:start_text_preparation.preparation_worker": [
    "Path",
    "format_path_warning_text",
    "generate_enriched_chunks",
    "int",
    "len",
    "mkdir",
    "str",
    "validate_book_path"
  ],
  "gradio_tabs.tab5_prepare_text:get_preparation_status": [
    "get"
  ],
  "gradio_tabs.tab5_prepare_text:stop_text_preparation": [
    "get"
  ],
  "gradio_tabs.tab5_prepare_text:create_prepare_text_tab": [
    "Button",
    "Checkbox",
    "Column",
    "Dropdown",
    "Markdown",
    "Row",
    "Slider",
    "Textbox",
    "change",
    "click",
    "get_available_text_files",
    "then",
    "update"
  ],
  "gradio_tabs.tab5_prepare_text:create_prepare_text_tab.refresh_file_list": [
    "get_available_text_files",
    "update"
  ],
  "scripts.make_backup:make_backup": [
    "ZipFile",
    "add_path",
    "exists",
    "now",
    "print"
  ],
  "scripts.make_backup:make_backup.add_path": [
    "is_dir",
    "is_file",
    "relative_to",
    "rglob",
    "str",
    "write"
  ],
  "scripts.make_backup:main": [
    "ArgumentParser",
    "Path",
    "add_argument",
    "make_backup",
    "parse_args",
    "resolve"
  ],
  "scripts.make_backup:<module>": [
    "main"
  ],
  "Voice_Samples.mel:process_audio_file": [
    "len",
    "load",
    "print",
    "splitext",
    "write"
  ],
  "Voice_Samples.mel:main": [
    "append",
    "endswith",
    "enumerate",
    "exists",
    "exit",
    "export",
    "from_mp3",
    "input",
    "int",
    "len",
    "listdir",
    "lower",
    "print",
    "process_audio_file",
    "remove",
    "splitext"
  ],
  "Voice_Samples.mel:<module>": [
    "main"
  ],
  "wrapper.chunk_revisions:accept_revision": [
    "Path",
    "exists",
    "mkdir",
    "move",
    "print",
    "str"
  ],
  "wrapper.chunk_synthesizer:get_original_voice_from_log": [
    "Path",
    "exists",
    "open",
    "print",
    "split",
    "startswith",
    "strip"
  ],
  "wrapper.chunk_synthesizer:get_original_voice_from_filename": [
    "Path",
    "glob",
    "group",
    "print",
    "search"
  ],
  "wrapper.chunk_synthesizer:find_voice_file_by_name": [
    "list_voice_samples",
    "lower",
    "print"
  ],
  "wrapper.chunk_synthesizer:get_tts_params_for_chunk": [
    "get",
    "get_float_input",
    "print"
  ],
  "wrapper.chunk_synthesizer:get_tts_params_for_chunk.get_float_input": [
    "float",
    "input",
    "print",
    "strip"
  ],
  "wrapper.chunk_synthesizer:synthesize_chunk": [
    "BytesIO",
    "Path",
    "apply_smart_fade_memory",
    "cpu",
    "detach",
    "detect_voice_for_book",
    "dim",
    "empty_cache",
    "ensure_voice_sample_compatibility",
    "export",
    "find_voice_file_by_name",
    "from_wav",
    "generate",
    "get",
    "get_tts_params_for_chunk",
    "is_available",
    "list_voice_samples",
    "load_optimized_model",
    "no_grad",
    "numpy",
    "prewarm_model_with_voice",
    "print",
    "print_exc",
    "process_audio_with_trimming_and_silence",
    "seek",
    "smart_audio_validation_memory",
    "squeeze",
    "str",
    "trim_audio_endpoint",
    "unsqueeze",
    "write"
  ],
  "wrapper.chunk_tool:select_book_for_repair": [
    "Path",
    "any",
    "append",
    "enumerate",
    "exists",
    "glob",
    "input",
    "int",
    "is_dir",
    "iterdir",
    "len",
    "print",
    "replace",
    "strip"
  ],
  "wrapper.chunk_tool:run_chunk_repair_tool": [
    "Path",
    "accept_revision",
    "enumerate",
    "exists",
    "float",
    "get",
    "get_float_input",
    "input",
    "int",
    "isdigit",
    "len",
    "load_chunks",
    "lower",
    "play_chunk_audio",
    "print",
    "save_chunks",
    "search_chunks",
    "select_book_for_repair",
    "split",
    "str",
    "strip",
    "synthesize_chunk"
  ],
  "wrapper.chunk_tool:run_chunk_repair_tool.get_float_input": [
    "float",
    "input",
    "print",
    "strip"
  ],
  "wrapper.chunk_search:search_chunks": [
    "append",
    "lower"
  ],
  "wrapper.chunk_loader:load_chunks": [
    "get",
    "isinstance",
    "load",
    "open"
  ],
  "wrapper.chunk_loader:load_metadata": [
    "get",
    "isinstance",
    "load",
    "open",
    "print"
  ],
  "wrapper.chunk_loader:save_chunks": [
    "OrderedDict",
    "append",
    "copy",
    "deepcopy",
    "dump",
    "isinstance",
    "items",
    "open",
    "print",
    "replace",
    "sub"
  ],
  "wrapper.chunk_player:play_chunk_audio": [
    "exists",
    "print",
    "run"
  ],
  "tools.ort_gpu_diagnose:print_header": [
    "print"
  ],
  "tools.ort_gpu_diagnose:find_shadowing_modules": [
    "append",
    "join",
    "startswith",
    "walk"
  ],
  "tools.ort_gpu_diagnose:show_python_env": [
    "get",
    "getsitepackages",
    "next",
    "print",
    "print_header",
    "replace"
  ],
  "tools.ort_gpu_diagnose:show_shadowing": [
    "abspath",
    "append",
    "commonpath",
    "find_shadowing_modules",
    "get",
    "getcwd",
    "print",
    "print_header"
  ],
  "tools.ort_gpu_diagnose:try_import_onnxruntime": [
    "find_spec",
    "get_all_providers",
    "get_available_providers",
    "getattr",
    "hasattr",
    "print",
    "print_header",
    "repr"
  ],
  "tools.ort_gpu_diagnose:try_torch_cuda": [
    "device_count",
    "get_device_name",
    "getattr",
    "is_available",
    "print",
    "print_header",
    "repr"
  ],
  "tools.ort_gpu_diagnose:try_nvidia_smi": [
    "check_output",
    "enumerate",
    "len",
    "print",
    "print_header",
    "repr",
    "splitlines",
    "which"
  ],
  "tools.ort_gpu_diagnose:maybe_run_onnx_test": [
    "append",
    "dirname",
    "join",
    "print",
    "print_header",
    "run",
    "str"
  ],
  "tools.ort_gpu_diagnose:print_next_steps_hint": [
    "dedent",
    "print",
    "print_header",
    "strip"
  ],
  "tools.ort_gpu_diagnose:main": [
    "ArgumentParser",
    "add_argument",
    "maybe_run_onnx_test",
    "parse_args",
    "print_next_steps_hint",
    "show_python_env",
    "show_shadowing",
    "try_import_onnxruntime",
    "try_nvidia_smi",
    "try_torch_cuda"
  ],
  "tools.ort_gpu_diagnose:<module>": [
    "SystemExit",
    "main"
  ],
  "tools.config_audit:extract_flags": [
    "add",
    "isinstance",
    "isupper",
    "parse",
    "read_text",
    "set",
    "str",
    "walk"
  ],
  "tools.config_audit:scan_usage": [
    "add",
    "any",
    "read_text",
    "relative_to",
    "rglob",
    "set",
    "str"
  ],
  "tools.config_audit:main": [
    "Path",
    "append",
    "dumps",
    "exists",
    "extract_flags",
    "get",
    "items",
    "join",
    "len",
    "list",
    "mkdir",
    "print",
    "resolve",
    "scan_usage",
    "set",
    "sorted",
    "write_text"
  ],
  "tools.config_audit:<module>": [
    "main"
  ],
  "tools.trace_pipeline_flow:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.trace_pipeline_flow:monitor_gpu": [
    "int",
    "run",
    "split",
    "strip"
  ],
  "tools.trace_pipeline_flow:trace_single_chunk_pipeline": [
    "append",
    "cat",
    "cpu",
    "detach",
    "drop_invalid_tokens",
    "inference",
    "inference_mode",
    "monitor_gpu",
    "numpy",
    "prepare_conditionals",
    "print",
    "squeeze",
    "strip",
    "sum",
    "tensor",
    "text_to_tokens",
    "time",
    "to",
    "values"
  ],
  "tools.trace_pipeline_flow:analyze_pipeline_bottlenecks": [
    "items",
    "print",
    "sort",
    "sum",
    "values"
  ],
  "tools.trace_pipeline_flow:trace_multiple_chunks": [
    "append",
    "enumerate",
    "len",
    "max",
    "min",
    "monitor_gpu",
    "print",
    "sum",
    "time",
    "trace_single_chunk_pipeline"
  ],
  "tools.trace_pipeline_flow:main": [
    "Path",
    "analyze_pipeline_bottlenecks",
    "dump",
    "exists",
    "get_device_name",
    "is_available",
    "items",
    "keys",
    "len",
    "load_optimized_model",
    "max",
    "open",
    "prewarm_model_with_voice",
    "print",
    "print_exc",
    "sorted",
    "strftime",
    "sum",
    "trace_multiple_chunks",
    "trace_single_chunk_pipeline",
    "values"
  ],
  "tools.generate_from_json:<module>": [
    "Path",
    "append",
    "main",
    "str"
  ],
  "tools.generate_from_json:main": [
    "Path",
    "ThreadPoolExecutor",
    "append",
    "as_completed",
    "ensure_voice_sample_compatibility",
    "enumerate",
    "exists",
    "get",
    "glob",
    "input",
    "int",
    "is_available",
    "len",
    "list_voice_samples",
    "load_chunks",
    "load_optimized_model",
    "log_chunk_progress",
    "prewarm_model_with_voice",
    "print",
    "result",
    "setup_book_directories",
    "str",
    "strip",
    "submit",
    "time",
    "timedelta",
    "unlink"
  ],
  "tools.spider_run:<module>": [
    "Path",
    "main",
    "resolve"
  ],
  "tools.spider_run:run": [
    "call",
    "join",
    "print"
  ],
  "tools.spider_run:main": [
    "ArgumentParser",
    "add_argument",
    "copy",
    "exists",
    "get",
    "join",
    "lower",
    "mkdir",
    "parse_args",
    "pop",
    "print",
    "run",
    "str",
    "strip",
    "unlink"
  ],
  "tools.emotion_extractor:<module>": [
    "Path",
    "exit",
    "insert",
    "main",
    "str"
  ],
  "tools.emotion_extractor:EmotionExtractor.__init__": [
    "FileNotFoundError",
    "Path",
    "exists"
  ],
  "tools.emotion_extractor:EmotionExtractor.load_chunk_data": [
    "EmotionalSegment",
    "append",
    "classify_emotion",
    "exists",
    "get",
    "len",
    "load",
    "open",
    "print",
    "str"
  ],
  "tools.emotion_extractor:EmotionExtractor.analyze_audio_quality": [
    "abs",
    "len",
    "load",
    "max",
    "mean",
    "print",
    "rms",
    "spectral_centroid",
    "zero_crossing_rate"
  ],
  "tools.emotion_extractor:EmotionExtractor.select_best_segments": [
    "analyze_audio_quality",
    "append",
    "defaultdict",
    "enumerate",
    "items",
    "len",
    "print",
    "sort"
  ],
  "tools.emotion_extractor:EmotionExtractor.select_best_segments.score_segment": [
    "abs"
  ],
  "tools.emotion_extractor:EmotionExtractor.combine_emotional_samples": [
    "Path",
    "append",
    "array",
    "extend",
    "int",
    "items",
    "len",
    "load",
    "mkdir",
    "print",
    "str",
    "write"
  ],
  "tools.emotion_extractor:EmotionExtractor.generate_sample_report": [
    "Path",
    "defaultdict",
    "enumerate",
    "items",
    "len",
    "open",
    "print",
    "sorted",
    "upper",
    "write"
  ],
  "tools.emotion_extractor:main": [
    "ArgumentParser",
    "EmotionExtractor",
    "add_argument",
    "combine_emotional_samples",
    "generate_sample_report",
    "len",
    "load_chunk_data",
    "parse_args",
    "print",
    "select_best_segments"
  ],
  "tools.measure_token_memory:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.measure_token_memory:get_memory_usage": [
    "Process",
    "memory_info",
    "virtual_memory"
  ],
  "tools.measure_token_memory:measure_tensor_size": [
    "element_size",
    "is_tensor",
    "list",
    "numel",
    "str"
  ],
  "tools.measure_token_memory:generate_test_tokens": [
    "append",
    "cat",
    "cpu",
    "drop_invalid_tokens",
    "enumerate",
    "get_memory_usage",
    "inference",
    "inference_mode",
    "len",
    "measure_tensor_size",
    "prepare_conditionals",
    "print",
    "strip",
    "tensor",
    "text_to_tokens"
  ],
  "tools.measure_token_memory:analyze_queue_capacity": [
    "append",
    "int",
    "len",
    "mean",
    "min",
    "print"
  ],
  "tools.measure_token_memory:simulate_queue_transfer_overhead": [
    "Event",
    "cuda",
    "elapsed_time",
    "empty_cache",
    "len",
    "print",
    "record",
    "synchronize"
  ],
  "tools.measure_token_memory:main": [
    "analyze_queue_capacity",
    "append",
    "dump",
    "generate_test_tokens",
    "get_device_name",
    "get_memory_usage",
    "is_available",
    "len",
    "list_voice_samples",
    "load_optimized_model",
    "open",
    "prewarm_model_with_voice",
    "print",
    "simulate_queue_transfer_overhead"
  ],
  "tools.test_sequence_batching:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.test_sequence_batching:clear_memory": [
    "collect",
    "empty_cache",
    "is_available"
  ],
  "tools.test_sequence_batching:get_test_voice": [
    "list_voice_samples"
  ],
  "tools.test_sequence_batching:create_test_chunks": [
    "append",
    "copy",
    "len",
    "range"
  ],
  "tools.test_sequence_batching:benchmark_individual_processing": [
    "append",
    "enumerate",
    "generate",
    "get",
    "len",
    "print",
    "time"
  ],
  "tools.test_sequence_batching:benchmark_sequence_batching": [
    "analyze_batching_potential",
    "create_sequence_batch_processor",
    "len",
    "print",
    "process_chunks_with_sequence_batching",
    "time"
  ],
  "tools.test_sequence_batching:compare_performance": [
    "print"
  ],
  "tools.test_sequence_batching:main": [
    "benchmark_individual_processing",
    "benchmark_sequence_batching",
    "clear_memory",
    "compare_performance",
    "create_test_chunks",
    "dump",
    "get_device_name",
    "get_test_voice",
    "is_available",
    "items",
    "len",
    "load_optimized_model",
    "open",
    "prewarm_model_with_voice",
    "print",
    "sleep",
    "str",
    "strftime"
  ],
  "tools.runtime_summarize:main": [
    "Path",
    "add",
    "dumps",
    "exists",
    "get",
    "items",
    "list",
    "loads",
    "open",
    "print",
    "resolve",
    "set",
    "sorted",
    "write_text"
  ],
  "tools.runtime_summarize:<module>": [
    "main"
  ],
  "tools.analyze_attention_implementation:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.analyze_attention_implementation:check_flash_attention_availability": [
    "int",
    "print",
    "split"
  ],
  "tools.analyze_attention_implementation:analyze_current_attention_config": [
    "getattr",
    "hasattr",
    "print",
    "type"
  ],
  "tools.analyze_attention_implementation:benchmark_attention_implementations": [
    "cat",
    "hasattr",
    "inference",
    "inference_mode",
    "prepare_conditionals",
    "print",
    "str",
    "strip",
    "tensor",
    "text_to_tokens",
    "time"
  ],
  "tools.analyze_attention_implementation:create_attention_optimization_plan": [
    "append",
    "print"
  ],
  "tools.analyze_attention_implementation:main": [
    "Path",
    "analyze_current_attention_config",
    "benchmark_attention_implementations",
    "check_flash_attention_availability",
    "create_attention_optimization_plan",
    "dump",
    "exists",
    "get_device_name",
    "is_available",
    "load_optimized_model",
    "open",
    "prewarm_model_with_voice",
    "print",
    "print_exc",
    "strftime"
  ],
  "tools.combine_only:combine_audio_for_book": [
    "Path",
    "_perform_combine_operation",
    "exists",
    "get_audio_files_in_directory",
    "get_wav_duration",
    "int",
    "len",
    "print",
    "str",
    "sum",
    "timedelta",
    "verify_chunk_sequence"
  ],
  "tools.combine_only:_perform_combine_operation": [
    "add_metadata_to_m4b",
    "combine_audio_chunks",
    "convert_to_m4b",
    "exists",
    "find_book_files",
    "int",
    "print",
    "stat",
    "str",
    "time",
    "timedelta",
    "unlink"
  ],
  "tools.combine_only:run_combine_only_mode": [
    "_perform_combine_operation",
    "enumerate",
    "exists",
    "get_audio_files_in_directory",
    "get_wav_duration",
    "glob",
    "input",
    "int",
    "is_dir",
    "iterdir",
    "len",
    "list",
    "lower",
    "print",
    "sorted",
    "str",
    "strip",
    "sum",
    "timedelta",
    "verify_chunk_sequence"
  ],
  "tools.combine_only:verify_chunk_sequence": [
    "append",
    "group",
    "int",
    "match",
    "max",
    "range",
    "sort"
  ],
  "tools.combine_only:list_available_books_for_combine": [
    "append",
    "exists",
    "get_audio_files_in_directory",
    "get_wav_duration",
    "int",
    "is_dir",
    "iterdir",
    "len",
    "str",
    "sum",
    "timedelta"
  ],
  "tools.combine_only:quick_combine": [
    "combine_audio_chunks",
    "convert_to_m4b",
    "exists",
    "get_audio_files_in_directory",
    "len",
    "print",
    "rename"
  ],
  "tools.combine_only:<module>": [
    "len",
    "quick_combine",
    "run_combine_only_mode"
  ],
  "tools.gui_static_map:<module>": [
    "Path",
    "main",
    "resolve"
  ],
  "tools.gui_static_map:qualname_from_attr": [
    "append",
    "isinstance",
    "join",
    "reversed"
  ],
  "tools.gui_static_map:GUISpy.visit_Assign": [
    "generic_visit",
    "isinstance",
    "qualname_from_attr"
  ],
  "tools.gui_static_map:GUISpy.visit_Call": [
    "append",
    "generic_visit",
    "isinstance",
    "qualname_from_attr"
  ],
  "tools.gui_static_map:GUISpy.visit_FunctionDef": [
    "generic_visit"
  ],
  "tools.gui_static_map:SlotAnalyzer.__init__": [
    "set"
  ],
  "tools.gui_static_map:SlotAnalyzer.visit_Call": [
    "add",
    "generic_visit",
    "getattr",
    "isinstance",
    "qualname_from_attr",
    "startswith"
  ],
  "tools.gui_static_map:SlotAnalyzer.generic_visit": [
    "iter_child_nodes",
    "setattr",
    "visit"
  ],
  "tools.gui_static_map:build_feature_map": [
    "GUISpy",
    "SlotAnalyzer",
    "append",
    "get",
    "parse",
    "read_text",
    "sorted",
    "split",
    "str",
    "visit"
  ],
  "tools.gui_static_map:main": [
    "build_feature_map",
    "dumps",
    "exists",
    "mkdir",
    "print",
    "write_text"
  ],
  "tools.test_cuda_integration:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.test_cuda_integration:clear_memory": [
    "collect",
    "empty_cache",
    "is_available"
  ],
  "tools.test_cuda_integration:get_test_voice": [
    "list_voice_samples"
  ],
  "tools.test_cuda_integration:test_cuda_optimizer_integration": [
    "apply_optimizations",
    "clear_memory",
    "create_cuda_optimizer",
    "create_optimized_tensor",
    "current_device",
    "get_device_name",
    "get_optimization_summary",
    "get_test_voice",
    "get_tts_optimizer",
    "is_available",
    "load_optimized_model",
    "optimize_tensor_memory_layout",
    "prewarm_model_with_voice",
    "print",
    "print_exc",
    "randn",
    "restore_original_methods"
  ],
  "tools.test_cuda_integration:main": [
    "test_cuda_optimizer_integration"
  ],
  "tools.test_sequential_pipeline:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.test_sequential_pipeline:get_memory_usage": [
    "Process",
    "is_available",
    "memory_allocated",
    "memory_info",
    "memory_reserved",
    "virtual_memory"
  ],
  "tools.test_sequential_pipeline:monitor_gpu_simple": [
    "int",
    "run",
    "strip"
  ],
  "tools.test_sequential_pipeline:phase_1_t3_processing": [
    "append",
    "cat",
    "cpu",
    "drop_invalid_tokens",
    "enumerate",
    "get_memory_usage",
    "inference",
    "inference_mode",
    "len",
    "monitor_gpu_simple",
    "prepare_conditionals",
    "print",
    "strip",
    "sum",
    "tensor",
    "text_to_tokens",
    "time"
  ],
  "tools.test_sequential_pipeline:clear_t3_from_memory": [
    "collect",
    "empty_cache",
    "get_memory_usage",
    "hasattr",
    "print"
  ],
  "tools.test_sequential_pipeline:phase_2_s3gen_processing": [
    "append",
    "cuda",
    "empty_cache",
    "enumerate",
    "inference",
    "inference_mode",
    "len",
    "locals",
    "monitor_gpu_simple",
    "print",
    "sum",
    "time"
  ],
  "tools.test_sequential_pipeline:main": [
    "Path",
    "append",
    "clear_t3_from_memory",
    "dump",
    "exists",
    "get_device_name",
    "is_available",
    "isinstance",
    "len",
    "load_optimized_model",
    "open",
    "phase_1_t3_processing",
    "phase_2_s3gen_processing",
    "prewarm_model_with_voice",
    "print",
    "print_exc",
    "read",
    "sentence_chunk_text",
    "strftime",
    "time"
  ],
  "tools.cuda_kernel_profiler:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.cuda_kernel_profiler:CudaKernelProfiler.__init__": [
    "_get_device"
  ],
  "tools.cuda_kernel_profiler:CudaKernelProfiler._get_device": [
    "RuntimeError",
    "current_device",
    "is_available"
  ],
  "tools.cuda_kernel_profiler:CudaKernelProfiler._get_gpu_utilization": [
    "CudaUtilizationSnapshot",
    "float",
    "int",
    "perf_counter",
    "print",
    "run",
    "split",
    "strip"
  ],
  "tools.cuda_kernel_profiler:CudaKernelProfiler._monitor_utilization": [
    "_get_gpu_utilization",
    "append",
    "sleep"
  ],
  "tools.cuda_kernel_profiler:CudaKernelProfiler.start_monitoring": [
    "Thread",
    "start"
  ],
  "tools.cuda_kernel_profiler:CudaKernelProfiler.stop_monitoring": [
    "copy",
    "join"
  ],
  "tools.cuda_kernel_profiler:CudaKernelProfiler.analyze_utilization": [
    "len",
    "max",
    "min",
    "sum"
  ],
  "tools.cuda_kernel_profiler:CudaKernelProfiler.profile_inference_workload": [
    "analyze_utilization",
    "autocast",
    "empty_cache",
    "hasattr",
    "mm",
    "perf_counter",
    "print",
    "randn",
    "range",
    "start_monitoring",
    "stop_monitoring",
    "synchronize",
    "t"
  ],
  "tools.cuda_kernel_profiler:CudaKernelProfiler.generate_optimization_recommendations": [
    "append",
    "get"
  ],
  "tools.cuda_kernel_profiler:CudaKernelProfiler.run_comprehensive_profile": [
    "KernelProfilingResult",
    "analyze_utilization",
    "enumerate",
    "extend",
    "generate_optimization_recommendations",
    "get",
    "len",
    "load_optimized_model",
    "prewarm_model_with_voice",
    "print",
    "profile_inference_workload",
    "sleep"
  ],
  "tools.cuda_kernel_profiler:CudaKernelProfiler.save_profile_results": [
    "asdict",
    "dump",
    "open",
    "print",
    "strftime"
  ],
  "tools.cuda_kernel_profiler:CudaKernelProfiler.print_summary": [
    "enumerate",
    "print"
  ],
  "tools.cuda_kernel_profiler:main": [
    "ArgumentParser",
    "CudaKernelProfiler",
    "add_argument",
    "get_device_name",
    "is_available",
    "list_voice_samples",
    "parse_args",
    "print",
    "print_exc",
    "print_summary",
    "run_comprehensive_profile",
    "save_profile_results"
  ],
  "tools.test_flash_attention:<module>": [
    "Path",
    "insert",
    "str",
    "test_flash_attention_vs_eager"
  ],
  "tools.test_flash_attention:benchmark_attention_implementation": [
    "cat",
    "collect",
    "empty_cache",
    "hasattr",
    "inference",
    "inference_mode",
    "memory_allocated",
    "prepare_conditionals",
    "print",
    "str",
    "strip",
    "tensor",
    "text_to_tokens",
    "time"
  ],
  "tools.test_flash_attention:load_model_with_attention": [
    "TTS_Engine",
    "hasattr",
    "print"
  ],
  "tools.test_flash_attention:test_flash_attention_vs_eager": [
    "Path",
    "benchmark_attention_implementation",
    "collect",
    "dump",
    "empty_cache",
    "exists",
    "get",
    "get_device_name",
    "is_available",
    "load_optimized_model",
    "open",
    "prewarm_model_with_voice",
    "print",
    "print_exc",
    "strftime"
  ],
  "tools.feature_run_logger:<module>": [
    "Path",
    "main",
    "resolve"
  ],
  "tools.feature_run_logger:parse_input_expr": [
    "endswith",
    "len",
    "split",
    "startswith"
  ],
  "tools.feature_run_logger:get_input_value": [
    "getattr",
    "meth"
  ],
  "tools.feature_run_logger:_parse_self_qualname": [
    "len",
    "split",
    "startswith"
  ],
  "tools.feature_run_logger:_resolve_attr_chain": [
    "getattr"
  ],
  "tools.feature_run_logger:instrument_window": [
    "append",
    "get",
    "set",
    "setdefault",
    "split",
    "update"
  ],
  "tools.feature_run_logger:instrument_window.wrapped_init": [
    "MethodType",
    "_parse_self_qualname",
    "_resolve_attr_chain",
    "callable",
    "connect",
    "dumps",
    "get",
    "getattr",
    "hasattr",
    "items",
    "keys",
    "list",
    "make_wrapper",
    "mkdir",
    "original_init",
    "print",
    "resolve",
    "setattr",
    "sorted",
    "str",
    "values",
    "write_text"
  ],
  "tools.feature_run_logger:instrument_window.wrapped_init.make_wrapper._wrapper": [
    "_orig",
    "append",
    "currentIndex",
    "dumps",
    "exists",
    "findChildren",
    "flush",
    "get_input_value",
    "getattr",
    "getprofile",
    "len",
    "loads",
    "mkdir",
    "open",
    "parse_input_expr",
    "print",
    "read_text",
    "repr",
    "resolve",
    "set",
    "setprofile",
    "sorted",
    "tabText",
    "time",
    "union",
    "write",
    "write_text"
  ],
  "tools.feature_run_logger:instrument_window.wrapped_init.make_wrapper._wrapper._should_keep": [
    "Path",
    "resolve"
  ],
  "tools.feature_run_logger:instrument_window.wrapped_init.make_wrapper._wrapper._prof": [
    "Path",
    "_should_keep",
    "add",
    "relative_to",
    "resolve",
    "str"
  ],
  "tools.feature_run_logger:instrument_window.wrapped_init.make_wrapper": [
    "getattr"
  ],
  "tools.feature_run_logger:main": [
    "SystemExit",
    "callable",
    "dir",
    "exists",
    "getattr",
    "hasattr",
    "import_module",
    "instrument_window",
    "isinstance",
    "issubclass",
    "loads",
    "main",
    "read_text"
  ],
  "tools.feature_run_logger:main._wrap_rbc": [
    "dumps",
    "getprofile",
    "len",
    "mkdir",
    "open",
    "orig_rbc",
    "print",
    "repr",
    "resolve",
    "set",
    "setprofile",
    "sorted",
    "str",
    "time",
    "write",
    "write_text"
  ],
  "tools.feature_run_logger:main._wrap_rbc._keep": [
    "Path",
    "resolve"
  ],
  "tools.feature_run_logger:main._wrap_rbc._prof": [
    "Path",
    "_keep",
    "add",
    "relative_to",
    "resolve",
    "str"
  ],
  "tools.xtts_finetune_extractor:<module>": [
    "Path",
    "basicConfig",
    "exit",
    "insert",
    "main",
    "print",
    "str"
  ],
  "tools.xtts_finetune_extractor:SentimentIntensityAnalyzer.polarity_scores": [
    "lower",
    "max",
    "min",
    "sum"
  ],
  "tools.xtts_finetune_extractor:XTTSFinetuneExtractor.__init__": [
    "FileNotFoundError",
    "Path",
    "SentimentIntensityAnalyzer",
    "exists"
  ],
  "tools.xtts_finetune_extractor:XTTSFinetuneExtractor.analyze_directory_structure": [
    "Path",
    "any",
    "append",
    "endswith",
    "info",
    "items",
    "keys",
    "len",
    "lower",
    "rglob",
    "rstrip",
    "str",
    "walk"
  ],
  "tools.xtts_finetune_extractor:XTTSFinetuneExtractor.load_metadata": [
    "endswith",
    "info",
    "isinstance",
    "items",
    "len",
    "load",
    "open",
    "reader",
    "split",
    "strip",
    "warning"
  ],
  "tools.xtts_finetune_extractor:XTTSFinetuneExtractor.analyze_audio_file": [
    "XTTSAudioFile",
    "assess_audio_quality",
    "classify_emotion",
    "len",
    "load",
    "polarity_scores",
    "warning"
  ],
  "tools.xtts_finetune_extractor:XTTSFinetuneExtractor.assess_audio_quality": [
    "abs",
    "append",
    "len",
    "max",
    "mean",
    "min",
    "rms",
    "spectral_centroid",
    "zero_crossing_rate"
  ],
  "tools.xtts_finetune_extractor:XTTSFinetuneExtractor.extract_audio_files": [
    "Path",
    "analyze_audio_file",
    "append",
    "enumerate",
    "info",
    "keys",
    "len"
  ],
  "tools.xtts_finetune_extractor:XTTSFinetuneExtractor.select_best_samples": [
    "append",
    "defaultdict",
    "info",
    "items",
    "len",
    "sort"
  ],
  "tools.xtts_finetune_extractor:XTTSFinetuneExtractor.select_best_samples.score_file": [
    "abs"
  ],
  "tools.xtts_finetune_extractor:XTTSFinetuneExtractor.create_voice_samples": [
    "Path",
    "append",
    "array",
    "extend",
    "info",
    "int",
    "items",
    "len",
    "load",
    "mkdir",
    "str",
    "warning",
    "write"
  ],
  "tools.xtts_finetune_extractor:XTTSFinetuneExtractor.generate_report": [
    "Path",
    "defaultdict",
    "enumerate",
    "info",
    "items",
    "len",
    "mean",
    "open",
    "title",
    "upper",
    "write"
  ],
  "tools.xtts_finetune_extractor:main": [
    "ArgumentParser",
    "Path",
    "XTTSFinetuneExtractor",
    "add_argument",
    "analyze_directory_structure",
    "create_voice_samples",
    "exception",
    "extract_audio_files",
    "generate_report",
    "get",
    "items",
    "len",
    "load_metadata",
    "parse_args",
    "print",
    "select_best_samples"
  ],
  "tools.test_compile_fix:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.test_compile_fix:clear_memory": [
    "collect",
    "empty_cache",
    "is_available"
  ],
  "tools.test_compile_fix:get_test_voice": [
    "list_voice_samples"
  ],
  "tools.test_compile_fix:run_quick_inference_test": [
    "hasattr",
    "perf_counter",
    "print",
    "type"
  ],
  "tools.test_compile_fix:main": [
    "clear_memory",
    "get_test_voice",
    "hasattr",
    "is_available",
    "load_optimized_model",
    "lower",
    "prewarm_model_with_voice",
    "print",
    "print_exc",
    "run_quick_inference_test",
    "str",
    "type"
  ],
  "tools.headless_performance_test:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.headless_performance_test:HeadlessPerformanceTester.__init__": [
    "Path",
    "_get_device",
    "basicConfig",
    "getLogger",
    "getenv",
    "int"
  ],
  "tools.headless_performance_test:HeadlessPerformanceTester._get_device": [
    "current_device",
    "hasattr",
    "is_available"
  ],
  "tools.headless_performance_test:HeadlessPerformanceTester._get_vram_usage": [
    "memory_allocated"
  ],
  "tools.headless_performance_test:HeadlessPerformanceTester._clear_memory": [
    "collect",
    "empty_cache"
  ],
  "tools.headless_performance_test:HeadlessPerformanceTester._measure_tensor_contiguity": [
    "is_contiguous",
    "named_parameters"
  ],
  "tools.headless_performance_test:HeadlessPerformanceTester._measure_memory_fragmentation": [
    "memory_allocated",
    "memory_reserved"
  ],
  "tools.headless_performance_test:HeadlessPerformanceTester._get_voice_file": [
    "list_voice_samples",
    "lower"
  ],
  "tools.headless_performance_test:HeadlessPerformanceTester._run_single_inference": [
    "Path",
    "append",
    "error",
    "exists",
    "len",
    "mkdir",
    "perf_counter",
    "process_one_chunk",
    "punc_norm",
    "split",
    "str",
    "unlink"
  ],
  "tools.headless_performance_test:HeadlessPerformanceTester.test_torch_compile_configurations": [
    "PerformanceResult",
    "_clear_memory",
    "_get_voice_file",
    "_get_vram_usage",
    "_measure_memory_fragmentation",
    "_measure_tensor_contiguity",
    "_run_single_inference",
    "append",
    "compile",
    "error",
    "extend",
    "get",
    "hasattr",
    "info",
    "len",
    "load_optimized_model",
    "max",
    "perf_counter",
    "prewarm_model_with_voice",
    "range",
    "sum"
  ],
  "tools.headless_performance_test:HeadlessPerformanceTester.test_batching_configurations": [
    "info"
  ],
  "tools.headless_performance_test:HeadlessPerformanceTester.test_memory_optimizations": [
    "info"
  ],
  "tools.headless_performance_test:HeadlessPerformanceTester.run_full_test_suite": [
    "extend",
    "info",
    "test_batching_configurations",
    "test_memory_optimizations",
    "test_torch_compile_configurations"
  ],
  "tools.headless_performance_test:HeadlessPerformanceTester.save_results": [
    "asdict",
    "dump",
    "info",
    "open",
    "strftime"
  ],
  "tools.headless_performance_test:HeadlessPerformanceTester.print_summary": [
    "len",
    "print",
    "sorted"
  ],
  "tools.headless_performance_test:main": [
    "ArgumentParser",
    "HeadlessPerformanceTester",
    "add_argument",
    "parse_args",
    "print_summary",
    "run_full_test_suite",
    "save_results",
    "str",
    "test_batching_configurations",
    "test_memory_optimizations",
    "test_torch_compile_configurations"
  ],
  "tools.trace_t3_inference:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.trace_t3_inference:monitor_gpu": [
    "int",
    "run",
    "split",
    "strip"
  ],
  "tools.trace_t3_inference:patched_t3_inference_with_timing": [
    "AlignmentStreamAnalyzer",
    "MinPLogitsWarper",
    "RepetitionPenaltyLogitsProcessor",
    "T3HuggingfaceBackend",
    "TopPLogitsWarper",
    "_ensure_BOT_EOT",
    "all",
    "append",
    "atleast_2d",
    "cat",
    "close",
    "empty",
    "full",
    "get",
    "get_fixed_embedding",
    "hasattr",
    "int",
    "locals",
    "min_p_warper",
    "monitor_gpu",
    "multinomial",
    "ones_like",
    "patched_model",
    "prepare_input_embeds",
    "print",
    "range",
    "repetition_penalty_processor",
    "size",
    "softmax",
    "speech_emb",
    "squeeze",
    "time",
    "to",
    "top_p_warper",
    "view"
  ],
  "tools.trace_t3_inference:trace_t3_inference_detailed": [
    "cat",
    "patched_t3_inference_with_timing",
    "prepare_conditionals",
    "print",
    "strip",
    "tensor",
    "text_to_tokens"
  ],
  "tools.trace_t3_inference:main": [
    "Path",
    "append",
    "dump",
    "enumerate",
    "exists",
    "get_device_name",
    "is_available",
    "items",
    "keys",
    "len",
    "load_optimized_model",
    "open",
    "prewarm_model_with_voice",
    "print",
    "print_exc",
    "sort",
    "sorted",
    "strftime",
    "sum",
    "trace_t3_inference_detailed",
    "values"
  ],
  "tools.tts_trt_benchmark:<module>": [
    "Path",
    "insert",
    "main",
    "resolve",
    "str"
  ],
  "tools.tts_trt_benchmark:parse_args": [
    "ArgumentParser",
    "add_argument",
    "parse_args"
  ],
  "tools.tts_trt_benchmark:run_once": [
    "RuntimeError",
    "copy",
    "endswith",
    "find",
    "len",
    "loads",
    "pop",
    "reversed",
    "rfind",
    "run",
    "splitlines",
    "startswith",
    "str",
    "strip"
  ],
  "tools.tts_trt_benchmark:main": [
    "Path",
    "dumps",
    "exists",
    "exit",
    "parse_args",
    "print",
    "round",
    "run_once",
    "summarize"
  ],
  "tools.tts_trt_benchmark:main.summarize": [
    "get"
  ],
  "tools.test_kv_cache_optimization:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.test_kv_cache_optimization:analyze_kv_cache_usage": [
    "append",
    "cat",
    "collect",
    "element_size",
    "empty_cache",
    "hasattr",
    "inference_mode",
    "isinstance",
    "len",
    "memory_allocated",
    "min",
    "numel",
    "prepare_conditionals",
    "print",
    "range",
    "str",
    "strip",
    "t3_model",
    "tensor",
    "text_to_tokens",
    "time"
  ],
  "tools.test_kv_cache_optimization:test_kv_cache_preallocation": [
    "benchmark_standard_inference",
    "print"
  ],
  "tools.test_kv_cache_optimization:test_cache_memory_layout": [
    "benchmark_contiguous_cache_inference",
    "benchmark_standard_inference",
    "print"
  ],
  "tools.test_kv_cache_optimization:benchmark_standard_inference": [
    "cat",
    "collect",
    "empty_cache",
    "inference",
    "inference_mode",
    "prepare_conditionals",
    "print",
    "strip",
    "tensor",
    "text_to_tokens",
    "time"
  ],
  "tools.test_kv_cache_optimization:benchmark_contiguous_cache_inference": [
    "print"
  ],
  "tools.test_kv_cache_optimization:recommend_kv_optimizations": [
    "append",
    "get",
    "len",
    "max",
    "print",
    "sum"
  ],
  "tools.test_kv_cache_optimization:main": [
    "Path",
    "analyze_kv_cache_usage",
    "dump",
    "exists",
    "get",
    "get_device_name",
    "is_available",
    "load_optimized_model",
    "open",
    "prewarm_model_with_voice",
    "print",
    "print_exc",
    "recommend_kv_optimizations",
    "strftime",
    "test_cache_memory_layout"
  ],
  "tools.test_batched_inference:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.test_batched_inference:load_batching_plan": [
    "exists",
    "load",
    "open",
    "print"
  ],
  "tools.test_batched_inference:prepare_text_batches": [
    "append",
    "enumerate",
    "len",
    "print"
  ],
  "tools.test_batched_inference:tokenize_text_batch": [
    "append",
    "cat",
    "full",
    "max",
    "squeeze",
    "stack",
    "strip",
    "tensor",
    "text_to_tokens"
  ],
  "tools.test_batched_inference:benchmark_sequential_inference": [
    "append",
    "cat",
    "collect",
    "empty_cache",
    "enumerate",
    "hasattr",
    "inference",
    "inference_mode",
    "len",
    "memory_allocated",
    "str",
    "strip",
    "tensor",
    "text_to_tokens",
    "time"
  ],
  "tools.test_batched_inference:benchmark_batched_inference": [
    "collect",
    "empty_cache",
    "hasattr",
    "inference",
    "inference_mode",
    "len",
    "memory_allocated",
    "str",
    "time",
    "tokenize_text_batch"
  ],
  "tools.test_batched_inference:run_batch_comparison": [
    "benchmark_batched_inference",
    "benchmark_sequential_inference",
    "len",
    "print"
  ],
  "tools.test_batched_inference:analyze_batch_results": [
    "append",
    "float",
    "get",
    "len",
    "max",
    "min",
    "print",
    "sum"
  ],
  "tools.test_batched_inference:main": [
    "Path",
    "analyze_batch_results",
    "append",
    "dump",
    "enumerate",
    "exists",
    "exit",
    "get",
    "isinstance",
    "len",
    "load",
    "load_batching_plan",
    "load_optimized_model",
    "open",
    "prepare_text_batches",
    "prewarm_model_with_voice",
    "print",
    "run_batch_comparison",
    "str",
    "strftime"
  ],
  "tools.safe_archiver:load_candidates": [
    "exists",
    "loads",
    "read_text"
  ],
  "tools.safe_archiver:load_reached": [
    "exists",
    "loads",
    "read_text",
    "set"
  ],
  "tools.safe_archiver:apply": [
    "append",
    "dumps",
    "exists",
    "mkdir",
    "move",
    "str",
    "write_text"
  ],
  "tools.safe_archiver:restore": [
    "exists",
    "get",
    "loads",
    "mkdir",
    "move",
    "read_text",
    "str"
  ],
  "tools.safe_archiver:main": [
    "ArgumentParser",
    "Path",
    "add_argument",
    "apply",
    "len",
    "load_candidates",
    "load_reached",
    "parse_args",
    "print",
    "resolve",
    "restore"
  ],
  "tools.safe_archiver:<module>": [
    "main"
  ],
  "tools.emotional_audio_enhancer:<module>": [
    "basicConfig",
    "main"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.__init__": [
    "BooleanVar",
    "DoubleVar",
    "IntVar",
    "StringVar",
    "geometry",
    "mkdtemp",
    "setup_ui",
    "title"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.setup_ui": [
    "Button",
    "Checkbutton",
    "Entry",
    "Frame",
    "Label",
    "LabelFrame",
    "Progressbar",
    "Radiobutton",
    "Scale",
    "check_audio_tools",
    "config",
    "create_tooltip",
    "enumerate",
    "get",
    "grid",
    "isinstance",
    "pack",
    "update_display"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.setup_ui.update_display": [
    "config",
    "float",
    "int",
    "isinstance"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.create_tooltip.on_enter": [
    "Label",
    "Toplevel",
    "pack",
    "wm_geometry",
    "wm_overrideredirect"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.create_tooltip.on_leave": [
    "destroy",
    "hasattr"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.create_tooltip": [
    "bind"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.select_input_file": [
    "Path",
    "askopenfilename",
    "get",
    "set",
    "str"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.select_output_file": [
    "asksavefilename",
    "set"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.update_emotion_presets": [
    "get",
    "items",
    "set"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.check_audio_tools": [
    "append",
    "run",
    "showwarning"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.start_processing": [
    "Thread",
    "config",
    "get",
    "set",
    "showerror",
    "start"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.process_audio": [
    "apply_compression",
    "apply_eq",
    "apply_formant_shift",
    "apply_pitch_shift",
    "apply_reverb",
    "apply_tempo_change",
    "apply_tremolo",
    "apply_vibrato",
    "cleanup_temp_files",
    "config",
    "copy2",
    "error",
    "get",
    "join",
    "set",
    "showerror",
    "showinfo",
    "str",
    "sum",
    "update_status",
    "values"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.apply_pitch_shift": [
    "get",
    "run",
    "str",
    "update_status"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.apply_formant_shift": [
    "get",
    "run",
    "update_status"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.apply_compression": [
    "get",
    "run",
    "update_status"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.apply_eq": [
    "get",
    "run",
    "str",
    "update_status"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.apply_tempo_change": [
    "get",
    "run",
    "str",
    "update_status"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.apply_reverb": [
    "get",
    "run",
    "str",
    "update_status"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.apply_tremolo": [
    "get",
    "run",
    "str",
    "update_status"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.apply_vibrato": [
    "get",
    "run",
    "str",
    "update_status"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.update_status": [
    "after",
    "config",
    "info"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.cleanup_temp_files": [
    "join",
    "listdir",
    "remove"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.preview_audio": [
    "Popen",
    "get",
    "showinfo",
    "showwarning"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.reset_settings": [
    "set",
    "update_emotion_presets",
    "values"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.save_preset": [
    "asksavefilename",
    "dump",
    "get",
    "items",
    "open",
    "showinfo"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.load_preset": [
    "askopenfilename",
    "items",
    "load",
    "open",
    "set",
    "showerror",
    "showinfo",
    "str"
  ],
  "tools.emotional_audio_enhancer:EmotionalAudioEnhancer.__del__": [
    "rmtree"
  ],
  "tools.emotional_audio_enhancer:main": [
    "EmotionalAudioEnhancer",
    "Style",
    "Tk",
    "geometry",
    "mainloop",
    "protocol",
    "theme_use",
    "update_idletasks",
    "winfo_height",
    "winfo_screenheight",
    "winfo_screenwidth",
    "winfo_width"
  ],
  "tools.emotional_audio_enhancer:main.on_closing": [
    "cleanup_temp_files",
    "destroy"
  ],
  "tools.analyze_book_json_for_batching:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.analyze_book_json_for_batching:parse_book_json": [
    "ChunkInfo",
    "append",
    "enumerate",
    "get",
    "int",
    "isinstance",
    "items",
    "len",
    "load",
    "open",
    "print",
    "split",
    "str",
    "strip",
    "type"
  ],
  "tools.analyze_book_json_for_batching:group_chunks_by_tts_params": [
    "BatchGroup",
    "append",
    "calculate_batch_benefit",
    "defaultdict",
    "dict",
    "items",
    "len",
    "print",
    "sorted",
    "sum",
    "tuple"
  ],
  "tools.analyze_book_json_for_batching:calculate_batch_benefit": [
    "len",
    "min"
  ],
  "tools.analyze_book_json_for_batching:analyze_batching_potential": [
    "Counter",
    "dict",
    "len",
    "max",
    "print",
    "sorted",
    "sum",
    "values"
  ],
  "tools.analyze_book_json_for_batching:print_analysis_report": [
    "enumerate",
    "items",
    "len",
    "print",
    "sorted"
  ],
  "tools.analyze_book_json_for_batching:create_batching_plan": [
    "append",
    "copy",
    "items",
    "len",
    "min",
    "print",
    "strftime",
    "sum"
  ],
  "tools.analyze_book_json_for_batching:save_analysis_results": [
    "dump",
    "open",
    "print",
    "str"
  ],
  "tools.analyze_book_json_for_batching:main": [
    "Path",
    "analyze_batching_potential",
    "create_batching_plan",
    "exists",
    "exit",
    "group_chunks_by_tts_params",
    "len",
    "parse_book_json",
    "print",
    "print_analysis_report",
    "save_analysis_results"
  ],
  "tools.test_unified_device_mode:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.test_unified_device_mode:clear_memory": [
    "collect",
    "empty_cache",
    "is_available"
  ],
  "tools.test_unified_device_mode:get_test_voice": [
    "list_voice_samples"
  ],
  "tools.test_unified_device_mode:check_device_configuration": [
    "getenv",
    "items",
    "print"
  ],
  "tools.test_unified_device_mode:analyze_model_devices": [
    "hasattr",
    "items",
    "len",
    "list",
    "next",
    "parameters",
    "print",
    "set",
    "str",
    "values"
  ],
  "tools.test_unified_device_mode:test_basic_inference": [
    "generate",
    "hasattr",
    "prepare_conditionals",
    "print",
    "print_exc",
    "time"
  ],
  "tools.test_unified_device_mode:test_batch_inference": [
    "generate_batch",
    "len",
    "print",
    "print_exc",
    "time"
  ],
  "tools.test_unified_device_mode:main": [
    "analyze_model_devices",
    "check_device_configuration",
    "clear_memory",
    "get_device_name",
    "get_test_voice",
    "getenv",
    "is_available",
    "load_optimized_model",
    "lower",
    "prewarm_model_with_voice",
    "print",
    "test_basic_inference",
    "test_batch_inference"
  ],
  "tools.gui_walker:<module>": [
    "main",
    "setdefault"
  ],
  "tools.gui_walker:log": [
    "append",
    "print"
  ],
  "tools.gui_walker:save_log": [
    "Path",
    "join",
    "mkdir",
    "resolve",
    "write_text"
  ],
  "tools.gui_walker:main": [
    "QApplication",
    "_PkgStubFinder",
    "count",
    "currentWidget",
    "dir",
    "findChildren",
    "getattr",
    "import_module",
    "insert",
    "instance",
    "isinstance",
    "issubclass",
    "len",
    "log",
    "main_cls",
    "mouseClick",
    "processEvents",
    "qWait",
    "range",
    "save_log",
    "setCurrentIndex",
    "show",
    "tabText",
    "text"
  ],
  "tools.gui_walker:main._PkgStubLoader.create_module": [
    "ModuleType",
    "getattr"
  ],
  "tools.gui_walker:main._PkgStubLoader.exec_module": [
    "setattr",
    "startswith"
  ],
  "tools.gui_walker:main._PkgStubFinder.find_spec": [
    "ModuleSpec",
    "_PkgStubLoader",
    "startswith"
  ],
  "tools.audio_emotion_scanner:<module>": [
    "Path",
    "basicConfig",
    "exit",
    "insert",
    "main",
    "str"
  ],
  "tools.audio_emotion_scanner:AudioEmotionScanner.__init__": [
    "SentimentIntensityAnalyzer"
  ],
  "tools.audio_emotion_scanner:AudioEmotionScanner.load_whisper_model": [
    "collect",
    "empty_cache",
    "error",
    "info",
    "is_available",
    "load_model",
    "load_whisper_model",
    "memory_allocated"
  ],
  "tools.audio_emotion_scanner:AudioEmotionScanner.chunk_audio": [
    "append",
    "info",
    "int",
    "len",
    "load",
    "min"
  ],
  "tools.audio_emotion_scanner:AudioEmotionScanner.transcribe_chunk": [
    "TranscriptSegment",
    "append",
    "collect",
    "empty_cache",
    "endswith",
    "error",
    "get",
    "index",
    "is_available",
    "join",
    "len",
    "rstrip",
    "strip",
    "transcribe"
  ],
  "tools.audio_emotion_scanner:AudioEmotionScanner.classify_speech_pattern": [
    "lower",
    "search",
    "strip"
  ],
  "tools.audio_emotion_scanner:AudioEmotionScanner.analyze_transcript_segments": [
    "EmotionalSegment",
    "append",
    "classify_emotion",
    "classify_speech_pattern",
    "len",
    "polarity_scores",
    "strip"
  ],
  "tools.audio_emotion_scanner:AudioEmotionScanner.extract_audio_segment": [
    "dirname",
    "error",
    "int",
    "len",
    "linspace",
    "load",
    "makedirs",
    "max",
    "write"
  ],
  "tools.audio_emotion_scanner:AudioEmotionScanner.scan_audio_file": [
    "abs",
    "analyze_transcript_segments",
    "append",
    "chunk_audio",
    "collect",
    "defaultdict",
    "dict",
    "empty_cache",
    "enumerate",
    "extend",
    "info",
    "is_available",
    "items",
    "len",
    "load_whisper_model",
    "save_analysis_results",
    "sort",
    "transcribe_chunk"
  ],
  "tools.audio_emotion_scanner:AudioEmotionScanner.save_analysis_results": [
    "Path",
    "append",
    "defaultdict",
    "dump",
    "enumerate",
    "info",
    "items",
    "len",
    "mkdir",
    "open",
    "round",
    "upper",
    "write"
  ],
  "tools.audio_emotion_scanner:AudioEmotionScanner.extract_best_segments": [
    "Path",
    "append",
    "defaultdict",
    "dict",
    "enumerate",
    "extract_audio_segment",
    "info",
    "items",
    "mkdir",
    "str"
  ],
  "tools.audio_emotion_scanner:main": [
    "ArgumentParser",
    "AudioEmotionScanner",
    "add_argument",
    "exception",
    "extract_best_segments",
    "items",
    "len",
    "parse_args",
    "print",
    "scan_audio_file"
  ],
  "tools.test_dual_queue_pipeline:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.test_dual_queue_pipeline:DualQueueManager.__init__": [
    "Event",
    "Queue"
  ],
  "tools.test_dual_queue_pipeline:DualQueueManager.switch_queues": [
    "append",
    "print",
    "set",
    "time"
  ],
  "tools.test_dual_queue_pipeline:DualQueueManager.get_queue_status": [
    "empty",
    "full",
    "qsize"
  ],
  "tools.test_dual_queue_pipeline:load_test_content": [
    "FileNotFoundError",
    "Path",
    "exists",
    "len",
    "open",
    "print",
    "read",
    "stat",
    "str"
  ],
  "tools.test_dual_queue_pipeline:prepare_text_chunks": [
    "append",
    "enumerate",
    "isinstance",
    "len",
    "print",
    "sentence_chunk_text",
    "split",
    "strip"
  ],
  "tools.test_dual_queue_pipeline:t3_worker": [
    "append",
    "cat",
    "cpu",
    "drop_invalid_tokens",
    "enumerate",
    "full",
    "inference",
    "inference_mode",
    "is_set",
    "len",
    "prepare_conditionals",
    "print",
    "put",
    "strip",
    "switch_queues",
    "tensor",
    "text_to_tokens",
    "time"
  ],
  "tools.test_dual_queue_pipeline:s3gen_worker": [
    "append",
    "cuda",
    "empty",
    "empty_cache",
    "get",
    "inference",
    "inference_mode",
    "is_set",
    "len",
    "print",
    "range",
    "task_done",
    "time"
  ],
  "tools.test_dual_queue_pipeline:monitor_gpu_utilization": [
    "append",
    "int",
    "is_set",
    "print",
    "run",
    "sleep",
    "strip",
    "time"
  ],
  "tools.test_dual_queue_pipeline:analyze_pipeline_performance": [
    "len",
    "max",
    "min",
    "print",
    "sum"
  ],
  "tools.test_dual_queue_pipeline:main": [
    "DualQueueManager",
    "Thread",
    "analyze_pipeline_performance",
    "dump",
    "get_device_name",
    "is_available",
    "join",
    "len",
    "load_optimized_model",
    "load_test_content",
    "open",
    "prepare_text_chunks",
    "prewarm_model_with_voice",
    "print",
    "print_exc",
    "s3gen_worker",
    "set",
    "start",
    "strftime",
    "sum",
    "t3_worker",
    "time"
  ],
  "tools.quick_batching_test:<module>": [
    "Path",
    "insert",
    "quick_batch_test",
    "str"
  ],
  "tools.quick_batching_test:quick_batch_test": [
    "append",
    "empty_cache",
    "hasattr",
    "inference",
    "inference_mode",
    "len",
    "load_optimized_model",
    "prewarm_model_with_voice",
    "print",
    "sum",
    "time",
    "tokenize_batch",
    "tokenize_single"
  ],
  "tools.quick_batching_test:quick_batch_test.tokenize_single": [
    "cat",
    "strip",
    "tensor",
    "text_to_tokens"
  ],
  "tools.quick_batching_test:quick_batch_test.tokenize_batch": [
    "append",
    "cat",
    "full",
    "max",
    "squeeze",
    "stack",
    "tokenize_single"
  ],
  "tools.path_checker:<module>": [
    "Path",
    "append",
    "main",
    "str"
  ],
  "tools.path_checker:main": [
    "check_existing_audiobook_paths",
    "enumerate",
    "len",
    "print"
  ],
  "tools.run_tts_once:<module>": [
    "Path",
    "insert",
    "main",
    "resolve",
    "str"
  ],
  "tools.run_tts_once:parse_args": [
    "ArgumentParser",
    "add_argument",
    "parse_args"
  ],
  "tools.run_tts_once:set_trt_env": [
    "pop"
  ],
  "tools.run_tts_once:default_texts": [
    "len",
    "max",
    "min"
  ],
  "tools.run_tts_once:main": [
    "Path",
    "append",
    "default_texts",
    "dumps",
    "enumerate",
    "exists",
    "exit",
    "float",
    "generate",
    "get_autocast",
    "getattr",
    "hasattr",
    "int",
    "is_available",
    "len",
    "load_optimized_model",
    "max",
    "no_grad",
    "parse_args",
    "prepare_conditionals",
    "print",
    "range",
    "read_text",
    "round",
    "set_trt_env",
    "splitlines",
    "strip",
    "sum",
    "time"
  ],
  "tools.test_attention_optimizations:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.test_attention_optimizations:benchmark_attention_implementation": [
    "cat",
    "collect",
    "empty_cache",
    "hasattr",
    "inference",
    "inference_mode",
    "memory_allocated",
    "prepare_conditionals",
    "print",
    "str",
    "strip",
    "tensor",
    "text_to_tokens",
    "time"
  ],
  "tools.test_attention_optimizations:test_sdpa_attention": [
    "benchmark_attention_implementation",
    "print"
  ],
  "tools.test_attention_optimizations:test_grouped_query_attention": [
    "benchmark_attention_implementation",
    "print"
  ],
  "tools.test_attention_optimizations:install_flash_attention": [
    "print",
    "run"
  ],
  "tools.test_attention_optimizations:main": [
    "Path",
    "dump",
    "exists",
    "get",
    "get_device_name",
    "install_flash_attention",
    "is_available",
    "load_optimized_model",
    "open",
    "prewarm_model_with_voice",
    "print",
    "print_exc",
    "strftime",
    "test_grouped_query_attention",
    "test_sdpa_attention"
  ],
  "tools.test_s3gen_cpu_performance:<module>": [
    "Path",
    "insert",
    "main",
    "str"
  ],
  "tools.test_s3gen_cpu_performance:clear_memory": [
    "collect",
    "empty_cache",
    "is_available"
  ],
  "tools.test_s3gen_cpu_performance:get_test_voice": [
    "list_voice_samples"
  ],
  "tools.test_s3gen_cpu_performance:get_memory_usage": [
    "Process",
    "get_device_properties",
    "is_available",
    "memory_allocated",
    "memory_info",
    "memory_reserved",
    "virtual_memory"
  ],
  "tools.test_s3gen_cpu_performance:create_test_speech_tokens": [
    "append",
    "cat",
    "drop_invalid_tokens",
    "enumerate",
    "inference",
    "inference_mode",
    "len",
    "prepare_conditionals",
    "print",
    "strip",
    "tensor",
    "text_to_tokens",
    "time"
  ],
  "tools.test_s3gen_cpu_performance:test_s3gen_gpu_performance": [
    "append",
    "enumerate",
    "get_memory_usage",
    "hasattr",
    "inference",
    "inference_mode",
    "len",
    "print",
    "time",
    "to"
  ],
  "tools.test_s3gen_cpu_performance:test_s3gen_cpu_performance": [
    "append",
    "cpu",
    "enumerate",
    "get_memory_usage",
    "hasattr",
    "inference",
    "inference_mode",
    "is_tensor",
    "items",
    "len",
    "print",
    "time",
    "to"
  ],
  "tools.test_s3gen_cpu_performance:analyze_pipeline_potential": [
    "get",
    "len",
    "max",
    "print",
    "sum"
  ],
  "tools.test_s3gen_cpu_performance:main": [
    "analyze_pipeline_potential",
    "clear_memory",
    "create_test_speech_tokens",
    "dump",
    "get_device_name",
    "get_test_voice",
    "is_available",
    "len",
    "load_optimized_model",
    "open",
    "prewarm_model_with_voice",
    "print",
    "str",
    "strftime",
    "test_s3gen_cpu_performance",
    "test_s3gen_gpu_performance"
  ],
  "tools.spider_ci:load_graph": [
    "exists",
    "loads",
    "read_text"
  ],
  "tools.spider_ci:detect_cycles.dfs": [
    "append",
    "dfs",
    "get",
    "index",
    "pop"
  ],
  "tools.spider_ci:detect_cycles": [
    "dfs",
    "keys",
    "list"
  ],
  "tools.spider_ci:main": [
    "ArgumentParser",
    "Path",
    "SystemExit",
    "add_argument",
    "detect_cycles",
    "dumps",
    "len",
    "load_graph",
    "mkdir",
    "parse_args",
    "print",
    "resolve",
    "sum",
    "values",
    "write_text"
  ],
  "tools.spider_ci:<module>": [
    "main"
  ],
  "tools.feature_spider:<module>": [
    "Path",
    "main",
    "resolve"
  ],
  "tools.feature_spider:rel": [
    "relative_to",
    "resolve",
    "str"
  ],
  "tools.feature_spider:list_py_files": [
    "Path",
    "any",
    "append",
    "endswith",
    "walk"
  ],
  "tools.feature_spider:module_to_path": [
    "Path",
    "exists",
    "replace",
    "with_suffix"
  ],
  "tools.feature_spider:resolve_import": [
    "append",
    "getattr",
    "isinstance",
    "join",
    "module_to_path",
    "range",
    "rel",
    "split",
    "strip"
  ],
  "tools.feature_spider:build_import_graph": [
    "add",
    "append",
    "isinstance",
    "list",
    "parse",
    "pop",
    "read_text",
    "rel",
    "resolve",
    "resolve_import",
    "set",
    "setdefault",
    "str",
    "walk"
  ],
  "tools.feature_spider:to_dot": [
    "append",
    "items",
    "join",
    "replace"
  ],
  "tools.feature_spider:parse_gui_connections": [
    "append",
    "compile",
    "finditer",
    "group",
    "read_text",
    "setdefault"
  ],
  "tools.feature_spider:main": [
    "ArgumentParser",
    "add_argument",
    "append",
    "build_import_graph",
    "dumps",
    "exists",
    "items",
    "keys",
    "list",
    "list_py_files",
    "mkdir",
    "parse_args",
    "parse_gui_connections",
    "print",
    "rel",
    "resolve",
    "set",
    "sorted",
    "startswith",
    "to_dot",
    "values",
    "write_text"
  ],
  "modules.terminal_logger:TerminalLogger.__init__": [
    "Lock",
    "Path",
    "resolve"
  ],
  "modules.terminal_logger:TerminalLogger.start_logging": [
    "now",
    "open",
    "print",
    "write"
  ],
  "modules.terminal_logger:TerminalLogger.stop_logging": [
    "now",
    "open",
    "print",
    "write"
  ],
  "modules.terminal_logger:TerminalLogger._emit_chunk_summary": [
    "float",
    "flush",
    "open",
    "str",
    "write"
  ],
  "modules.terminal_logger:TerminalLogger.emit_chunk_summary": [
    "_emit_chunk_summary"
  ],
  "modules.terminal_logger:TerminalLogger.write": [
    "any",
    "flush",
    "group",
    "int",
    "open",
    "print",
    "search",
    "splitlines",
    "startswith",
    "strip",
    "write"
  ],
  "modules.terminal_logger:TerminalLogger.flush": [
    "flush"
  ],
  "modules.terminal_logger:TerminalLogger.write_file_only": [
    "endswith",
    "flush",
    "open",
    "write"
  ],
  "modules.terminal_logger:TerminalLogger.set_eta_frequency": [
    "int",
    "max"
  ],
  "modules.terminal_logger:TerminalLogger.set_batch_size": [
    "int",
    "max"
  ],
  "modules.terminal_logger:start_terminal_logging": [
    "TerminalLogger",
    "start_logging",
    "stop_logging"
  ],
  "modules.terminal_logger:stop_terminal_logging": [
    "stop_logging"
  ],
  "modules.terminal_logger:log_only": [
    "Path",
    "endswith",
    "open",
    "write",
    "write_file_only"
  ],
  "modules.terminal_logger:set_eta_frequency": [
    "set_eta_frequency"
  ],
  "modules.terminal_logger:set_batch_size": [
    "set_batch_size"
  ],
  "modules.terminal_logger:emit_chunk_summary": [
    "emit_chunk_summary"
  ],
  "modules.terminal_logger:get_running_avg_its": [
    "get_running_avg_its"
  ],
  "modules.dual_model_optimizer:DualModelParallelOptimizer.__init__": [
    "ThreadPoolExecutor"
  ],
  "modules.dual_model_optimizer:DualModelParallelOptimizer.load_dual_models": [
    "Path",
    "_load_single_model",
    "collect",
    "empty_cache",
    "get_device_properties",
    "insert",
    "isinstance",
    "len",
    "memory_allocated",
    "memory_reserved",
    "optimize_chatterbox_model",
    "print",
    "str",
    "synchronize"
  ],
  "modules.dual_model_optimizer:DualModelParallelOptimizer.load_dual_models._load_single_model": [
    "Path",
    "exists",
    "from_local",
    "from_pretrained",
    "print",
    "strip"
  ],
  "modules.dual_model_optimizer:DualModelParallelOptimizer._generate_single_threaded": [
    "generate",
    "no_grad",
    "print"
  ],
  "modules.dual_model_optimizer:DualModelParallelOptimizer.generate_parallel_pair": [
    "result",
    "submit"
  ],
  "modules.dual_model_optimizer:DualModelParallelOptimizer.benchmark_dual_vs_single": [
    "_generate_single_threaded",
    "append",
    "extend",
    "generate_parallel_pair",
    "len",
    "locals",
    "print",
    "synchronize",
    "time"
  ],
  "modules.dual_model_optimizer:DualModelParallelOptimizer.process_chunks_parallel": [
    "_generate_single_threaded",
    "append",
    "extend",
    "generate_parallel_pair",
    "len",
    "print",
    "range",
    "time"
  ],
  "modules.dual_model_optimizer:DualModelParallelOptimizer.cleanup": [
    "empty_cache",
    "print",
    "shutdown"
  ],
  "modules.dual_model_optimizer:test_dual_model_optimization": [
    "DualModelParallelOptimizer",
    "benchmark_dual_vs_single",
    "cleanup",
    "load_dual_models",
    "print"
  ],
  "modules.dual_model_optimizer:<module>": [
    "test_dual_model_optimization"
  ],
  "modules.voice_detector:get_likely_voices_for_book": [
    "any",
    "append",
    "find_voice_file_by_name",
    "get_voice_from_json",
    "get_voice_from_log",
    "get_voices_from_filenames",
    "len",
    "print"
  ],
  "modules.voice_detector:detect_voice_for_book": [
    "get_likely_voices_for_book"
  ],
  "modules.voice_detector:get_voice_from_json": [
    "group",
    "isinstance",
    "loads",
    "open",
    "print",
    "read",
    "search",
    "strip"
  ],
  "modules.voice_detector:get_voice_from_log": [
    "Path",
    "exists",
    "open",
    "print",
    "split",
    "startswith",
    "strip"
  ],
  "modules.voice_detector:get_voices_from_filenames": [
    "Path",
    "append",
    "exists",
    "glob",
    "group",
    "search"
  ],
  "modules.voice_detector:get_voice_from_filename": [
    "get_voices_from_filenames"
  ],
  "modules.voice_detector:find_voice_file_by_name": [
    "list_voice_samples",
    "lower"
  ],
  "modules.voice_detector:add_voice_to_json": [
    "any",
    "dump",
    "insert",
    "isinstance",
    "keys",
    "loads",
    "open",
    "print",
    "read",
    "startswith",
    "write"
  ],
  "modules.voice_detector:remove_voice_comment_from_json": [
    "join",
    "len",
    "open",
    "print",
    "read",
    "split",
    "startswith",
    "strip",
    "write"
  ],
  "modules.cuda_optimizer:<module>": [
    "getLogger"
  ],
  "modules.cuda_optimizer:CudaOptimizer.__init__": [
    "_setup_cuda_streams"
  ],
  "modules.cuda_optimizer:CudaOptimizer.apply_cuda_optimizations": [
    "_enable_kernel_fusion",
    "_optimize_cuda_settings",
    "_optimize_memory_allocator",
    "_optimize_tensor_operations",
    "error",
    "extend",
    "is_available"
  ],
  "modules.cuda_optimizer:CudaOptimizer._optimize_cuda_settings": [
    "append",
    "hasattr",
    "warning"
  ],
  "modules.cuda_optimizer:CudaOptimizer._optimize_memory_allocator": [
    "append",
    "get_device_properties",
    "hasattr",
    "is_available",
    "set_per_process_memory_fraction",
    "warning"
  ],
  "modules.cuda_optimizer:CudaOptimizer._enable_kernel_fusion": [
    "append",
    "hasattr",
    "set_fusion_strategy",
    "warning"
  ],
  "modules.cuda_optimizer:CudaOptimizer._optimize_tensor_operations": [
    "append",
    "hasattr",
    "set_num_threads",
    "warning"
  ],
  "modules.cuda_optimizer:CudaOptimizer.optimize_tensor_memory_layout": [
    "contiguous",
    "dim",
    "is_contiguous",
    "to",
    "warning"
  ],
  "modules.cuda_optimizer:CudaOptimizer.create_optimized_tensor": [
    "empty",
    "optimize_tensor_memory_layout",
    "startswith",
    "warning"
  ],
  "modules.cuda_optimizer:CudaOptimizer.preallocate_batch_tensors": [
    "contiguous",
    "empty",
    "info",
    "len",
    "str",
    "to",
    "warning"
  ],
  "modules.cuda_optimizer:CudaOptimizer.get_preallocated_tensor": [
    "clone",
    "create_optimized_tensor"
  ],
  "modules.cuda_optimizer:CudaOptimizer._setup_cuda_streams": [
    "Stream",
    "info",
    "is_available",
    "warning"
  ],
  "modules.cuda_optimizer:CudaOptimizer.async_batch_inference": [
    "batch_fn",
    "stream",
    "warning"
  ],
  "modules.cuda_optimizer:CudaOptimizer.pipeline_batch_processing": [
    "append",
    "cuda",
    "hasattr",
    "len",
    "model_fn",
    "range",
    "stream",
    "synchronize",
    "values",
    "warning"
  ],
  "modules.cuda_optimizer:CudaOptimizer.fused_attention_with_cache": [
    "cat",
    "hasattr",
    "matmul",
    "scaled_dot_product_attention",
    "size",
    "softmax",
    "transpose",
    "warning"
  ],
  "modules.cuda_optimizer:CudaOptimizer.optimize_batch_processing": [
    "get_device_properties",
    "int",
    "is_available",
    "max",
    "memory_allocated",
    "min",
    "warning"
  ],
  "modules.cuda_optimizer:CudaOptimizer.clear_memory_efficiently": [
    "collect",
    "empty_cache",
    "is_available",
    "synchronize",
    "warning"
  ],
  "modules.cuda_optimizer:CudaOptimizer.restore_original_settings": [
    "items",
    "warning"
  ],
  "modules.cuda_optimizer:CudaOptimizer.get_optimization_summary": [
    "is_available",
    "len"
  ],
  "modules.cuda_optimizer:create_cuda_optimizer": [
    "CudaOptimizer",
    "apply_cuda_optimizations",
    "info",
    "len"
  ],
  "modules.tts_engine:<module>": [
    "Lock",
    "set"
  ],
  "modules.tts_engine:clear_voice_cache": [
    "info"
  ],
  "modules.tts_engine:store_voice_cache": [
    "getsizeof",
    "hasattr",
    "info",
    "time",
    "warning"
  ],
  "modules.tts_engine:restore_voice_cache": [
    "debug",
    "info"
  ],
  "modules.tts_engine:find_chunks_json_file": [
    "Path",
    "exists",
    "lower",
    "replace"
  ],
  "modules.tts_engine:_release_global_tts_model": [
    "clear",
    "clear_cache",
    "collect",
    "cpu",
    "empty_cache",
    "hasattr",
    "ipc_collect",
    "is_available",
    "items",
    "print",
    "reset_peak_memory_stats",
    "reset_states",
    "synchronize"
  ],
  "modules.tts_engine:set_seed": [
    "hasattr",
    "info",
    "is_available",
    "manual_seed",
    "manual_seed_all",
    "seed"
  ],
  "modules.tts_engine:monitor_gpu_activity": [
    "is_available",
    "memory_allocated"
  ],
  "modules.tts_engine:optimize_memory_usage": [
    "collect",
    "empty_cache",
    "ipc_collect",
    "is_available"
  ],
  "modules.tts_engine:monitor_vram_usage": [
    "is_available",
    "memory_allocated",
    "memory_reserved",
    "optimize_memory_usage",
    "warning"
  ],
  "modules.tts_engine:get_optimal_workers": [
    "memory_allocated",
    "min"
  ],
  "modules.tts_engine:_voice_sig": [
    "Path",
    "resolve",
    "stat",
    "str"
  ],
  "modules.tts_engine:_core_tts_params_sig": [
    "float",
    "get",
    "round"
  ],
  "modules.tts_engine:prewarm_model_with_voice": [
    "ensure_voice_sample_compatibility",
    "generate",
    "prepare_conditionals",
    "print",
    "restore_voice_cache",
    "store_voice_cache"
  ],
  "modules.tts_engine:get_best_available_device": [
    "empty_cache",
    "is_available",
    "tensor",
    "to",
    "warning"
  ],
  "modules.tts_engine:load_optimized_model": [
    "Path",
    "bool",
    "error",
    "eval",
    "exists",
    "from_local",
    "from_pretrained",
    "hasattr",
    "info",
    "is_available",
    "optimize_chatterbox_model",
    "randn",
    "set_float32_matmul_precision",
    "strip",
    "warning"
  ],
  "modules.tts_engine:patch_alignment_layer.patched_forward": [
    "original_forward"
  ],
  "modules.tts_engine:patch_alignment_layer": [
    "MethodType"
  ],
  "modules.tts_engine:process_batch": [
    "BytesIO",
    "append",
    "cpu",
    "dim",
    "enumerate",
    "export",
    "float",
    "from_wav",
    "gen_with_backoff",
    "get",
    "hasattr",
    "info",
    "items",
    "len",
    "max",
    "min",
    "no_grad",
    "numpy",
    "process_audio_with_trimming_and_silence",
    "process_one_chunk",
    "seek",
    "set_seed",
    "squeeze",
    "trim_audio_endpoint",
    "unsqueeze",
    "warning",
    "write"
  ],
  "modules.tts_engine:process_batch.gen_with_backoff": [
    "clear",
    "collect",
    "empty_cache",
    "extend",
    "generate_batch",
    "is_available",
    "len",
    "lower",
    "max",
    "range",
    "str",
    "warning"
  ],
  "modules.tts_engine:process_one_chunk": [
    "BytesIO",
    "RuntimeError",
    "ValueError",
    "_cuda_clearCublasWorkspaces",
    "adjust_parameters_for_retry",
    "array",
    "astype",
    "calculate_text_similarity",
    "clear_cache",
    "collect",
    "copy",
    "cpu",
    "detach",
    "dim",
    "emit_chunk_summary",
    "empty_cache",
    "error",
    "evaluate_chunk_quality",
    "export",
    "fp32_fallback_mode",
    "from_wav",
    "generate",
    "get",
    "get_array_of_samples",
    "get_tts_optimizer",
    "getenv",
    "glob",
    "has_mid_energy_drop",
    "hasattr",
    "info",
    "ipc_collect",
    "is_available",
    "isinstance",
    "items",
    "len",
    "list",
    "locals",
    "log_only",
    "log_run_func",
    "mean",
    "memory_allocated",
    "memory_reserved",
    "no_grad",
    "numpy",
    "open",
    "optimize_memory_usage",
    "print",
    "print_exc",
    "process_audio_with_trimming_and_silence",
    "punc_norm",
    "range",
    "reset_peak_memory_stats",
    "reset_states",
    "reshape",
    "seek",
    "set_seed",
    "silent",
    "sleep",
    "squeeze",
    "str",
    "strip",
    "synchronize",
    "time",
    "transcribe",
    "trim_audio_endpoint",
    "type",
    "unlink",
    "unsqueeze",
    "warning",
    "write"
  ],
  "modules.tts_engine:smooth_sentiment_scores": [
    "len",
    "max",
    "reversed",
    "sum",
    "zip"
  ],
  "modules.tts_engine:generate_enriched_chunks": [
    "SentimentIntensityAnalyzer",
    "abs",
    "add_voice_to_json",
    "append",
    "detect_content_boundaries",
    "enumerate",
    "get",
    "info",
    "int",
    "len",
    "max",
    "min",
    "polarity_scores",
    "print",
    "read_text",
    "round",
    "save_chunks",
    "sentence_chunk_text",
    "smart_punctuate",
    "smooth_sentiment_scores",
    "split",
    "strftime"
  ],
  "modules.tts_engine:create_parameter_microbatches": [
    "append",
    "defaultdict",
    "float",
    "get",
    "isinstance",
    "items",
    "len",
    "print",
    "range",
    "sort"
  ],
  "modules.tts_engine:process_book_folder": [
    "Path",
    "ThreadPoolExecutor",
    "_cuda_clearCublasWorkspaces",
    "_release_global_tts_model",
    "add_metadata_to_m4b",
    "append",
    "as_completed",
    "bool",
    "cleanup_asr_model",
    "clear_voice_cache",
    "collect",
    "combine_audio_chunks",
    "convert_to_m4b",
    "copy",
    "create_parameter_microbatches",
    "empty_cache",
    "ensure_voice_sample_compatibility",
    "enumerate",
    "error",
    "estimate_tokens_in_text",
    "exists",
    "extend",
    "find_book_files",
    "float",
    "generate_enriched_chunks",
    "get",
    "get_audio_files_in_directory",
    "get_chunk_audio_duration",
    "get_optimal_workers",
    "getattr",
    "glob",
    "hasattr",
    "info",
    "int",
    "ipc_collect",
    "is_available",
    "isinstance",
    "join",
    "len",
    "load_asr_model_adaptive",
    "load_optimized_model",
    "log_chunk_progress",
    "log_only",
    "log_run",
    "min",
    "pause_for_chunk_review",
    "prewarm_model_with_voice",
    "print",
    "range",
    "record_model_reload",
    "reset_peak_memory_stats",
    "reset_reload_manager",
    "result",
    "round",
    "set_batch_size",
    "setup_book_directories",
    "setup_logging",
    "should_reload_model",
    "sleep",
    "start_terminal_logging",
    "str",
    "strftime",
    "submit",
    "sum",
    "synchronize",
    "time",
    "timedelta",
    "track_chunk_performance",
    "type",
    "unlink"
  ],
  "modules.tts_engine:process_single_batch.log_run": [
    "open",
    "write"
  ],
  "modules.tts_engine:process_single_batch": [
    "Path",
    "cleanup_asr_model",
    "collect",
    "empty_cache",
    "ensure_voice_sample_compatibility",
    "len",
    "load_asr_model_adaptive",
    "load_optimized_model",
    "prewarm_model_with_voice",
    "print",
    "process_batch",
    "punc_norm"
  ],
  "modules.path_validator:detect_problematic_characters": [
    "append",
    "items",
    "search"
  ],
  "modules.path_validator:suggest_safe_path": [
    "sanitize_filename"
  ],
  "modules.path_validator:validate_book_path": [
    "detect_problematic_characters",
    "join",
    "suggest_safe_path"
  ],
  "modules.path_validator:validate_and_create_audiobook_path": [
    "validate_book_path"
  ],
  "modules.path_validator:check_existing_audiobook_paths": [
    "append",
    "detect_problematic_characters",
    "exists",
    "is_dir",
    "iterdir",
    "join",
    "suggest_safe_path"
  ],
  "modules.path_validator:format_path_warning_html": [
    "detect_problematic_characters",
    "validate_book_path"
  ],
  "modules.path_validator:format_path_warning_text": [
    "validate_book_path"
  ],
  "modules.audio_processor:<module>": [
    "warning"
  ],
  "modules.audio_processor:check_audio_health": [
    "abs",
    "len",
    "mean",
    "read",
    "round",
    "sqrt",
    "str"
  ],
  "modules.audio_processor:detect_tts_hum_artifact": [
    "abs",
    "info",
    "len",
    "mean",
    "range",
    "read",
    "rfft",
    "rfftfreq",
    "sqrt",
    "str",
    "sum"
  ],
  "modules.audio_processor:smart_audio_validation": [
    "check_audio_health",
    "detect_tts_hum_artifact",
    "handle_problematic_chunks"
  ],
  "modules.audio_processor:has_mid_energy_drop": [
    "enumerate",
    "int",
    "len",
    "max",
    "mean",
    "numpy",
    "range",
    "sqrt",
    "squeeze"
  ],
  "modules.audio_processor:detect_spectral_artifacts": [
    "abs",
    "array",
    "astype",
    "debug",
    "diff",
    "error",
    "get_array_of_samples",
    "isinstance",
    "len",
    "max",
    "mean",
    "mfcc",
    "min",
    "read",
    "reshape",
    "str",
    "var"
  ],
  "modules.audio_processor:evaluate_chunk_quality": [
    "append",
    "check_audio_health",
    "detect_spectral_artifacts",
    "isinstance",
    "len",
    "sum",
    "validate_output_matches_input"
  ],
  "modules.audio_processor:validate_output_matches_input": [
    "NamedTemporaryFile",
    "calculate_text_similarity",
    "error",
    "export",
    "get",
    "isinstance",
    "load_asr_model_adaptive",
    "str",
    "strip",
    "transcribe",
    "unlink",
    "warning"
  ],
  "modules.audio_processor:calculate_text_similarity.normalize_text": [
    "lower",
    "split",
    "sub"
  ],
  "modules.audio_processor:calculate_text_similarity": [
    "intersection",
    "len",
    "normalize_text",
    "set"
  ],
  "modules.audio_processor:adjust_parameters_for_retry": [
    "copy",
    "max",
    "min"
  ],
  "modules.audio_processor:handle_problematic_chunks": [
    "mkdir",
    "move",
    "str",
    "warning"
  ],
  "modules.audio_processor:pause_for_chunk_review": [
    "any",
    "error",
    "glob",
    "input",
    "iterdir",
    "len",
    "list",
    "move",
    "print",
    "rmdir",
    "str",
    "strip",
    "sub"
  ],
  "modules.audio_processor:detect_end_artifact": [
    "abs",
    "diff",
    "info",
    "int",
    "len",
    "mean",
    "read",
    "rfft",
    "rfftfreq",
    "sign",
    "sqrt",
    "str",
    "sum"
  ],
  "modules.audio_processor:find_end_of_speech": [
    "get",
    "getLogger",
    "get_speech_timestamps",
    "int",
    "items",
    "load",
    "pop",
    "read_audio",
    "setLevel",
    "str"
  ],
  "modules.audio_processor:fade_out_wav": [
    "int",
    "len",
    "linspace",
    "read",
    "str",
    "write"
  ],
  "modules.audio_processor:apply_smart_fade": [
    "detect_end_artifact",
    "fade_out_wav",
    "find_end_of_speech"
  ],
  "modules.audio_processor:apply_smart_fade_memory": [
    "fade_out"
  ],
  "modules.audio_processor:add_contextual_silence_memory": [
    "silent"
  ],
  "modules.audio_processor:smart_fade_out": [
    "detect_silence",
    "export",
    "fade_out",
    "from_wav",
    "get_array_of_samples",
    "info",
    "len",
    "max"
  ],
  "modules.audio_processor:trim_audio_endpoint": [
    "append",
    "array",
    "astype",
    "get_array_of_samples",
    "int",
    "len",
    "max",
    "mean",
    "min",
    "range",
    "reshape",
    "sqrt"
  ],
  "modules.audio_processor:process_audio_with_trimming_and_silence": [
    "add_contextual_silence_memory",
    "trim_audio_endpoint"
  ],
  "modules.audio_processor:add_contextual_silence": [
    "export",
    "from_wav",
    "info",
    "silent"
  ],
  "modules.audio_processor:add_chunk_end_silence": [
    "export",
    "from_wav",
    "info",
    "silent",
    "warning"
  ],
  "modules.audio_processor:get_wav_duration": [
    "float",
    "getframerate",
    "getnframes",
    "open",
    "str"
  ],
  "modules.audio_processor:get_chunk_audio_duration": [
    "get_wav_duration",
    "len",
    "read",
    "str"
  ],
  "modules.bandwidth_monitor:RealTimeBandwidthMonitor.__init__": [
    "Queue"
  ],
  "modules.bandwidth_monitor:RealTimeBandwidthMonitor.start_monitoring": [
    "Thread",
    "print",
    "start"
  ],
  "modules.bandwidth_monitor:RealTimeBandwidthMonitor.stop_monitoring": [
    "_analyze_bandwidth_data",
    "append",
    "empty",
    "get_nowait",
    "join"
  ],
  "modules.bandwidth_monitor:RealTimeBandwidthMonitor._monitor_loop": [
    "_get_bandwidth_sample",
    "get",
    "print",
    "put",
    "sleep",
    "time"
  ],
  "modules.bandwidth_monitor:RealTimeBandwidthMonitor._get_bandwidth_sample": [
    "float",
    "len",
    "run",
    "split",
    "strip"
  ],
  "modules.bandwidth_monitor:RealTimeBandwidthMonitor._analyze_bandwidth_data": [
    "len",
    "max",
    "min",
    "sum"
  ],
  "modules.bandwidth_monitor:TTSBandwidthProfiler.__init__": [
    "RealTimeBandwidthMonitor"
  ],
  "modules.bandwidth_monitor:TTSBandwidthProfiler.profile_tts_generation": [
    "_print_bandwidth_report",
    "generate",
    "len",
    "print",
    "sleep",
    "start_monitoring",
    "stop_monitoring",
    "time"
  ],
  "modules.bandwidth_monitor:TTSBandwidthProfiler._print_bandwidth_report": [
    "print"
  ],
  "modules.bandwidth_monitor:monitor_tts_bandwidth": [
    "TTSBandwidthProfiler",
    "append",
    "enumerate",
    "len",
    "print",
    "profile_tts_generation",
    "sleep"
  ],
  "modules.sequence_batch_processor:<module>": [
    "getLogger"
  ],
  "modules.sequence_batch_processor:SequenceBatchProcessor.__init__": [
    "getLogger"
  ],
  "modules.sequence_batch_processor:SequenceBatchProcessor.analyze_batching_potential": [
    "_generate_recommendations",
    "_group_by_parameters",
    "len",
    "sum"
  ],
  "modules.sequence_batch_processor:SequenceBatchProcessor._group_by_parameters": [
    "_create_parameter_signature",
    "append",
    "defaultdict",
    "enumerate",
    "get",
    "list",
    "sort",
    "values"
  ],
  "modules.sequence_batch_processor:SequenceBatchProcessor._create_parameter_signature": [
    "get",
    "round"
  ],
  "modules.sequence_batch_processor:SequenceBatchProcessor._generate_recommendations": [
    "append",
    "len",
    "sum"
  ],
  "modules.sequence_batch_processor:SequenceBatchProcessor.process_chunks_with_sequence_batching": [
    "_group_by_parameters",
    "_log_performance_summary",
    "_process_parameter_group",
    "enumerate",
    "get",
    "info",
    "len",
    "time"
  ],
  "modules.sequence_batch_processor:SequenceBatchProcessor._process_parameter_group": [
    "_process_chunk_batch",
    "_process_individual_chunk",
    "len",
    "range"
  ],
  "modules.sequence_batch_processor:SequenceBatchProcessor._process_chunk_batch": [
    "_process_individual_chunk",
    "error",
    "generate_batch",
    "get",
    "info",
    "len",
    "time",
    "zip"
  ],
  "modules.sequence_batch_processor:SequenceBatchProcessor._process_individual_chunk": [
    "error",
    "generate",
    "get",
    "info",
    "time",
    "zeros"
  ],
  "modules.sequence_batch_processor:SequenceBatchProcessor._log_performance_summary": [
    "info"
  ],
  "modules.sequence_batch_processor:create_sequence_batch_processor": [
    "SequenceBatchProcessor",
    "info"
  ],
  "modules.gpu_bandwidth_monitor:<module>": [
    "getLogger"
  ],
  "modules.gpu_bandwidth_monitor:GPUBandwidthMonitor.__init__": [
    "Lock",
    "__init__",
    "super"
  ],
  "modules.gpu_bandwidth_monitor:GPUBandwidthMonitor.run": [
    "_sample_gpu",
    "append",
    "debug",
    "info",
    "sleep"
  ],
  "modules.gpu_bandwidth_monitor:GPUBandwidthMonitor._sample_gpu": [
    "GPUSample",
    "float",
    "int",
    "len",
    "run",
    "split",
    "strip",
    "time"
  ],
  "modules.gpu_bandwidth_monitor:GPUBandwidthMonitor.get_statistics": [
    "len",
    "max",
    "min",
    "sum"
  ],
  "modules.gpu_bandwidth_monitor:GPUBandwidthMonitor.print_report": [
    "get_statistics",
    "print",
    "warning"
  ],
  "modules.token_calculator:TTSTokenCalculator.__init__": [
    "getattr",
    "hasattr"
  ],
  "modules.token_calculator:TTSTokenCalculator.analyze_chunks": [
    "analyze_single_chunk",
    "append"
  ],
  "modules.token_calculator:TTSTokenCalculator.analyze_single_chunk": [
    "TokenAnalysis",
    "encode",
    "hasattr",
    "isinstance",
    "len",
    "max",
    "print",
    "size",
    "split",
    "tokenize"
  ],
  "modules.token_calculator:TTSTokenCalculator.print_analysis_summary": [
    "enumerate",
    "len",
    "print"
  ],
  "modules.token_calculator:TTSTokenCalculator.print_real_audiobook_analysis": [
    "append",
    "get",
    "hasattr",
    "len",
    "max",
    "min",
    "print",
    "print_analysis_summary",
    "sorted",
    "sum"
  ],
  "modules.token_calculator:analyze_real_audiobook_chunks": [
    "TTSTokenCalculator",
    "analyze_chunks",
    "analyze_test_chunks",
    "get",
    "len",
    "load",
    "max",
    "min",
    "open",
    "print",
    "print_real_audiobook_analysis",
    "sum"
  ],
  "modules.token_calculator:analyze_test_chunks": [
    "TTSTokenCalculator",
    "analyze_chunks",
    "print_analysis_summary"
  ],
  "modules.text_processor:load_abbreviations": [
    "Path",
    "create_sample_abbreviations_file",
    "enumerate",
    "exists",
    "len",
    "open",
    "print",
    "split",
    "startswith",
    "strip"
  ],
  "modules.text_processor:create_sample_abbreviations_file": [
    "open",
    "print",
    "write"
  ],
  "modules.text_processor:preprocess_abbreviations": [
    "info",
    "items",
    "replace"
  ],
  "modules.text_processor:smart_punctuate": [
    "append",
    "join",
    "load_abbreviations",
    "preprocess_abbreviations",
    "print",
    "replace",
    "search",
    "splitlines",
    "strip",
    "sub"
  ],
  "modules.text_processor:fix_short_sentence_artifacts": [
    "append",
    "endswith",
    "join",
    "len",
    "range",
    "split",
    "strip",
    "sum"
  ],
  "modules.text_processor:_is_apostrophe": [
    "isalpha",
    "len"
  ],
  "modules.text_processor:sentence_chunk_text": [
    "_break_long_sentence_simple",
    "_combine_small_chunks",
    "any",
    "append",
    "enumerate",
    "extend",
    "len",
    "lower",
    "range",
    "split",
    "strip"
  ],
  "modules.text_processor:_break_long_sentence_simple": [
    "append",
    "end",
    "finditer",
    "len",
    "list",
    "reversed",
    "split",
    "strip"
  ],
  "modules.text_processor:_combine_small_chunks": [
    "append",
    "len",
    "split"
  ],
  "modules.text_processor:break_long_sentence_backwards": [
    "append",
    "end",
    "finditer",
    "join",
    "len",
    "list",
    "min",
    "range",
    "split",
    "strip"
  ],
  "modules.text_processor:detect_punctuation_boundary": [
    "endswith",
    "strip"
  ],
  "modules.text_processor:detect_content_boundaries": [
    "detect_punctuation_boundary",
    "len",
    "search",
    "strip"
  ],
  "modules.text_processor:_split_long_dialogue": [
    "_split_long_dialogue",
    "append",
    "end",
    "enumerate",
    "extend",
    "finditer",
    "join",
    "len",
    "list",
    "min",
    "split",
    "strip"
  ],
  "modules.text_processor:reload_abbreviations": [
    "load_abbreviations"
  ],
  "modules.text_processor:test_abbreviations": [
    "load_abbreviations",
    "preprocess_abbreviations",
    "print"
  ],
  "modules.text_processor:test_chunking": [
    "enumerate",
    "len",
    "print",
    "sentence_chunk_text",
    "split"
  ],
  "modules.text_processor:get_chunk_bucket": [
    "len"
  ],
  "modules.text_processor:analyze_chunk_distribution": [
    "append",
    "calculate_optimization_potential",
    "get_chunk_bucket",
    "isinstance",
    "items",
    "len",
    "max",
    "min",
    "sum"
  ],
  "modules.text_processor:calculate_optimization_potential": [
    "max"
  ],
  "modules.text_processor:create_bucketed_chunk_groups": [
    "append",
    "enumerate",
    "get_chunk_bucket",
    "isinstance",
    "items"
  ],
  "modules.text_processor:log_chunk_bucketing_stats": [
    "analyze_chunk_distribution",
    "capitalize",
    "items",
    "log_func",
    "upper"
  ],
  "modules.token_usage_logger:TokenUsageLogger.__init__": [
    "Lock",
    "_initialize_log_file"
  ],
  "modules.token_usage_logger:TokenUsageLogger._initialize_log_file": [
    "now",
    "open",
    "print",
    "write"
  ],
  "modules.token_usage_logger:TokenUsageLogger.start_chunk": [
    "time"
  ],
  "modules.token_usage_logger:TokenUsageLogger.log_chunk_completion": [
    "open",
    "print",
    "time",
    "write"
  ],
  "modules.token_usage_logger:TokenUsageLogger.log_chunk_data": [
    "open",
    "print",
    "write"
  ],
  "modules.token_usage_logger:TokenUsageLogger.get_log_summary": [
    "append",
    "float",
    "int",
    "len",
    "max",
    "min",
    "open",
    "sorted",
    "split",
    "startswith",
    "strip",
    "sum"
  ],
  "modules.token_usage_logger:TokenUsageLogger.print_summary": [
    "float",
    "get_log_summary",
    "print"
  ],
  "modules.token_usage_logger:initialize_token_logging": [
    "TokenUsageLogger"
  ],
  "modules.token_usage_logger:start_chunk_logging": [
    "start_chunk"
  ],
  "modules.token_usage_logger:log_chunk_tokens": [
    "log_chunk_completion"
  ],
  "modules.token_usage_logger:log_chunk_data_direct": [
    "log_chunk_data"
  ],
  "modules.token_usage_logger:print_token_usage_summary": [
    "print",
    "print_summary"
  ],
  "modules.resume_handler:analyze_existing_chunks": [
    "append",
    "exists",
    "get_audio_files_in_directory",
    "group",
    "int",
    "len",
    "match",
    "max",
    "print",
    "range",
    "sort"
  ],
  "modules.resume_handler:suggest_resume_point": [
    "min",
    "print"
  ],
  "modules.resume_handler:validate_resume_point": [
    "print"
  ],
  "modules.resume_handler:process_book_folder_resume": [
    "ThreadPoolExecutor",
    "add_metadata_to_m4b",
    "append",
    "as_completed",
    "cleanup_asr_model",
    "collect",
    "combine_audio_chunks",
    "convert_to_m4b",
    "detect_deployment_environment",
    "empty_cache",
    "enable_gpu_persistence_mode",
    "ensure_voice_sample_compatibility",
    "enumerate",
    "error",
    "exists",
    "extend",
    "find_book_files",
    "find_chunks_json_file",
    "get",
    "get_chunk_audio_duration",
    "get_optimal_workers",
    "info",
    "int",
    "is_dir",
    "isinstance",
    "join",
    "len",
    "load_asr_model_adaptive",
    "load_chunks",
    "load_optimized_model",
    "log_chunk_progress",
    "log_run",
    "min",
    "mkdir",
    "pause_for_chunk_review",
    "prewarm_model_with_voice",
    "print",
    "process_chunks_with_pipeline",
    "range",
    "result",
    "rmtree",
    "setup_book_directories",
    "setup_logging",
    "sleep",
    "str",
    "strftime",
    "submit",
    "sum",
    "time",
    "timedelta",
    "validate_resume_point",
    "warning"
  ],
  "modules.resume_handler:resume_book_from_chunk": [
    "Path",
    "analyze_existing_chunks",
    "dict",
    "enumerate",
    "exists",
    "get_best_available_device",
    "input",
    "int",
    "is_dir",
    "iterdir",
    "len",
    "list_voice_samples",
    "print",
    "process_book_folder_resume",
    "prompt_float",
    "sorted",
    "strip",
    "suggest_resume_point"
  ],
  "modules.resume_handler:resume_book_from_chunk.prompt_float": [
    "float",
    "input",
    "strip"
  ],
  "modules.resume_handler:find_incomplete_books": [
    "analyze_existing_chunks",
    "append",
    "exists",
    "glob",
    "is_dir",
    "iterdir",
    "len",
    "list"
  ],
  "modules.resume_handler:auto_resume_incomplete": [
    "enumerate",
    "find_incomplete_books",
    "input",
    "int",
    "len",
    "lower",
    "print",
    "resume_book_from_chunk",
    "strip"
  ],
  "modules.real_tts_optimizer:RealTTSOptimizer.__init__": [
    "getLogger"
  ],
  "modules.real_tts_optimizer:RealTTSOptimizer.fp32_fallback_mode": [
    "print"
  ],
  "modules.real_tts_optimizer:RealTTSOptimizer.apply_optimizations": [
    "_apply_torch_compile",
    "_optimize_cuda_settings",
    "_optimize_s3gen_inference",
    "_optimize_t3_inference",
    "append",
    "dir",
    "format_exc",
    "get_device_name",
    "hasattr",
    "is_available",
    "join",
    "print",
    "startswith",
    "type"
  ],
  "modules.real_tts_optimizer:RealTTSOptimizer._optimize_t3_inference": [
    "hasattr"
  ],
  "modules.real_tts_optimizer:RealTTSOptimizer._optimize_t3_inference.optimized_t3_inference": [
    "autocast"
  ],
  "modules.real_tts_optimizer:RealTTSOptimizer._optimize_s3gen_inference": [
    "hasattr"
  ],
  "modules.real_tts_optimizer:RealTTSOptimizer._optimize_s3gen_inference.optimized_s3gen_inference": [
    "autocast"
  ],
  "modules.real_tts_optimizer:RealTTSOptimizer._apply_torch_compile": [
    "compile",
    "hasattr",
    "print"
  ],
  "modules.real_tts_optimizer:RealTTSOptimizer._optimize_cuda_settings": [
    "is_available"
  ],
  "modules.real_tts_optimizer:RealTTSOptimizer.restore_original_methods": [
    "hasattr",
    "print"
  ],
  "modules.real_tts_optimizer:get_tts_optimizer": [
    "RealTTSOptimizer"
  ],
  "modules.real_tts_optimizer:optimize_chatterbox_model": [
    "apply_optimizations",
    "get_tts_optimizer"
  ],
  "modules.real_tts_optimizer:optimized_inference": [
    "apply_optimizations",
    "get_tts_optimizer",
    "print",
    "restore_original_methods"
  ],
  "modules.t3_minimal_export:<module>": [
    "Path",
    "export_t3_minimal",
    "insert",
    "str"
  ],
  "modules.t3_minimal_export:create_working_t3_cond": [
    "T3Cond",
    "size"
  ],
  "modules.t3_minimal_export:export_t3_minimal": [
    "InferenceSession",
    "Path",
    "T3WorkingWrapper",
    "astype",
    "collect",
    "cpu",
    "empty_cache",
    "encode",
    "export",
    "is_available",
    "load_t3_minimal",
    "mkdir",
    "numpy",
    "print",
    "print_exc",
    "randn",
    "run",
    "tensor",
    "unsqueeze",
    "wrapper"
  ],
  "modules.t3_minimal_export:export_t3_minimal.T3WorkingWrapper.__init__": [
    "__init__",
    "super"
  ],
  "modules.t3_minimal_export:export_t3_minimal.T3WorkingWrapper.forward": [
    "create_working_t3_cond",
    "full",
    "no_grad",
    "ones",
    "size",
    "t3",
    "zeros"
  ],
  "modules.advanced_optimizations:<module>": [
    "getLogger"
  ],
  "modules.advanced_optimizations:set_warmup_mode": [
    "info"
  ],
  "modules.advanced_optimizations:AdvancedOptimizer.diagnose_and_fix_torch_compile": [
    "append",
    "info",
    "len",
    "run",
    "split"
  ],
  "modules.advanced_optimizations:AdvancedOptimizer.apply_smart_torch_compile": [
    "_test_compiled_method",
    "compile",
    "error",
    "hasattr",
    "info",
    "warning"
  ],
  "modules.advanced_optimizations:AdvancedOptimizer._test_compiled_method": [
    "cuda",
    "info",
    "is_available",
    "randint",
    "randn",
    "warning"
  ],
  "modules.advanced_optimizations:AdvancedOptimizer.apply_advanced_int8_quantization": [
    "_get_model_memory_usage",
    "dict",
    "error",
    "hasattr",
    "info",
    "isinstance",
    "join",
    "named_modules",
    "quantize_dynamic",
    "setattr",
    "split",
    "warning"
  ],
  "modules.advanced_optimizations:AdvancedOptimizer.apply_memory_optimizations": [
    "_enable_efficient_attention",
    "_set_memory_env_vars",
    "contiguous",
    "error",
    "gradient_checkpointing_enable",
    "hasattr",
    "info",
    "is_available",
    "is_contiguous",
    "isinstance",
    "named_modules",
    "named_parameters",
    "to",
    "warning"
  ],
  "modules.advanced_optimizations:AdvancedOptimizer._enable_efficient_attention": [
    "append",
    "enable_flash_sdp",
    "enable_math_sdp",
    "enable_mem_efficient_sdp",
    "hasattr",
    "info",
    "lower",
    "named_modules",
    "warning"
  ],
  "modules.advanced_optimizations:AdvancedOptimizer._set_memory_env_vars": [
    "info",
    "items"
  ],
  "modules.advanced_optimizations:AdvancedOptimizer._get_model_memory_usage": [
    "element_size",
    "hasattr",
    "numel",
    "parameters",
    "sum"
  ],
  "modules.advanced_optimizations:AdvancedOptimizer.revert_optimizations": [
    "clear",
    "error",
    "hasattr",
    "info",
    "items"
  ],
  "modules.advanced_optimizations:get_advanced_optimizer": [
    "AdvancedOptimizer"
  ],
  "modules.advanced_optimizations:optimize_model_advanced": [
    "append",
    "apply_advanced_int8_quantization",
    "apply_memory_optimizations",
    "apply_smart_torch_compile",
    "diagnose_and_fix_torch_compile",
    "error",
    "get_advanced_optimizer",
    "info",
    "join"
  ],
  "modules.progress_tracker:setup_logging": [
    "Formatter",
    "StreamHandler",
    "addHandler",
    "basicConfig",
    "close",
    "getLogger",
    "open",
    "setFormatter",
    "setLevel",
    "str"
  ],
  "modules.progress_tracker:log_console": [
    "get",
    "info",
    "print"
  ],
  "modules.progress_tracker:log_run": [
    "open",
    "write"
  ],
  "modules.progress_tracker:log_chunk_progress": [
    "_status_callback",
    "flush",
    "fmt",
    "get_reload_manager",
    "get_running_avg_its",
    "get_statistics",
    "hasattr",
    "info",
    "monitor_vram_usage",
    "print",
    "time"
  ],
  "modules.progress_tracker:log_chunk_progress.fmt": [
    "int",
    "str",
    "timedelta"
  ],
  "modules.progress_tracker:display_batch_progress": [
    "print"
  ],
  "modules.progress_tracker:display_final_summary": [
    "int",
    "print",
    "timedelta"
  ],
  "modules.progress_tracker:monitor_vram_usage": [
    "is_available",
    "memory_allocated",
    "memory_reserved",
    "optimize_memory_if_needed",
    "warning"
  ],
  "modules.progress_tracker:monitor_gpu_utilization": [
    "nvmlDeviceGetHandleByIndex",
    "nvmlDeviceGetTemperature",
    "nvmlDeviceGetUtilizationRates",
    "nvmlInit"
  ],
  "modules.progress_tracker:optimize_memory_if_needed": [
    "collect",
    "empty_cache",
    "ipc_collect",
    "is_available",
    "optimize_cuda_memory_usage"
  ],
  "modules.progress_tracker:display_system_info": [
    "get_device_name",
    "get_device_properties",
    "is_available",
    "print"
  ],
  "modules.progress_tracker:PerformanceTracker.__init__": [
    "time"
  ],
  "modules.progress_tracker:PerformanceTracker.log_chunk_completion": [
    "append",
    "monitor_vram_usage",
    "sum",
    "time"
  ],
  "modules.progress_tracker:PerformanceTracker.log_batch_completion": [
    "append",
    "len",
    "sum"
  ],
  "modules.progress_tracker:PerformanceTracker.get_performance_summary": [
    "len",
    "max",
    "sum",
    "time"
  ],
  "modules.progress_tracker:log_processing_error": [
    "error",
    "print",
    "strftime"
  ],
  "modules.progress_tracker:log_processing_warning": [
    "print",
    "strftime",
    "warning"
  ],
  "modules.progress_tracker:create_status_line": [
    "int",
    "str",
    "timedelta"
  ],
  "modules.progress_tracker:update_status_line": [
    "print"
  ],
  "modules.progress_tracker:export_performance_report": [
    "int",
    "open",
    "timedelta",
    "write"
  ],
  "modules.simple_token_logger:init_token_log": [
    "exists",
    "makedirs",
    "now",
    "open",
    "strftime",
    "write"
  ],
  "modules.simple_token_logger:log_chunk": [
    "open",
    "write"
  ],
  "modules.asr_manager:get_real_time_vram_status": [
    "device_count",
    "get_device_properties",
    "is_available",
    "memory_allocated",
    "memory_reserved",
    "warning"
  ],
  "modules.asr_manager:calculate_available_vram_for_asr": [
    "get_real_time_vram_status",
    "max"
  ],
  "modules.asr_manager:can_model_fit_gpu": [
    "get"
  ],
  "modules.asr_manager:try_load_model_with_fallback.convert_device_name": [
    "lower"
  ],
  "modules.asr_manager:try_load_model_with_fallback": [
    "Exception",
    "convert_device_name",
    "load_model",
    "print",
    "str",
    "upper"
  ],
  "modules.asr_manager:load_asr_model_adaptive": [
    "calculate_available_vram_for_asr",
    "can_model_fit_gpu",
    "get",
    "get_real_time_vram_status",
    "load_model",
    "lower",
    "print",
    "try_load_model_with_fallback",
    "upper"
  ],
  "modules.asr_manager:cleanup_asr_model": [
    "empty_cache",
    "is_available",
    "print",
    "warning"
  ],
  "modules.asr_manager:get_asr_memory_info": [
    "calculate_available_vram_for_asr",
    "get_real_time_vram_status"
  ],
  "modules.asr_manager:<module>": [
    "cleanup_asr_model",
    "get_asr_memory_info",
    "load_asr_model_adaptive",
    "print"
  ],
  "modules.onnx_optimizer:T3ONNXOptimizer.convert_t3_to_onnx": [
    "T3InferenceWrapper",
    "_initialize_onnx_session",
    "_optimize_onnx_graph",
    "eval",
    "export",
    "join",
    "mkdtemp",
    "print",
    "randint",
    "randn",
    "to"
  ],
  "modules.onnx_optimizer:T3ONNXOptimizer.convert_t3_to_onnx.T3InferenceWrapper.__init__": [
    "__init__",
    "super"
  ],
  "modules.onnx_optimizer:T3ONNXOptimizer.convert_t3_to_onnx.T3InferenceWrapper.forward": [
    "inference"
  ],
  "modules.onnx_optimizer:T3ONNXOptimizer._optimize_onnx_graph": [
    "load",
    "optimize_model",
    "print",
    "replace",
    "save_model_to_file"
  ],
  "modules.onnx_optimizer:T3ONNXOptimizer._initialize_onnx_session": [
    "InferenceSession",
    "SessionOptions",
    "get_providers",
    "print"
  ],
  "modules.onnx_optimizer:T3ONNXOptimizer.onnx_inference": [
    "array",
    "astype",
    "cpu",
    "from_numpy",
    "numpy",
    "print",
    "run",
    "to"
  ],
  "modules.onnx_optimizer:T3ONNXOptimizer.benchmark_onnx_vs_pytorch": [
    "inference",
    "no_grad",
    "onnx_inference",
    "print",
    "randint",
    "randn",
    "range",
    "synchronize",
    "time",
    "to"
  ],
  "modules.onnx_optimizer:optimize_model_with_onnx": [
    "T3ONNXOptimizer",
    "benchmark_onnx_vs_pytorch",
    "convert_t3_to_onnx",
    "print"
  ],
  "modules.onnx_optimizer:optimize_model_with_onnx.onnx_wrapped_inference": [
    "onnx_inference",
    "original_inference"
  ],
  "modules.dual_tts_engine:<module>": [
    "getLogger"
  ],
  "modules.dual_tts_engine:TTSWorker.__init__": [
    "__init__",
    "info",
    "super"
  ],
  "modules.dual_tts_engine:TTSWorker.run": [
    "_process_chunk",
    "error",
    "get",
    "info",
    "put",
    "time"
  ],
  "modules.dual_tts_engine:TTSWorker._process_chunk": [
    "AudioResult",
    "cpu",
    "detach",
    "drop_invalid_tokens",
    "empty_cache",
    "error",
    "from_numpy",
    "generate",
    "get",
    "inference",
    "inference_mode",
    "numpy",
    "pad",
    "punc_norm",
    "squeeze",
    "str",
    "stream",
    "synchronize",
    "text_to_tokens",
    "time",
    "to",
    "unsqueeze"
  ],
  "modules.dual_tts_engine:DualTTSCoordinator.__init__": [
    "Queue",
    "Stream",
    "TTSWorker",
    "info"
  ],
  "modules.dual_tts_engine:DualTTSCoordinator.start": [
    "info",
    "start"
  ],
  "modules.dual_tts_engine:DualTTSCoordinator.stop": [
    "info",
    "join",
    "stop"
  ],
  "modules.dual_tts_engine:DualTTSCoordinator.process_chunks": [
    "Thread",
    "_print_statistics",
    "append",
    "get",
    "info",
    "join",
    "len",
    "sort",
    "start",
    "stop",
    "time",
    "warning"
  ],
  "modules.dual_tts_engine:DualTTSCoordinator._dispatch_chunks": [
    "WorkItem",
    "debug",
    "full",
    "get",
    "put",
    "sleep"
  ],
  "modules.dual_tts_engine:DualTTSCoordinator._print_statistics": [
    "info",
    "len",
    "sum",
    "warning"
  ],
  "modules.dual_tts_engine:load_dual_tts_models": [
    "Path",
    "empty_cache",
    "error",
    "from_local",
    "info",
    "memory_allocated",
    "memory_reserved",
    "str",
    "warning"
  ],
  "modules.batch_processor:<module>": [
    "ArgumentParser",
    "Path",
    "add_argument",
    "append",
    "get",
    "load",
    "open",
    "parse_args",
    "process_single_batch"
  ],
  "modules.system_detector:<module>": [
    "Path",
    "get_system_profile",
    "insert",
    "items",
    "print",
    "print_system_summary",
    "recommend_asr_models",
    "str",
    "upper"
  ],
  "modules.system_detector:get_gpu_memory": [
    "device_count",
    "get_device_properties",
    "is_available",
    "memory_allocated"
  ],
  "modules.system_detector:get_system_memory": [
    "virtual_memory"
  ],
  "modules.system_detector:get_cpu_cores": [
    "cpu_count"
  ],
  "modules.system_detector:get_system_profile": [
    "estimate_tts_vram_usage",
    "get_cpu_cores",
    "get_gpu_memory",
    "get_system_memory",
    "max"
  ],
  "modules.system_detector:get_safe_asr_models": [
    "append",
    "items"
  ],
  "modules.system_detector:get_safe_cpu_models": [
    "append",
    "items"
  ],
  "modules.system_detector:recommend_asr_models": [
    "categorize_system",
    "get_safe_asr_models",
    "get_safe_cpu_models",
    "index",
    "len",
    "max",
    "range",
    "reversed"
  ],
  "modules.system_detector:print_system_summary": [
    "categorize_system",
    "print"
  ],
  "modules.dual_t3_engine:<module>": [
    "getLogger"
  ],
  "modules.dual_t3_engine:TTSWorker.__init__": [
    "__init__",
    "float",
    "info",
    "super"
  ],
  "modules.dual_t3_engine:TTSWorker.run": [
    "_process_chunk",
    "debug",
    "error",
    "get",
    "info",
    "put",
    "time"
  ],
  "modules.dual_t3_engine:TTSWorker._process_chunk": [
    "AudioResult",
    "TokenResult",
    "dim",
    "empty_cache",
    "error",
    "generate",
    "hasattr",
    "inference",
    "len",
    "str",
    "stream",
    "synchronize",
    "time"
  ],
  "modules.dual_t3_engine:S3GenWorker.__init__": [
    "__init__",
    "info",
    "super"
  ],
  "modules.dual_t3_engine:S3GenWorker.run": [
    "_process_tokens",
    "debug",
    "empty",
    "error",
    "get",
    "info",
    "put",
    "time",
    "warning"
  ],
  "modules.dual_t3_engine:S3GenWorker._process_tokens": [
    "AudioResult",
    "cpu",
    "error",
    "inference",
    "numpy",
    "stream",
    "synchronize",
    "time"
  ],
  "modules.dual_t3_engine:DualT3Coordinator.__init__": [
    "Queue",
    "S3GenWorker",
    "Stream",
    "T3Worker",
    "info"
  ],
  "modules.dual_t3_engine:DualT3Coordinator.start": [
    "info",
    "start"
  ],
  "modules.dual_t3_engine:DualT3Coordinator.stop": [
    "info",
    "join",
    "stop"
  ],
  "modules.dual_t3_engine:DualT3Coordinator.process_chunks": [
    "Thread",
    "_print_statistics",
    "append",
    "get",
    "info",
    "join",
    "len",
    "sort",
    "start",
    "stop",
    "time",
    "warning"
  ],
  "modules.dual_t3_engine:DualT3Coordinator._dispatch_chunks": [
    "WorkItem",
    "debug",
    "full",
    "get",
    "put",
    "sleep",
    "time"
  ],
  "modules.dual_t3_engine:DualT3Coordinator._print_statistics": [
    "info",
    "len",
    "sum"
  ],
  "modules.dual_t3_engine:load_dual_t3_models": [
    "Path",
    "empty_cache",
    "error",
    "from_local",
    "info",
    "memory_allocated",
    "memory_reserved",
    "str",
    "warning"
  ],
  "modules.gui_json_generator:<module>": [
    "Path",
    "append",
    "print",
    "str"
  ],
  "modules.gui_json_generator:generate_audiobook_from_json": [
    "Exception",
    "Path",
    "ThreadPoolExecutor",
    "ValueError",
    "all",
    "append",
    "as_completed",
    "combine_audio_for_book",
    "endswith",
    "ensure_voice_sample_compatibility",
    "enumerate",
    "exists",
    "get",
    "glob",
    "index",
    "int",
    "is_available",
    "isinstance",
    "len",
    "list_voice_samples",
    "load_chunks",
    "load_optimized_model",
    "log_chunk_progress",
    "mkdir",
    "prewarm_model_with_voice",
    "print",
    "replace",
    "result",
    "str",
    "submit",
    "time",
    "timedelta",
    "unlink"
  ],
  "modules.gui_json_generator:get_book_name_from_json_path": [
    "Path",
    "endswith",
    "index",
    "len",
    "replace"
  ],
  "modules.file_manager:is_ffmpeg_available": [
    "run"
  ],
  "modules.file_manager:list_voice_samples": [
    "glob",
    "lower",
    "sorted"
  ],
  "modules.file_manager:ensure_voice_sample_compatibility": [
    "basename",
    "dirname",
    "info",
    "join",
    "lower",
    "run",
    "splitext",
    "str"
  ],
  "modules.file_manager:run_ffmpeg": [
    "RuntimeError",
    "error",
    "join",
    "run"
  ],
  "modules.file_manager:convert_to_m4b_with_peak_normalization": [
    "FileNotFoundError",
    "Popen",
    "append",
    "ffmpeg_error_message",
    "group",
    "groups",
    "is_ffmpeg_available",
    "join",
    "map",
    "print",
    "search",
    "str",
    "time",
    "wait"
  ],
  "modules.file_manager:convert_to_m4b_with_loudness_normalization": [
    "FileNotFoundError",
    "Popen",
    "append",
    "convert_to_m4b_with_peak_normalization",
    "ffmpeg_error_message",
    "group",
    "groups",
    "is_ffmpeg_available",
    "join",
    "loads",
    "map",
    "print",
    "run",
    "search",
    "split",
    "startswith",
    "str",
    "strip",
    "time",
    "wait"
  ],
  "modules.file_manager:convert_to_m4b_with_simple_normalization": [
    "FileNotFoundError",
    "Popen",
    "append",
    "ffmpeg_error_message",
    "group",
    "groups",
    "is_ffmpeg_available",
    "join",
    "map",
    "print",
    "search",
    "str",
    "time",
    "wait"
  ],
  "modules.file_manager:convert_to_m4b": [
    "FileNotFoundError",
    "Popen",
    "convert_to_m4b_with_loudness_normalization",
    "convert_to_m4b_with_peak_normalization",
    "convert_to_m4b_with_simple_normalization",
    "ffmpeg_error_message",
    "group",
    "groups",
    "is_ffmpeg_available",
    "map",
    "print",
    "search",
    "str",
    "time",
    "wait"
  ],
  "modules.file_manager:add_metadata_to_m4b": [
    "FileNotFoundError",
    "append",
    "exists",
    "extend",
    "ffmpeg_error_message",
    "is_ffmpeg_available",
    "open",
    "print",
    "run_ffmpeg",
    "split",
    "str",
    "strip",
    "unlink"
  ],
  "modules.file_manager:chunk_sort_key": [
    "group",
    "int",
    "match"
  ],
  "modules.file_manager:create_concat_file": [
    "info",
    "len",
    "open",
    "replace",
    "resolve",
    "str",
    "write"
  ],
  "modules.file_manager:cleanup_temp_files": [
    "glob",
    "unlink"
  ],
  "modules.file_manager:sanitize_filename": [
    "strip",
    "sub"
  ],
  "modules.file_manager:setup_book_directories": [
    "info",
    "mkdir",
    "sanitize_filename"
  ],
  "modules.file_manager:find_book_files": [
    "exists",
    "glob",
    "sorted"
  ],
  "modules.file_manager:combine_audio_chunks": [
    "FileNotFoundError",
    "RuntimeError",
    "append",
    "create_concat_file",
    "error",
    "exists",
    "info",
    "len",
    "mkdir",
    "open",
    "read",
    "resolve",
    "run_ffmpeg",
    "str"
  ],
  "modules.file_manager:get_audio_files_in_directory": [
    "fullmatch",
    "glob",
    "sorted"
  ],
  "modules.file_manager:verify_audio_file": [
    "error",
    "info",
    "str"
  ],
  "modules.file_manager:verify_chunk_completeness": [
    "append",
    "exists",
    "range",
    "verify_audio_file"
  ],
  "modules.file_manager:export_processing_log": [
    "items",
    "open",
    "write"
  ],
  "modules.file_manager:save_chunk_info": [
    "apply_batch_binning",
    "dump",
    "open"
  ],
  "modules.file_manager:apply_batch_binning": [
    "abs",
    "add",
    "append",
    "copy",
    "get",
    "items",
    "len",
    "print",
    "round",
    "set",
    "sum",
    "values"
  ],
  "modules.file_manager:load_chunk_info": [
    "exists",
    "load",
    "open",
    "warning"
  ],
  "modules.vram_bandwidth_monitor:VRAMBandwidthMonitor.start_monitoring.monitor_loop": [
    "_get_vram_snapshot",
    "append",
    "sleep"
  ],
  "modules.vram_bandwidth_monitor:VRAMBandwidthMonitor.start_monitoring": [
    "Thread",
    "print",
    "start"
  ],
  "modules.vram_bandwidth_monitor:VRAMBandwidthMonitor.stop_monitoring": [
    "_analyze_snapshots",
    "join",
    "len",
    "print"
  ],
  "modules.vram_bandwidth_monitor:VRAMBandwidthMonitor._get_vram_snapshot": [
    "VRAMSnapshot",
    "int",
    "len",
    "run",
    "split",
    "strip",
    "time"
  ],
  "modules.vram_bandwidth_monitor:VRAMBandwidthMonitor._analyze_snapshots": [
    "abs",
    "append",
    "len",
    "max",
    "min",
    "range",
    "sum"
  ],
  "modules.vram_bandwidth_monitor:VRAMBandwidthMonitor.print_analysis": [
    "print"
  ],
  "modules.vram_bandwidth_monitor:start_vram_monitoring": [
    "VRAMBandwidthMonitor",
    "start_monitoring"
  ],
  "modules.vram_bandwidth_monitor:stop_vram_monitoring_and_analyze": [
    "print_analysis",
    "stop_monitoring"
  ],
  "modules.vram_bandwidth_monitor:monitor_t3_bandwidth.wrapper": [
    "func",
    "start_vram_monitoring",
    "stop_vram_monitoring_and_analyze"
  ],
  "modules.token_analyzer:<module>": [
    "getLogger"
  ],
  "modules.token_analyzer:TokenAnalyzer.predict_chunk_tokens": [
    "abs",
    "get",
    "int",
    "max",
    "min",
    "warning"
  ],
  "modules.token_analyzer:TokenAnalyzer.analyze_chunks_json": [
    "ValueError",
    "append",
    "error",
    "get",
    "int",
    "len",
    "load",
    "max",
    "mean",
    "median",
    "min",
    "open",
    "percentile",
    "predict_chunk_tokens",
    "std",
    "str"
  ],
  "modules.token_analyzer:TokenAnalyzer.update_max_tokens_config": [
    "Path",
    "error",
    "exists",
    "info",
    "read_text",
    "sub",
    "write_text"
  ],
  "modules.token_analyzer:get_token_analyzer": [
    "TokenAnalyzer"
  ],
  "modules.token_analyzer:analyze_and_optimize_tokens": [
    "__import__",
    "analyze_chunks_json",
    "get_token_analyzer",
    "getattr",
    "update_max_tokens_config"
  ],
  "modules.token_analyzer:format_analysis_summary": [
    "append",
    "get",
    "join"
  ],
  "modules.t3_standalone_export:<module>": [
    "Path",
    "export_t3_standalone",
    "getLogger",
    "insert",
    "str"
  ],
  "modules.t3_standalone_export:find_cached_model_files": [
    "FileNotFoundError",
    "expanduser",
    "get",
    "glob",
    "join",
    "max"
  ],
  "modules.t3_standalone_export:load_t3_minimal": [
    "EnTokenizer",
    "Path",
    "T3",
    "collect",
    "empty_cache",
    "error",
    "eval",
    "find_cached_model_files",
    "get_tensor",
    "is_available",
    "isinstance",
    "keys",
    "load_state_dict",
    "max_memory_allocated",
    "memory_allocated",
    "print",
    "print_exc",
    "reset_peak_memory_stats",
    "safe_open",
    "to"
  ],
  "modules.t3_standalone_export:create_minimal_t3_wrapper.T3MinimalWrapper.__init__": [
    "__init__",
    "super"
  ],
  "modules.t3_standalone_export:create_minimal_t3_wrapper.T3MinimalWrapper.forward": [
    "T3Cond",
    "full",
    "hasattr",
    "no_grad",
    "ones",
    "size",
    "t3",
    "zeros"
  ],
  "modules.t3_standalone_export:create_minimal_t3_wrapper": [
    "T3MinimalWrapper"
  ],
  "modules.t3_standalone_export:export_t3_standalone": [
    "InferenceSession",
    "Path",
    "abs",
    "astype",
    "collect",
    "cpu",
    "create_minimal_t3_wrapper",
    "empty_cache",
    "encode",
    "export",
    "get_available_providers",
    "insert",
    "is_available",
    "load_t3_minimal",
    "max",
    "min",
    "mkdir",
    "numpy",
    "print",
    "print_exc",
    "randn",
    "run",
    "stat",
    "tensor",
    "unsqueeze",
    "wrapper"
  ],
  "config.config:<module>": [
    "Path",
    "get"
  ],
  "src.chatterbox.vc:ChatterboxVC.__init__": [
    "PerthImplicitWatermarker",
    "is_tensor",
    "items",
    "to"
  ],
  "src.chatterbox.vc:ChatterboxVC.from_local": [
    "Path",
    "S3Gen",
    "cls",
    "device",
    "eval",
    "exists",
    "load",
    "load_file",
    "load_state_dict",
    "to"
  ],
  "src.chatterbox.vc:ChatterboxVC.from_pretrained": [
    "Path",
    "from_local",
    "hf_hub_download",
    "is_available",
    "is_built",
    "print"
  ],
  "src.chatterbox.vc:ChatterboxVC.set_target_voice": [
    "embed_ref",
    "load"
  ],
  "src.chatterbox.vc:ChatterboxVC.generate": [
    "apply_watermark",
    "cpu",
    "detach",
    "float",
    "from_numpy",
    "inference",
    "inference_mode",
    "load",
    "numpy",
    "set_target_voice",
    "squeeze",
    "to",
    "tokenizer",
    "unsqueeze"
  ],
  "src.chatterbox.text_utils:detect_language": [
    "findall",
    "len",
    "sub"
  ],
  "src.chatterbox.text_utils:split_by_word_boundary": [
    "_split_cjk_text",
    "_split_spaced_text",
    "append",
    "detect_language",
    "extend",
    "get_punctuation_pattern",
    "len",
    "split"
  ],
  "src.chatterbox.text_utils:_split_cjk_text": [
    "append",
    "len",
    "search"
  ],
  "src.chatterbox.text_utils:_split_spaced_text": [
    "append",
    "len",
    "split",
    "strip"
  ],
  "src.chatterbox.text_utils:merge_short_sentences": [
    "append",
    "detect_language",
    "len",
    "max",
    "strip"
  ],
  "src.chatterbox.text_utils:split_text_into_segments": [
    "append",
    "debug",
    "detect_language",
    "extend",
    "get_sentence_separators",
    "len",
    "merge_short_sentences",
    "split",
    "split_by_word_boundary",
    "strip"
  ],
  "src.chatterbox.tts:punc_norm": [
    "any",
    "endswith",
    "islower",
    "join",
    "len",
    "replace",
    "rstrip",
    "split",
    "upper"
  ],
  "src.chatterbox.tts:Conditionals.to": [
    "is_tensor",
    "items",
    "to"
  ],
  "src.chatterbox.tts:Conditionals.save": [
    "dict",
    "save"
  ],
  "src.chatterbox.tts:Conditionals.load": [
    "T3Cond",
    "cls",
    "device",
    "isinstance",
    "load"
  ],
  "src.chatterbox.tts:ChatterboxTTS.__init__": [
    "PerthImplicitWatermarker"
  ],
  "src.chatterbox.tts:ChatterboxTTS.from_local": [
    "EnTokenizer",
    "Path",
    "S3Gen",
    "T3",
    "VoiceEncoder",
    "cls",
    "device",
    "eval",
    "exists",
    "getenv",
    "keys",
    "load",
    "load_file",
    "load_state_dict",
    "str",
    "to"
  ],
  "src.chatterbox.tts:ChatterboxTTS.from_pretrained": [
    "Path",
    "from_local",
    "hf_hub_download",
    "is_available",
    "is_built",
    "print"
  ],
  "src.chatterbox.tts:ChatterboxTTS.prepare_conditionals": [
    "Conditionals",
    "T3Cond",
    "atleast_2d",
    "embed_ref",
    "embeds_from_wavs",
    "forward",
    "from_numpy",
    "load",
    "mean",
    "ones",
    "resample",
    "to"
  ],
  "src.chatterbox.tts:ChatterboxTTS.generate": [
    "NamedTemporaryFile",
    "T3Cond",
    "_clean_artifacts",
    "_generate_long_text_async",
    "_generate_single_segment",
    "append",
    "cat",
    "create_silence",
    "exists",
    "len",
    "load",
    "ones",
    "parse_pause_tags",
    "prepare_conditionals",
    "print",
    "save",
    "squeeze",
    "strip",
    "to",
    "unlink",
    "unsqueeze"
  ],
  "src.chatterbox.tts:ChatterboxTTS._generate_long_text_async": [
    "_clean_audio_segments_batch",
    "_generate_segments_async",
    "append",
    "cat",
    "create_silence",
    "enumerate",
    "extend",
    "len",
    "parse_pause_tags",
    "round",
    "split_text_into_segments",
    "squeeze",
    "strip",
    "unsqueeze"
  ],
  "src.chatterbox.tts:ChatterboxTTS._generate_segments_async": [
    "Queue",
    "ThreadPoolExecutor",
    "as_completed",
    "create_silence",
    "empty",
    "enumerate",
    "get",
    "len",
    "min",
    "result",
    "submit"
  ],
  "src.chatterbox.tts:ChatterboxTTS._generate_segments_async.generate_worker": [
    "_generate_single_segment",
    "create_silence",
    "punc_norm",
    "put",
    "str",
    "strip"
  ],
  "src.chatterbox.tts:ChatterboxTTS._clean_audio_segments_batch": [
    "NamedTemporaryFile",
    "_clean_artifacts",
    "append",
    "enumerate",
    "exists",
    "load",
    "print",
    "save",
    "unlink"
  ],
  "src.chatterbox.tts:ChatterboxTTS._generate_single_segment": [
    "apply_watermark",
    "cpu",
    "detach",
    "drop_invalid_tokens",
    "from_numpy",
    "inference",
    "inference_mode",
    "numpy",
    "pad",
    "punc_norm",
    "squeeze",
    "text_to_tokens",
    "to",
    "unsqueeze"
  ],
  "src.chatterbox.tts:ChatterboxTTS._clean_artifacts": [
    "NamedTemporaryFile",
    "RuntimeError",
    "close",
    "exists",
    "getsize",
    "join",
    "print",
    "run",
    "unlink"
  ],
  "src.chatterbox.tts:ChatterboxTTS.generate_batch": [
    "T3Cond",
    "append",
    "apply_watermark",
    "cpu",
    "detach",
    "drop_invalid_tokens",
    "from_numpy",
    "inference",
    "inference_mode",
    "max",
    "numpy",
    "ones",
    "pad",
    "prepare_conditionals",
    "punc_norm",
    "squeeze",
    "stack",
    "text_to_tokens",
    "to",
    "unsqueeze"
  ],
  "src.chatterbox.tts:parse_pause_tags": [
    "append",
    "end",
    "finditer",
    "float",
    "group",
    "int",
    "max",
    "round",
    "start",
    "strip",
    "sub"
  ],
  "src.chatterbox.tts:parse_pause_tags._repl": [
    "get",
    "group"
  ],
  "src.chatterbox.tts:create_silence": [
    "int",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.s3gen:drop_invalid_tokens": [
    "len"
  ],
  "src.chatterbox.models.s3gen.s3gen:get_resampler": [
    "Resample",
    "lru_cache",
    "to"
  ],
  "src.chatterbox.models.s3gen.s3gen:S3Token2Mel.__init__": [
    "CAMPPlus",
    "CausalConditionalCFM",
    "CausalMaskedDiffWithXvec",
    "ConditionalDecoder",
    "DictConfig",
    "S3Tokenizer",
    "UpsampleConformerEncoder",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.s3gen:S3Token2Mel.device": [
    "next",
    "parameters"
  ],
  "src.chatterbox.models.s3gen.s3gen:S3Token2Mel.embed_ref": [
    "dict",
    "float",
    "from_numpy",
    "get_resampler",
    "inference",
    "isinstance",
    "len",
    "mel_extractor",
    "print",
    "size",
    "to",
    "tokenizer",
    "transpose",
    "unsqueeze",
    "warning"
  ],
  "src.chatterbox.models.s3gen.s3gen:S3Token2Mel.forward": [
    "LongTensor",
    "embed_ref",
    "from_numpy",
    "inference",
    "is_tensor",
    "isinstance",
    "len",
    "list",
    "size",
    "to",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.s3gen:S3Token2Wav.__init__": [
    "ConvRNNF0Predictor",
    "HiFTGenerator",
    "__init__",
    "cos",
    "linspace",
    "register_buffer",
    "super",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.s3gen:S3Token2Wav.forward": [
    "forward",
    "inference",
    "len",
    "min",
    "size",
    "super",
    "to",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.s3gen:S3Token2Wav.flow_inference": [
    "forward",
    "inference_mode",
    "super"
  ],
  "src.chatterbox.models.s3gen.s3gen:S3Token2Wav.hift_inference": [
    "inference",
    "inference_mode",
    "to",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.s3gen:S3Token2Wav.inference": [
    "flow_inference",
    "hift_inference",
    "inference_mode",
    "len",
    "min",
    "size"
  ],
  "src.chatterbox.models.s3gen.f0_predictor:ConvRNNF0Predictor.__init__": [
    "Conv1d",
    "ELU",
    "Linear",
    "Sequential",
    "__init__",
    "super",
    "weight_norm"
  ],
  "src.chatterbox.models.s3gen.f0_predictor:ConvRNNF0Predictor.forward": [
    "abs",
    "classifier",
    "condnet",
    "squeeze",
    "transpose"
  ],
  "src.chatterbox.models.s3gen.flow:MaskedDiffWithXvec.__init__": [
    "DictConfig",
    "Embedding",
    "Linear",
    "__init__",
    "info",
    "output_size",
    "super"
  ],
  "src.chatterbox.models.s3gen.flow:MaskedDiffWithXvec.forward": [
    "clamp",
    "compute_loss",
    "contiguous",
    "encoder",
    "encoder_proj",
    "enumerate",
    "float",
    "input_embedding",
    "int",
    "interpolate",
    "length_regulator",
    "make_pad_mask",
    "normalize",
    "randint",
    "random",
    "spk_embed_affine_layer",
    "squeeze",
    "to",
    "transpose",
    "unsqueeze",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.flow:MaskedDiffWithXvec.inference": [
    "clamp",
    "concat",
    "contiguous",
    "decoder",
    "encoder",
    "encoder_proj",
    "float",
    "half",
    "inference",
    "inference_mode",
    "input_embedding",
    "int",
    "make_pad_mask",
    "normalize",
    "spk_embed_affine_layer",
    "tensor",
    "to",
    "transpose",
    "unsqueeze",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.flow:CausalMaskedDiffWithXvec.__init__": [
    "DictConfig",
    "Embedding",
    "Linear",
    "__init__",
    "info",
    "output_size",
    "super"
  ],
  "src.chatterbox.models.s3gen.flow:CausalMaskedDiffWithXvec.inference": [
    "clamp",
    "concat",
    "contiguous",
    "decoder",
    "encoder",
    "encoder_proj",
    "float",
    "half",
    "inference_mode",
    "input_embedding",
    "make_pad_mask",
    "normalize",
    "spk_embed_affine_layer",
    "tensor",
    "to",
    "transpose",
    "unsqueeze",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.decoder:mask_to_bias": [
    "to"
  ],
  "src.chatterbox.models.s3gen.decoder:Transpose.__init__": [
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.decoder:Transpose.forward": [
    "transpose"
  ],
  "src.chatterbox.models.s3gen.decoder:CausalBlock1D.__init__": [
    "CausalConv1d",
    "LayerNorm",
    "Mish",
    "Sequential",
    "Transpose",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.decoder:CausalBlock1D.forward": [
    "block"
  ],
  "src.chatterbox.models.s3gen.decoder:CausalResnetBlock1D.__init__": [
    "CausalBlock1D",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.decoder:CausalConv1d.__init__": [
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.decoder:CausalConv1d.forward": [
    "forward",
    "pad",
    "super"
  ],
  "src.chatterbox.models.s3gen.decoder:ConditionalDecoder.__init__": [
    "BasicTransformerBlock",
    "Block1D",
    "CausalBlock1D",
    "CausalConv1d",
    "CausalResnetBlock1D",
    "Conv1d",
    "Downsample1D",
    "ModuleList",
    "ResnetBlock1D",
    "SinusoidalPosEmb",
    "TimestepEmbedding",
    "Upsample1D",
    "__init__",
    "append",
    "initialize_weights",
    "len",
    "range",
    "super",
    "tuple"
  ],
  "src.chatterbox.models.s3gen.decoder:ConditionalDecoder.initialize_weights": [
    "constant_",
    "isinstance",
    "kaiming_normal_",
    "modules"
  ],
  "src.chatterbox.models.s3gen.decoder:ConditionalDecoder.forward": [
    "add_optional_chunk_mask",
    "append",
    "bool",
    "contiguous",
    "downsample",
    "final_block",
    "final_proj",
    "mask_to_bias",
    "pack",
    "pop",
    "rearrange",
    "repeat",
    "resnet",
    "time_embeddings",
    "time_mlp",
    "to",
    "transformer_block",
    "upsample"
  ],
  "src.chatterbox.models.s3gen.hifigan:Snake.__init__": [
    "Parameter",
    "__init__",
    "ones",
    "super",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.hifigan:Snake.forward": [
    "exp",
    "pow",
    "sin",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.hifigan:get_padding": [
    "int"
  ],
  "src.chatterbox.models.s3gen.hifigan:init_weights": [
    "find",
    "normal_"
  ],
  "src.chatterbox.models.s3gen.hifigan:ResBlock.__init__": [
    "Conv1d",
    "ModuleList",
    "Snake",
    "__init__",
    "append",
    "apply",
    "get_padding",
    "len",
    "range",
    "super",
    "weight_norm"
  ],
  "src.chatterbox.models.s3gen.hifigan:ResBlock.forward": [
    "len",
    "range"
  ],
  "src.chatterbox.models.s3gen.hifigan:ResBlock.remove_weight_norm": [
    "len",
    "range",
    "remove_weight_norm"
  ],
  "src.chatterbox.models.s3gen.hifigan:SineGen.__init__": [
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.hifigan:SineGen._f02uv": [
    "type"
  ],
  "src.chatterbox.models.s3gen.hifigan:SineGen.forward": [
    "Uniform",
    "_f02uv",
    "cumsum",
    "no_grad",
    "randn_like",
    "range",
    "sample",
    "sin",
    "size",
    "to",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.hifigan:SourceModuleHnNSF.__init__": [
    "Linear",
    "SineGen",
    "Tanh",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.hifigan:SourceModuleHnNSF.forward": [
    "l_linear",
    "l_sin_gen",
    "l_tanh",
    "no_grad",
    "randn_like",
    "transpose"
  ],
  "src.chatterbox.models.s3gen.hifigan:HiFTGenerator.__init__": [
    "Conv1d",
    "ConvTranspose1d",
    "ModuleList",
    "ReflectionPad1d",
    "ResBlock",
    "SourceModuleHnNSF",
    "Upsample",
    "__init__",
    "append",
    "apply",
    "astype",
    "cumprod",
    "enumerate",
    "from_numpy",
    "get_window",
    "len",
    "prod",
    "range",
    "super",
    "weight_norm",
    "zip"
  ],
  "src.chatterbox.models.s3gen.hifigan:HiFTGenerator.remove_weight_norm": [
    "print",
    "remove_weight_norm"
  ],
  "src.chatterbox.models.s3gen.hifigan:HiFTGenerator._stft": [
    "stft",
    "to",
    "view_as_real"
  ],
  "src.chatterbox.models.s3gen.hifigan:HiFTGenerator._istft": [
    "clip",
    "complex",
    "cos",
    "istft",
    "sin",
    "to"
  ],
  "src.chatterbox.models.s3gen.hifigan:HiFTGenerator.decode": [
    "_istft",
    "_stft",
    "cat",
    "clamp",
    "conv_post",
    "conv_pre",
    "exp",
    "leaky_relu",
    "range",
    "reflection_pad",
    "sin",
    "squeeze",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.hifigan:HiFTGenerator.forward": [
    "decode",
    "f0_predictor",
    "f0_upsamp",
    "m_source",
    "to",
    "transpose"
  ],
  "src.chatterbox.models.s3gen.hifigan:HiFTGenerator.inference": [
    "decode",
    "f0_predictor",
    "f0_upsamp",
    "inference_mode",
    "m_source",
    "transpose",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.xvector:pad_list": [
    "fill_",
    "len",
    "max",
    "new",
    "range",
    "size"
  ],
  "src.chatterbox.models.s3gen.xvector:extract_feature": [
    "append",
    "fbank",
    "mean",
    "pad_list",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.xvector:BasicResBlock.__init__": [
    "BatchNorm2d",
    "Conv2d",
    "Sequential",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.xvector:BasicResBlock.forward": [
    "bn1",
    "bn2",
    "conv1",
    "conv2",
    "relu",
    "shortcut"
  ],
  "src.chatterbox.models.s3gen.xvector:FCM.__init__": [
    "BatchNorm2d",
    "Conv2d",
    "__init__",
    "_make_layer",
    "super"
  ],
  "src.chatterbox.models.s3gen.xvector:FCM._make_layer": [
    "Sequential",
    "append",
    "block"
  ],
  "src.chatterbox.models.s3gen.xvector:FCM.forward": [
    "bn1",
    "bn2",
    "conv1",
    "conv2",
    "layer1",
    "layer2",
    "relu",
    "reshape",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.xvector:get_nonlinear": [
    "BatchNorm1d",
    "PReLU",
    "ReLU",
    "Sequential",
    "ValueError",
    "add_module",
    "format",
    "split"
  ],
  "src.chatterbox.models.s3gen.xvector:statistics_pooling": [
    "cat",
    "mean",
    "std",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.xvector:StatsPool.forward": [
    "statistics_pooling"
  ],
  "src.chatterbox.models.s3gen.xvector:TDNNLayer.__init__": [
    "Conv1d",
    "__init__",
    "format",
    "get_nonlinear",
    "super"
  ],
  "src.chatterbox.models.s3gen.xvector:TDNNLayer.forward": [
    "linear",
    "nonlinear"
  ],
  "src.chatterbox.models.s3gen.xvector:CAMLayer.__init__": [
    "Conv1d",
    "ReLU",
    "Sigmoid",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.xvector:CAMLayer.forward": [
    "linear1",
    "linear2",
    "linear_local",
    "mean",
    "relu",
    "seg_pooling",
    "sigmoid"
  ],
  "src.chatterbox.models.s3gen.xvector:CAMLayer.seg_pooling": [
    "ValueError",
    "avg_pool1d",
    "expand",
    "max_pool1d",
    "reshape",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.xvector:CAMDenseTDNNLayer.__init__": [
    "CAMLayer",
    "Conv1d",
    "__init__",
    "format",
    "get_nonlinear",
    "super"
  ],
  "src.chatterbox.models.s3gen.xvector:CAMDenseTDNNLayer.bn_function": [
    "linear1",
    "nonlinear1"
  ],
  "src.chatterbox.models.s3gen.xvector:CAMDenseTDNNLayer.forward": [
    "bn_function",
    "cam_layer",
    "checkpoint",
    "nonlinear2"
  ],
  "src.chatterbox.models.s3gen.xvector:CAMDenseTDNNBlock.__init__": [
    "CAMDenseTDNNLayer",
    "__init__",
    "add_module",
    "range",
    "super"
  ],
  "src.chatterbox.models.s3gen.xvector:CAMDenseTDNNBlock.forward": [
    "cat",
    "layer"
  ],
  "src.chatterbox.models.s3gen.xvector:TransitLayer.__init__": [
    "Conv1d",
    "__init__",
    "get_nonlinear",
    "super"
  ],
  "src.chatterbox.models.s3gen.xvector:TransitLayer.forward": [
    "linear",
    "nonlinear"
  ],
  "src.chatterbox.models.s3gen.xvector:DenseLayer.__init__": [
    "Conv1d",
    "__init__",
    "get_nonlinear",
    "super"
  ],
  "src.chatterbox.models.s3gen.xvector:DenseLayer.forward": [
    "len",
    "linear",
    "nonlinear",
    "squeeze",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.xvector:CAMPPlus.__init__": [
    "CAMDenseTDNNBlock",
    "DenseLayer",
    "FCM",
    "OrderedDict",
    "Sequential",
    "StatsPool",
    "TDNNLayer",
    "TransitLayer",
    "__init__",
    "add_module",
    "enumerate",
    "get_nonlinear",
    "isinstance",
    "kaiming_normal_",
    "modules",
    "super",
    "zeros_",
    "zip"
  ],
  "src.chatterbox.models.s3gen.xvector:CAMPPlus.forward": [
    "head",
    "permute",
    "transpose",
    "xvector"
  ],
  "src.chatterbox.models.s3gen.xvector:CAMPPlus.inference": [
    "extract_feature",
    "forward",
    "to"
  ],
  "src.chatterbox.models.s3gen.flow_matching:<module>": [
    "create"
  ],
  "src.chatterbox.models.s3gen.flow_matching:ConditionalCFM.__init__": [
    "Lock",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.flow_matching:ConditionalCFM.forward": [
    "concat",
    "cos",
    "inference_mode",
    "linspace",
    "randn_like",
    "solve_euler",
    "stack",
    "to",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.flow_matching:ConditionalCFM.solve_euler": [
    "append",
    "float",
    "forward_estimator",
    "len",
    "range",
    "size",
    "split",
    "unsqueeze",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.flow_matching:ConditionalCFM.forward_estimator": [
    "contiguous",
    "data_ptr",
    "execute_v2",
    "forward",
    "isinstance",
    "set_input_shape",
    "size"
  ],
  "src.chatterbox.models.s3gen.flow_matching:ConditionalCFM.compute_loss": [
    "cos",
    "estimator",
    "mse_loss",
    "rand",
    "randn_like",
    "squeeze",
    "sum",
    "view"
  ],
  "src.chatterbox.models.s3gen.flow_matching:CausalConditionalCFM.__init__": [
    "__init__",
    "randn",
    "super"
  ],
  "src.chatterbox.models.s3gen.flow_matching:CausalConditionalCFM.forward": [
    "cos",
    "inference_mode",
    "linspace",
    "size",
    "solve_euler",
    "to"
  ],
  "src.chatterbox.models.tokenizers.tokenizer:<module>": [
    "getLogger"
  ],
  "src.chatterbox.models.tokenizers.tokenizer:EnTokenizer.__init__": [
    "check_vocabset_sot_eot",
    "from_file"
  ],
  "src.chatterbox.models.tokenizers.tokenizer:EnTokenizer.check_vocabset_sot_eot": [
    "get_vocab"
  ],
  "src.chatterbox.models.tokenizers.tokenizer:EnTokenizer.text_to_tokens": [
    "IntTensor",
    "encode",
    "unsqueeze"
  ],
  "src.chatterbox.models.tokenizers.tokenizer:EnTokenizer.encode": [
    "encode",
    "replace"
  ],
  "src.chatterbox.models.tokenizers.tokenizer:EnTokenizer.decode": [
    "cpu",
    "decode",
    "isinstance",
    "numpy",
    "replace"
  ],
  "src.chatterbox.models.s3tokenizer.__init__:drop_invalid_tokens": [
    "len",
    "nonzero",
    "squeeze"
  ],
  "src.chatterbox.models.s3tokenizer.s3tokenizer:S3Tokenizer.__init__": [
    "FloatTensor",
    "ModelConfig",
    "__init__",
    "hann_window",
    "mel",
    "register_buffer",
    "super"
  ],
  "src.chatterbox.models.s3tokenizer.s3tokenizer:S3Tokenizer.pad": [
    "append",
    "ceil",
    "dim",
    "from_numpy",
    "int",
    "isinstance",
    "pad",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3tokenizer.s3tokenizer:S3Tokenizer._prepare_audio": [
    "append",
    "dim",
    "from_numpy",
    "isinstance",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3tokenizer.s3tokenizer:S3Tokenizer.forward": [
    "_prepare_audio",
    "append",
    "detach",
    "log_mel_spectrogram",
    "long",
    "no_grad",
    "padding",
    "quantize",
    "squeeze",
    "to",
    "unwrap_model"
  ],
  "src.chatterbox.models.s3tokenizer.s3tokenizer:S3Tokenizer.log_mel_spectrogram": [
    "abs",
    "clamp",
    "from_numpy",
    "is_tensor",
    "log10",
    "max",
    "maximum",
    "pad",
    "stft",
    "to"
  ],
  "src.chatterbox.models.t3.t3:<module>": [
    "getLogger"
  ],
  "src.chatterbox.models.t3.t3:AttrDict.__init__": [
    "__init__",
    "super"
  ],
  "src.chatterbox.models.t3.t3:_ensure_BOT_EOT": [
    "int",
    "size",
    "sum"
  ],
  "src.chatterbox.models.t3.t3:T3.__init__": [
    "Embedding",
    "LearnedPositionEmbeddings",
    "Linear",
    "LlamaConfig",
    "LlamaModel",
    "T3CondEnc",
    "T3Config",
    "__init__",
    "setattr",
    "super"
  ],
  "src.chatterbox.models.t3.t3:T3.prepare_conditioning": [
    "cond_enc",
    "speech_emb",
    "speech_pos_emb"
  ],
  "src.chatterbox.models.t3.t3:T3.prepare_input_embeds": [
    "cat",
    "expand",
    "prepare_conditioning",
    "repeat",
    "size",
    "speech_emb",
    "speech_pos_emb",
    "text_emb",
    "text_pos_emb",
    "zeros_like"
  ],
  "src.chatterbox.models.t3.t3:T3.forward": [
    "AttrDict",
    "_ensure_BOT_EOT",
    "forward",
    "item",
    "prepare_input_embeds",
    "range",
    "size",
    "speech_head",
    "text_head",
    "zeros"
  ],
  "src.chatterbox.models.t3.t3:T3.loss": [
    "arange",
    "cross_entropy",
    "forward",
    "masked_fill",
    "max",
    "size"
  ],
  "src.chatterbox.models.t3.t3:T3.inference": [
    "AlignmentStreamAnalyzer",
    "MinPLogitsWarper",
    "RepetitionPenaltyLogitsProcessor",
    "T3HuggingfaceBackend",
    "TopPLogitsWarper",
    "_ensure_BOT_EOT",
    "all",
    "atleast_2d",
    "cat",
    "close",
    "empty",
    "full",
    "get_fixed_embedding",
    "hasattr",
    "inference_mode",
    "int",
    "min_p_warper",
    "multinomial",
    "ones_like",
    "patched_model",
    "prepare_input_embeds",
    "range",
    "repetition_penalty_processor",
    "size",
    "softmax",
    "speech_emb",
    "squeeze",
    "to",
    "top_p_warper",
    "tqdm",
    "view"
  ],
  "src.chatterbox.models.t3.llama_configs:<module>": [
    "dict"
  ],
  "src.chatterbox.models.voice_encoder.voice_encoder:pack": [
    "array",
    "as_tensor",
    "enumerate",
    "full",
    "isinstance",
    "len",
    "max",
    "size"
  ],
  "src.chatterbox.models.voice_encoder.voice_encoder:get_num_wins": [
    "divmod",
    "max"
  ],
  "src.chatterbox.models.voice_encoder.voice_encoder:get_frame_step": [
    "int",
    "round"
  ],
  "src.chatterbox.models.voice_encoder.voice_encoder:stride_as_partials": [
    "as_strided",
    "astype",
    "concatenate",
    "full",
    "get_frame_step",
    "get_num_wins",
    "len"
  ],
  "src.chatterbox.models.voice_encoder.voice_encoder:VoiceEncoder.__init__": [
    "LSTM",
    "Linear",
    "Parameter",
    "VoiceEncConfig",
    "__init__",
    "flatten_parameters",
    "super",
    "tensor"
  ],
  "src.chatterbox.models.voice_encoder.voice_encoder:VoiceEncoder.device": [
    "next",
    "parameters"
  ],
  "src.chatterbox.models.voice_encoder.voice_encoder:VoiceEncoder.forward": [
    "Exception",
    "lstm",
    "max",
    "min",
    "norm",
    "proj",
    "relu"
  ],
  "src.chatterbox.models.voice_encoder.voice_encoder:VoiceEncoder.inference": [
    "all",
    "cat",
    "ceil",
    "chunk",
    "concatenate",
    "cpu",
    "cumsum",
    "full",
    "get_frame_step",
    "get_num_wins",
    "int",
    "is_tensor",
    "len",
    "max",
    "mean",
    "norm",
    "range",
    "self",
    "size",
    "stack",
    "to",
    "tolist",
    "zip"
  ],
  "src.chatterbox.models.voice_encoder.voice_encoder:VoiceEncoder.utt_to_spk_embed": [
    "mean",
    "norm"
  ],
  "src.chatterbox.models.voice_encoder.voice_encoder:VoiceEncoder.voice_similarity": [
    "utt_to_spk_embed"
  ],
  "src.chatterbox.models.voice_encoder.voice_encoder:VoiceEncoder.embeds_from_mels": [
    "all",
    "asarray",
    "inference",
    "inference_mode",
    "isinstance",
    "numpy",
    "pack",
    "to",
    "utt_to_spk_embed"
  ],
  "src.chatterbox.models.voice_encoder.voice_encoder:VoiceEncoder.embeds_from_wavs": [
    "embeds_from_mels",
    "melspectrogram",
    "resample",
    "trim"
  ],
  "src.chatterbox.models.voice_encoder.melspec:mel_basis": [
    "lru_cache",
    "mel"
  ],
  "src.chatterbox.models.voice_encoder.melspec:preemphasis": [
    "clip",
    "lfilter"
  ],
  "src.chatterbox.models.voice_encoder.melspec:melspectrogram": [
    "_amp_to_db",
    "_normalize",
    "_stft",
    "abs",
    "astype",
    "dot",
    "len",
    "max",
    "mel_basis",
    "preemphasis"
  ],
  "src.chatterbox.models.voice_encoder.melspec:_stft": [
    "stft"
  ],
  "src.chatterbox.models.voice_encoder.melspec:_amp_to_db": [
    "log10",
    "maximum"
  ],
  "src.chatterbox.models.voice_encoder.melspec:_db_to_amp": [
    "power"
  ],
  "src.chatterbox.models.voice_encoder.melspec:_normalize": [
    "log10"
  ],
  "src.chatterbox.models.s3gen.utils.mel:dynamic_range_compression_torch": [
    "clamp",
    "log"
  ],
  "src.chatterbox.models.s3gen.utils.mel:spectral_normalize_torch": [
    "dynamic_range_compression_torch"
  ],
  "src.chatterbox.models.s3gen.utils.mel:mel_spectrogram": [
    "float",
    "from_numpy",
    "hann_window",
    "int",
    "isinstance",
    "len",
    "librosa_mel_fn",
    "matmul",
    "max",
    "min",
    "pad",
    "pow",
    "print",
    "spectral_normalize_torch",
    "sqrt",
    "squeeze",
    "stft",
    "str",
    "sum",
    "tensor",
    "to",
    "unsqueeze",
    "view_as_real"
  ],
  "src.chatterbox.models.s3gen.utils.class_utils:<module>": [
    "getattr"
  ],
  "src.chatterbox.models.s3gen.utils.mask:subsequent_chunk_mask": [
    "arange",
    "device",
    "div",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.utils.mask:add_optional_chunk_mask": [
    "item",
    "randint",
    "size",
    "subsequent_chunk_mask",
    "sum",
    "unsqueeze",
    "warning"
  ],
  "src.chatterbox.models.s3gen.utils.mask:make_pad_mask": [
    "arange",
    "expand",
    "item",
    "max",
    "size",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:BaseSubsampling.__init__": [
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:BaseSubsampling.position_encoding": [
    "position_encoding"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:EmbedinigNoSubsampling.__init__": [
    "Embedding",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:EmbedinigNoSubsampling.forward": [
    "embed",
    "pos_enc"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:LinearNoSubsampling.__init__": [
    "Dropout",
    "LayerNorm",
    "Linear",
    "Sequential",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:LinearNoSubsampling.forward": [
    "out",
    "pos_enc"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:Conv1dSubsampling2.__init__": [
    "Conv1d",
    "GELU",
    "Sequential",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:Conv1dSubsampling2.forward": [
    "conv",
    "pos_enc",
    "size",
    "transpose"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:Conv2dSubsampling4.__init__": [
    "Conv2d",
    "Linear",
    "ReLU",
    "Sequential",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:Conv2dSubsampling4.forward": [
    "contiguous",
    "conv",
    "out",
    "pos_enc",
    "size",
    "transpose",
    "unsqueeze",
    "view"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:Conv2dSubsampling6.__init__": [
    "Conv2d",
    "Linear",
    "ReLU",
    "Sequential",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:Conv2dSubsampling6.forward": [
    "contiguous",
    "conv",
    "linear",
    "pos_enc",
    "size",
    "transpose",
    "unsqueeze",
    "view"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:Conv2dSubsampling8.__init__": [
    "Conv2d",
    "Linear",
    "ReLU",
    "Sequential",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:Conv2dSubsampling8.forward": [
    "contiguous",
    "conv",
    "linear",
    "pos_enc",
    "size",
    "transpose",
    "unsqueeze",
    "view"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:LegacyLinearNoSubsampling.__init__": [
    "Dropout",
    "LayerNorm",
    "Linear",
    "ReLU",
    "Sequential",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.subsampling:LegacyLinearNoSubsampling.forward": [
    "out",
    "pos_enc"
  ],
  "src.chatterbox.models.s3gen.transformer.encoder_layer:TransformerEncoderLayer.__init__": [
    "Dropout",
    "LayerNorm",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.encoder_layer:TransformerEncoderLayer.forward": [
    "dropout",
    "feed_forward",
    "norm1",
    "norm2",
    "ones",
    "self_attn",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.transformer.encoder_layer:ConformerEncoderLayer.__init__": [
    "Dropout",
    "LayerNorm",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.encoder_layer:ConformerEncoderLayer.forward": [
    "conv_module",
    "dropout",
    "feed_forward",
    "feed_forward_macaron",
    "norm_conv",
    "norm_ff",
    "norm_ff_macaron",
    "norm_final",
    "norm_mha",
    "ones",
    "self_attn",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.transformer.activation:Swish.forward": [
    "sigmoid"
  ],
  "src.chatterbox.models.s3gen.transformer.activation:Snake.__init__": [
    "Parameter",
    "__init__",
    "ones",
    "super",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.transformer.activation:Snake.forward": [
    "exp",
    "pow",
    "sin",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.transformer.convolution:ConvolutionModule.__init__": [
    "BatchNorm1d",
    "Conv1d",
    "LayerNorm",
    "ReLU",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.convolution:ConvolutionModule.forward": [
    "activation",
    "cat",
    "depthwise_conv",
    "glu",
    "masked_fill_",
    "norm",
    "ones",
    "pad",
    "pointwise_conv1",
    "pointwise_conv2",
    "size",
    "transpose",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.transformer.positionwise_feed_forward:PositionwiseFeedForward.__init__": [
    "Dropout",
    "Linear",
    "ReLU",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.positionwise_feed_forward:PositionwiseFeedForward.forward": [
    "activation",
    "dropout",
    "w_1",
    "w_2"
  ],
  "src.chatterbox.models.s3gen.transformer.positionwise_feed_forward:MoEFFNLayer.__init__": [
    "Linear",
    "ModuleList",
    "PositionwiseFeedForward",
    "ReLU",
    "__init__",
    "range",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.positionwise_feed_forward:MoEFFNLayer.forward": [
    "enumerate",
    "expert",
    "gate",
    "size",
    "softmax",
    "to",
    "topk",
    "view",
    "where",
    "zeros_like"
  ],
  "src.chatterbox.models.s3gen.transformer.attention:MultiHeadedAttention.__init__": [
    "Dropout",
    "Linear",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.attention:MultiHeadedAttention.forward_qkv": [
    "linear_k",
    "linear_q",
    "linear_v",
    "size",
    "transpose",
    "view"
  ],
  "src.chatterbox.models.s3gen.transformer.attention:MultiHeadedAttention.forward_attention": [
    "contiguous",
    "dropout",
    "eq",
    "float",
    "linear_out",
    "masked_fill",
    "matmul",
    "ones",
    "size",
    "softmax",
    "transpose",
    "unsqueeze",
    "view"
  ],
  "src.chatterbox.models.s3gen.transformer.attention:MultiHeadedAttention.forward": [
    "cat",
    "empty",
    "forward_attention",
    "forward_qkv",
    "matmul",
    "ones",
    "size",
    "split",
    "sqrt",
    "transpose",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.transformer.attention:RelPositionMultiHeadedAttention.__init__": [
    "Linear",
    "Parameter",
    "Tensor",
    "__init__",
    "super",
    "xavier_uniform_"
  ],
  "src.chatterbox.models.s3gen.transformer.attention:RelPositionMultiHeadedAttention.rel_shift": [
    "cat",
    "size",
    "view",
    "view_as",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.transformer.attention:RelPositionMultiHeadedAttention.forward": [
    "cat",
    "empty",
    "forward_attention",
    "forward_qkv",
    "linear_pos",
    "matmul",
    "ones",
    "rel_shift",
    "size",
    "split",
    "sqrt",
    "to",
    "transpose",
    "view",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.transformer.embedding:PositionalEncoding.__init__": [
    "Dropout",
    "__init__",
    "arange",
    "cos",
    "exp",
    "log",
    "sin",
    "sqrt",
    "super",
    "unsqueeze",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.transformer.embedding:PositionalEncoding.forward": [
    "dropout",
    "position_encoding",
    "size",
    "to"
  ],
  "src.chatterbox.models.s3gen.transformer.embedding:PositionalEncoding.position_encoding": [
    "arange",
    "dim",
    "dropout",
    "embedding",
    "isinstance",
    "max",
    "to",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.transformer.embedding:RelPositionalEncoding.__init__": [
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.embedding:RelPositionalEncoding.forward": [
    "dropout",
    "position_encoding",
    "size",
    "to"
  ],
  "src.chatterbox.models.s3gen.transformer.embedding:WhisperPositionalEncoding.__init__": [
    "__init__",
    "arange",
    "cat",
    "cos",
    "delattr",
    "exp",
    "log",
    "register_buffer",
    "sin",
    "super",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.transformer.embedding:LearnablePositionalEncoding.__init__": [
    "Parameter",
    "__init__",
    "empty",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.embedding:NoPositionalEncoding.__init__": [
    "Dropout",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.embedding:NoPositionalEncoding.forward": [
    "dropout",
    "size",
    "to",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.transformer.embedding:NoPositionalEncoding.position_encoding": [
    "zeros"
  ],
  "src.chatterbox.models.s3gen.transformer.embedding:EspnetRelPositionalEncoding.__init__": [
    "Dropout",
    "__init__",
    "expand",
    "extend_pe",
    "sqrt",
    "super",
    "tensor"
  ],
  "src.chatterbox.models.s3gen.transformer.embedding:EspnetRelPositionalEncoding.extend_pe": [
    "arange",
    "cat",
    "cos",
    "exp",
    "flip",
    "log",
    "sin",
    "size",
    "to",
    "unsqueeze",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.transformer.embedding:EspnetRelPositionalEncoding.forward": [
    "dropout",
    "extend_pe",
    "position_encoding",
    "size"
  ],
  "src.chatterbox.models.s3gen.transformer.embedding:EspnetRelPositionalEncoding.position_encoding": [
    "size"
  ],
  "src.chatterbox.models.s3gen.transformer.upsample_encoder:Upsample1D.__init__": [
    "Conv1d",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.upsample_encoder:Upsample1D.forward": [
    "conv",
    "float",
    "interpolate",
    "pad"
  ],
  "src.chatterbox.models.s3gen.transformer.upsample_encoder:PreLookaheadLayer.__init__": [
    "Conv1d",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.upsample_encoder:PreLookaheadLayer.forward": [
    "contiguous",
    "conv1",
    "conv2",
    "leaky_relu",
    "pad",
    "transpose"
  ],
  "src.chatterbox.models.s3gen.transformer.upsample_encoder:UpsampleConformerEncoder.__init__": [
    "ConformerEncoderLayer",
    "ConvolutionModule",
    "LayerNorm",
    "ModuleList",
    "PositionwiseFeedForward",
    "PreLookaheadLayer",
    "Upsample1D",
    "__init__",
    "range",
    "super"
  ],
  "src.chatterbox.models.s3gen.transformer.upsample_encoder:UpsampleConformerEncoder.forward": [
    "add_optional_chunk_mask",
    "after_norm",
    "contiguous",
    "embed",
    "forward_layers",
    "forward_up_layers",
    "global_cmvn",
    "make_pad_mask",
    "pre_lookahead_layer",
    "size",
    "transpose",
    "unsqueeze",
    "up_embed",
    "up_layer"
  ],
  "src.chatterbox.models.s3gen.transformer.upsample_encoder:UpsampleConformerEncoder.forward_layers": [
    "layer"
  ],
  "src.chatterbox.models.s3gen.transformer.upsample_encoder:UpsampleConformerEncoder.forward_up_layers": [
    "layer"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:sequence_mask": [
    "arange",
    "max",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:LayerNorm.__init__": [
    "Parameter",
    "__init__",
    "ones",
    "super",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:LayerNorm.forward": [
    "len",
    "mean",
    "rsqrt",
    "view"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:ConvReluNorm.__init__": [
    "Conv1d",
    "Dropout",
    "LayerNorm",
    "ModuleList",
    "ReLU",
    "Sequential",
    "__init__",
    "append",
    "range",
    "super",
    "zero_"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:ConvReluNorm.forward": [
    "proj",
    "range",
    "relu_drop"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:DurationPredictor.__init__": [
    "Conv1d",
    "Dropout",
    "LayerNorm",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:DurationPredictor.forward": [
    "conv_1",
    "conv_2",
    "drop",
    "norm_1",
    "norm_2",
    "proj",
    "relu"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:RotaryPositionalEmbeddings.__init__": [
    "__init__",
    "int",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:RotaryPositionalEmbeddings._build_cache": [
    "arange",
    "cat",
    "cos",
    "einsum",
    "float",
    "sin",
    "to"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:RotaryPositionalEmbeddings._neg_half": [
    "cat"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:RotaryPositionalEmbeddings.forward": [
    "_build_cache",
    "_neg_half",
    "cat",
    "rearrange"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:MultiHeadAttention.__init__": [
    "Conv1d",
    "Dropout",
    "RotaryPositionalEmbeddings",
    "__init__",
    "copy_",
    "super",
    "xavier_uniform_"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:MultiHeadAttention.forward": [
    "attention",
    "conv_k",
    "conv_o",
    "conv_q",
    "conv_v"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:MultiHeadAttention.attention": [
    "_attention_bias_proximal",
    "contiguous",
    "drop",
    "key_rotary_pe",
    "masked_fill",
    "matmul",
    "query_rotary_pe",
    "rearrange",
    "size",
    "softmax",
    "sqrt",
    "to",
    "transpose",
    "view"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:MultiHeadAttention._attention_bias_proximal": [
    "abs",
    "arange",
    "log1p",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:FFN.__init__": [
    "Conv1d",
    "Dropout",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:FFN.forward": [
    "conv_1",
    "conv_2",
    "drop",
    "relu"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:Encoder.__init__": [
    "Dropout",
    "FFN",
    "LayerNorm",
    "ModuleList",
    "MultiHeadAttention",
    "__init__",
    "append",
    "range",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:Encoder.forward": [
    "drop",
    "range",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:TextEncoder.__init__": [
    "Conv1d",
    "ConvReluNorm",
    "DurationPredictor",
    "Embedding",
    "Encoder",
    "__init__",
    "normal_",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.text_encoder:TextEncoder.forward": [
    "cat",
    "detach",
    "emb",
    "encoder",
    "prenet",
    "proj_m",
    "proj_w",
    "repeat",
    "sequence_mask",
    "size",
    "sqrt",
    "to",
    "transpose",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:SinusoidalPosEmb.__init__": [
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:SinusoidalPosEmb.forward": [
    "arange",
    "cat",
    "cos",
    "exp",
    "float",
    "log",
    "sin",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:Block1D.__init__": [
    "Conv1d",
    "GroupNorm",
    "Mish",
    "Sequential",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:Block1D.forward": [
    "block"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:ResnetBlock1D.__init__": [
    "Block1D",
    "Conv1d",
    "Linear",
    "Mish",
    "Sequential",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:ResnetBlock1D.forward": [
    "block1",
    "block2",
    "mlp",
    "res_conv",
    "unsqueeze"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:Downsample1D.__init__": [
    "Conv1d",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:Downsample1D.forward": [
    "conv"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:TimestepEmbedding.__init__": [
    "Linear",
    "__init__",
    "get_activation",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:TimestepEmbedding.forward": [
    "act",
    "cond_proj",
    "linear_1",
    "linear_2",
    "post_act"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:Upsample1D.__init__": [
    "Conv1d",
    "ConvTranspose1d",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:Upsample1D.forward": [
    "conv",
    "interpolate"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:ConformerWrapper.__init__": [
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:ConformerWrapper.forward": [
    "bool",
    "forward",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:Decoder.__init__": [
    "Block1D",
    "Conv1d",
    "Downsample1D",
    "ModuleList",
    "ResnetBlock1D",
    "SinusoidalPosEmb",
    "TimestepEmbedding",
    "Upsample1D",
    "__init__",
    "append",
    "get_block",
    "initialize_weights",
    "len",
    "range",
    "super",
    "tuple"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:Decoder.get_block": [
    "BasicTransformerBlock",
    "ConformerWrapper",
    "ValueError"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:Decoder.initialize_weights": [
    "constant_",
    "isinstance",
    "kaiming_normal_",
    "modules"
  ],
  "src.chatterbox.models.s3gen.matcha.decoder:Decoder.forward": [
    "append",
    "downsample",
    "final_block",
    "final_proj",
    "pack",
    "pop",
    "rearrange",
    "repeat",
    "resnet",
    "time_embeddings",
    "time_mlp",
    "transformer_block",
    "upsample"
  ],
  "src.chatterbox.models.s3gen.matcha.flow_matching:BASECFM.__init__": [
    "__init__",
    "hasattr",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.flow_matching:BASECFM.forward": [
    "inference_mode",
    "linspace",
    "randn_like",
    "solve_euler"
  ],
  "src.chatterbox.models.s3gen.matcha.flow_matching:BASECFM.solve_euler": [
    "append",
    "estimator",
    "len",
    "range"
  ],
  "src.chatterbox.models.s3gen.matcha.flow_matching:BASECFM.compute_loss": [
    "estimator",
    "mse_loss",
    "rand",
    "randn_like",
    "squeeze",
    "sum"
  ],
  "src.chatterbox.models.s3gen.matcha.flow_matching:CFM.__init__": [
    "Decoder",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.transformer:SnakeBeta.__init__": [
    "LoRACompatibleLinear",
    "Parameter",
    "__init__",
    "isinstance",
    "ones",
    "super",
    "zeros"
  ],
  "src.chatterbox.models.s3gen.matcha.transformer:SnakeBeta.forward": [
    "exp",
    "pow",
    "proj",
    "sin"
  ],
  "src.chatterbox.models.s3gen.matcha.transformer:FeedForward.__init__": [
    "ApproximateGELU",
    "Dropout",
    "GEGLU",
    "GELU",
    "LoRACompatibleLinear",
    "ModuleList",
    "SnakeBeta",
    "__init__",
    "append",
    "int",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.transformer:FeedForward.forward": [
    "module"
  ],
  "src.chatterbox.models.s3gen.matcha.transformer:BasicTransformerBlock.__init__": [
    "AdaLayerNorm",
    "AdaLayerNormZero",
    "Attention",
    "FeedForward",
    "LayerNorm",
    "ValueError",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.s3gen.matcha.transformer:BasicTransformerBlock.forward": [
    "ValueError",
    "attn1",
    "attn2",
    "cat",
    "chunk",
    "ff",
    "norm1",
    "norm2",
    "norm3",
    "unsqueeze"
  ],
  "src.chatterbox.models.t3.modules.learned_pos_emb:LearnedPositionEmbeddings.__init__": [
    "Embedding",
    "__init__",
    "normal_",
    "super"
  ],
  "src.chatterbox.models.t3.modules.learned_pos_emb:LearnedPositionEmbeddings.forward": [
    "arange",
    "emb"
  ],
  "src.chatterbox.models.t3.modules.learned_pos_emb:LearnedPositionEmbeddings.get_fixed_embedding": [
    "atleast_2d",
    "emb",
    "is_tensor",
    "tensor",
    "to"
  ],
  "src.chatterbox.models.t3.modules.cond_enc:T3Cond.to": [
    "is_tensor",
    "item",
    "items",
    "setattr",
    "to",
    "type",
    "view"
  ],
  "src.chatterbox.models.t3.modules.cond_enc:T3Cond.save": [
    "save"
  ],
  "src.chatterbox.models.t3.modules.cond_enc:T3Cond.load": [
    "T3Cond",
    "load"
  ],
  "src.chatterbox.models.t3.modules.cond_enc:T3CondEnc.__init__": [
    "Linear",
    "NotImplementedError",
    "Perceiver",
    "__init__",
    "str",
    "super"
  ],
  "src.chatterbox.models.t3.modules.cond_enc:T3CondEnc.forward": [
    "cat",
    "emotion_adv_fc",
    "perceiver",
    "spkr_enc",
    "view",
    "zeros_like"
  ],
  "src.chatterbox.models.t3.modules.perceiver:RelativePositionBias.__init__": [
    "Embedding",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.t3.modules.perceiver:RelativePositionBias._relative_position_bucket": [
    "abs",
    "float",
    "full_like",
    "log",
    "long",
    "max",
    "min",
    "where",
    "zeros_like"
  ],
  "src.chatterbox.models.t3.modules.perceiver:RelativePositionBias.forward": [
    "_relative_position_bucket",
    "arange",
    "rearrange",
    "relative_attention_bias"
  ],
  "src.chatterbox.models.t3.modules.perceiver:AttentionQKV.__init__": [
    "Dropout",
    "__init__",
    "setup_flash_config",
    "super"
  ],
  "src.chatterbox.models.t3.modules.perceiver:AttentionQKV.forward": [
    "combine_heads",
    "flash_attention",
    "scaled_dot_product_attention",
    "split_heads"
  ],
  "src.chatterbox.models.t3.modules.perceiver:AttentionQKV.scaled_dot_product_attention": [
    "dropout",
    "einsum",
    "float",
    "masked_fill",
    "softmax"
  ],
  "src.chatterbox.models.t3.modules.perceiver:AttentionQKV.flash_attention": [
    "scaled_dot_product_attention",
    "sdp_kernel"
  ],
  "src.chatterbox.models.t3.modules.perceiver:AttentionQKV.split_heads": [
    "permute",
    "view"
  ],
  "src.chatterbox.models.t3.modules.perceiver:AttentionQKV.combine_heads": [
    "contiguous",
    "permute",
    "view"
  ],
  "src.chatterbox.models.t3.modules.perceiver:AttentionBlock2.__init__": [
    "AttentionQKV",
    "LayerNorm",
    "Linear",
    "RelativePositionBias",
    "__init__",
    "super"
  ],
  "src.chatterbox.models.t3.modules.perceiver:AttentionBlock2.forward": [
    "attention",
    "norm",
    "proj_out",
    "reshape",
    "to_k",
    "to_q",
    "to_v"
  ],
  "src.chatterbox.models.t3.modules.perceiver:Perceiver.__init__": [
    "AttentionBlock2",
    "Parameter",
    "__init__",
    "empty",
    "sqrt",
    "super",
    "uniform_"
  ],
  "src.chatterbox.models.t3.modules.perceiver:Perceiver.forward": [
    "attn",
    "expand"
  ],
  "src.chatterbox.models.t3.inference.t3_hf_backend:T3HuggingfaceBackend.__init__": [
    "__init__",
    "super"
  ],
  "src.chatterbox.models.t3.inference.t3_hf_backend:T3HuggingfaceBackend.prepare_inputs_for_generation": [
    "cat",
    "expand",
    "inference_mode",
    "size",
    "speech_enc"
  ],
  "src.chatterbox.models.t3.inference.t3_hf_backend:T3HuggingfaceBackend.forward": [
    "CausalLMOutputWithCrossAttentions",
    "inference_mode",
    "len",
    "model",
    "size",
    "speech_head"
  ],
  "src.chatterbox.models.t3.inference.alignment_stream_analyzer:<module>": [
    "getLogger"
  ],
  "src.chatterbox.models.t3.inference.alignment_stream_analyzer:AlignmentStreamAnalyzer.__init__": [
    "_add_attention_spy",
    "device",
    "next",
    "parameters",
    "zeros"
  ],
  "src.chatterbox.models.t3.inference.alignment_stream_analyzer:AlignmentStreamAnalyzer._add_attention_spy.attention_forward_hook": [
    "detach",
    "mean"
  ],
  "src.chatterbox.models.t3.inference.alignment_stream_analyzer:AlignmentStreamAnalyzer._add_attention_spy": [
    "MethodType",
    "register_forward_hook"
  ],
  "src.chatterbox.models.t3.inference.alignment_stream_analyzer:AlignmentStreamAnalyzer._add_attention_spy.patched_forward": [
    "original_forward"
  ],
  "src.chatterbox.models.t3.inference.alignment_stream_analyzer:AlignmentStreamAnalyzer.step": [
    "argmax",
    "cat",
    "clone",
    "max",
    "ones_like",
    "sum",
    "warn"
  ],
  "src.chatterbox.models.t3.inference.alignment_stream_analyzer:AlignmentStreamAnalyzer.close": [
    "hasattr",
    "remove"
  ],
  "tools.exporters.t3_fx_export:<module>": [
    "Path",
    "SystemExit",
    "insert",
    "main",
    "resolve",
    "str"
  ],
  "tools.exporters.t3_fx_export:_find_ckpt_dir": [
    "Path",
    "exists",
    "expanduser",
    "getenv",
    "home",
    "iterdir",
    "sorted",
    "stat",
    "strip"
  ],
  "tools.exporters.t3_fx_export:_load_t3": [
    "FileNotFoundError",
    "Path",
    "T3",
    "_find_ckpt_dir",
    "endswith",
    "eval",
    "float",
    "get",
    "isinstance",
    "len",
    "load_file",
    "load_state_dict",
    "lower",
    "print",
    "relative_to",
    "str",
    "to",
    "walk"
  ],
  "tools.exporters.t3_fx_export:_get_llama_layers": [
    "RuntimeError",
    "append",
    "children",
    "endswith",
    "getattr",
    "hasattr",
    "isinstance",
    "len",
    "list",
    "lower",
    "modules",
    "type"
  ],
  "tools.exporters.t3_fx_export:BlockWrapper.__init__": [
    "__init__",
    "super"
  ],
  "tools.exporters.t3_fx_export:BlockWrapper.forward": [
    "block",
    "isinstance"
  ],
  "tools.exporters.t3_fx_export:RoPETracer.is_leaf_module": [
    "is_leaf_module",
    "super",
    "type"
  ],
  "tools.exporters.t3_fx_export:trace_block": [
    "BlockWrapper",
    "GraphModule",
    "RoPETracer",
    "arange",
    "eval",
    "expand",
    "no_grad",
    "randn",
    "to",
    "trace",
    "unsqueeze",
    "wrapper"
  ],
  "tools.exporters.t3_fx_export:op_histogram": [
    "dict",
    "get",
    "get_submodule",
    "getattr",
    "items",
    "sorted",
    "str",
    "type"
  ],
  "tools.exporters.t3_fx_export:main": [
    "ArgumentParser",
    "IndexError",
    "Path",
    "_get_llama_layers",
    "_load_t3",
    "add_argument",
    "dumps",
    "getattr",
    "items",
    "join",
    "len",
    "makedirs",
    "numel",
    "op_histogram",
    "parameters",
    "parse_args",
    "print",
    "splitlines",
    "str",
    "sum",
    "trace_block",
    "type",
    "write_text"
  ]
}